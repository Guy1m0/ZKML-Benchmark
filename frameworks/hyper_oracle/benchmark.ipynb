{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 20:16:08.413462: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-31 20:16:08.433309: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 20:16:08.433333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 20:16:08.433860: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 20:16:08.437325: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 20:16:08.841452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch, struct, os, psutil, subprocess, time, threading\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use json file for model (results, config etc) management\n",
    "model_name = \"dnn_mnist_pt\"\n",
    "model_path = \"../../models/\"\n",
    "\n",
    "state_dict = torch.load(model_path + model_name + \".pth\", map_location=torch.device(\"cpu\"))\n",
    "list_vars = state_dict\n",
    "\n",
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "test_images_pt = torch.tensor(test_images).float()\n",
    "# Flatten and normalize the images\n",
    "test_images_pt = test_images_pt.view(-1, 28*28) / 255.0  # Flatten and normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 56)  # Flatten 28*28 and feed into 56 neurons\n",
    "        self.fc2 = nn.Linear(56, num_classes)  # 56 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "    \n",
    "model_pt = Net()\n",
    "model_pt.load_state_dict(state_dict)\n",
    "model_pt.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Ensure gradients are not computed\n",
    "    predictions = model_pt(test_images_pt)\n",
    "    predicted_labels = predictions.argmax(dim=1)\n",
    "predictions = predicted_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp/' created successfully\n"
     ]
    }
   ],
   "source": [
    "folder = \"./tmp/\"\n",
    "\n",
    "# Create the directory 'tmp' in the current working directory\n",
    "try:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"Directory '{folder}' created successfully\")\n",
    "except OSError as error:\n",
    "    print(f\"Directory '{folder}' cannot be created. Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing variable: fc1.weight with shape:  (56, 784)\n",
      "Processing variable: fc1.bias with shape:  (56,)\n",
      "Processing variable: fc2.weight with shape:  (10, 56)\n",
      "Processing variable: fc2.bias with shape:  (10,)\n"
     ]
    }
   ],
   "source": [
    "fname_out = folder + \"ggml-model-\" + model_name + \".bin\"\n",
    "pack_fmt = \"!i\"\n",
    "\n",
    "fout = open(fname_out, \"w+b\")\n",
    "fout.write(struct.pack(pack_fmt, 0x67676d6c)) # magic: ggml in hex\n",
    "\n",
    "for name in list_vars.keys():\n",
    "    data = list_vars[name].squeeze().numpy()\n",
    "    print(\"Processing variable: \" + name + \" with shape: \", data.shape) \n",
    "    n_dims = len(data.shape)\n",
    "   \n",
    "    fout.write(struct.pack(pack_fmt, n_dims))\n",
    "    \n",
    "    data = data.astype(np.float32)\n",
    "    for i in range(n_dims):\n",
    "        fout.write(struct.pack(pack_fmt, data.shape[n_dims - 1 - i]))\n",
    "\n",
    "    # data\n",
    "    data = data.astype(\">f4\")\n",
    "    data.tofile(fout)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_from_file(data_file=\"input\", show=False):\n",
    "    try:\n",
    "        with open(data_file, 'rb') as file:\n",
    "            buf = file.read()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, e\n",
    "\n",
    "    digits = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    \n",
    "    if show:\n",
    "        c = \"\"\n",
    "        for row in range(28):\n",
    "            for col in range(28):\n",
    "                if buf[row * 28 + col] > 230:\n",
    "                    c += \"&\"\n",
    "                else:\n",
    "                    c += \"-\"\n",
    "            c += \"\\n\"\n",
    "        print(c)\n",
    "\n",
    "    return digits, None\n",
    "\n",
    "def save_img_to_file(image, data_file = \"input\"):\n",
    "    try:\n",
    "        # Convert to bytes\n",
    "        image_bytes = image.astype('uint8').tobytes()\n",
    "        \n",
    "        # Write to file\n",
    "        with open(data_file, 'wb') as file:\n",
    "            file.write(image_bytes)\n",
    "        \n",
    "        #print(f\"Image saved to {data_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_memory(pid, freq = 0.01):\n",
    "    p = psutil.Process(pid)\n",
    "    max_memory = 0\n",
    "    while True:\n",
    "        try:\n",
    "            mem = p.memory_info().rss / (1024 * 1024)\n",
    "            max_memory = max(max_memory, mem)\n",
    "        except psutil.NoSuchProcess:\n",
    "            break  # Process has finished\n",
    "        time.sleep(freq)  # Poll every second\n",
    "        \n",
    "    #print(f\"Maximum memory used: {max_memory} MB\")\n",
    "    return max_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 8\n",
    "img_out_path = folder + str(ind)\n",
    "save_img_to_file(test_images[ind], img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_file = \"./bin/vm\"\n",
    "program = \"./bin/gglm.bin\"\n",
    "model_in_path = fname_out\n",
    "\n",
    "command = [f\"{vm_file}\", f\"--basedir={folder}\",\n",
    "                f\"--program={program}\", f\"--model={model_in_path}\", \n",
    "                f\"--data={img_out_path}\", \"--mipsVMCompatible\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process ID: 487774\n",
      "Maximum memory used: 86.6953125 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Get the process ID\n",
    "pid = process.pid\n",
    "print(f\"Process ID: {pid}\")\n",
    "\n",
    "# Start memory monitoring in a separate thread\n",
    "monitor_thread = threading.Thread(target=monitor_memory, args=(pid,))\n",
    "monitor_thread.start()\n",
    "\n",
    "# Wait for the process to complete and capture output\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Wait for the monitoring thread to finish\n",
    "monitor_thread.join()\n",
    "\n",
    "stderr[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "------------------&&&-&&&---\n",
      "--------------&&&&&&&&&&&---\n",
      "-------------&&&&&&&--------\n",
      "-------------&-&------------\n",
      "---------&------------------\n",
      "--------&-------------------\n",
      "-------&&-------------------\n",
      "------&---------------------\n",
      "------&---------------------\n",
      "-----&&&--------------------\n",
      "-----&&&&&------------------\n",
      "------&&&&&&&&&&&&----------\n",
      "---------&&&&&&&&&&---------\n",
      "------------&&&&&&&---------\n",
      "------------&&---&&---------\n",
      "------------&&&-&&&---------\n",
      "-------------&&&&&----------\n",
      "--------------&&------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "digits, error = load_img_from_file(img_out_path,show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "def benchmark(test_images, test_labels, tmp_folder, model_in_path, vm_file = \"./bin/vm\", program = \"./bin/gglm.bin\", threaded = True):\n",
    "    benchmark_start_time = time.time()\n",
    "    mem = []\n",
    "    results = []\n",
    "    for ind, img in enumerate(test_images):\n",
    "        img_out_path = tmp_folder + str(ind)\n",
    "        save_img_to_file(img, img_out_path)\n",
    "\n",
    "        # Exclusion of Pre-processing\n",
    "        start_time = time.time()\n",
    "        command = [f\"{vm_file}\", f\"--basedir={folder}\",\n",
    "                f\"--program={program}\", f\"--model={model_in_path}\", \n",
    "                f\"--data={img_out_path}\", \"--mipsVMCompatible\"]\n",
    "        \n",
    "        print (\"Process for image\", ind)\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Get the process ID\n",
    "        pid = process.pid\n",
    "\n",
    "        if threaded:\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                future = executor.submit(monitor_memory, pid)\n",
    "                _, stderr = process.communicate()\n",
    "                max_memory = future.result()\n",
    "                #print(f\"Maximum memory used in multi-threaded mode: {max_memory} bytes\")\n",
    "        else:\n",
    "            max_memory = monitor_memory(pid)  # Run in the same thread\n",
    "            _, stderr = process.communicate()\n",
    "            #print(f\"Maximum memory used in single-threaded mode: {max_memory} bytes\")\n",
    "        mem.append(max_memory)\n",
    "        #print (\"Ind:\", ind, \"mem:\", max_memory, \"time:\", time.time() - start_time)\n",
    "        results.append([int(stderr[-2]), max_memory, time.time() - start_time])\n",
    "    \n",
    "    print (\"Total time:\", time.time() - benchmark_start_time)\n",
    "    #print (\"total mem:\", sum(mem))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process for image 0\n",
      "Process for image 1\n",
      "Process for image 2\n",
      "Process for image 3\n",
      "Process for image 4\n",
      "Process for image 5\n",
      "Process for image 6\n",
      "Process for image 7\n",
      "Process for image 8\n",
      "Process for image 9\n",
      "Process for image 10\n",
      "Process for image 11\n",
      "Process for image 12\n",
      "Process for image 13\n",
      "Process for image 14\n",
      "Process for image 15\n",
      "Process for image 16\n",
      "Process for image 17\n",
      "Process for image 18\n",
      "Process for image 19\n",
      "Process for image 20\n",
      "Process for image 21\n",
      "Process for image 22\n",
      "Process for image 23\n",
      "Process for image 24\n",
      "Process for image 25\n",
      "Process for image 26\n",
      "Process for image 27\n",
      "Process for image 28\n",
      "Process for image 29\n",
      "Process for image 30\n",
      "Process for image 31\n",
      "Process for image 32\n",
      "Process for image 33\n",
      "Process for image 34\n",
      "Process for image 35\n",
      "Process for image 36\n",
      "Process for image 37\n",
      "Process for image 38\n",
      "Process for image 39\n",
      "Process for image 40\n",
      "Process for image 41\n",
      "Process for image 42\n",
      "Process for image 43\n",
      "Process for image 44\n",
      "Process for image 45\n",
      "Process for image 46\n",
      "Process for image 47\n",
      "Process for image 48\n",
      "Process for image 49\n",
      "Process for image 50\n",
      "Process for image 51\n",
      "Process for image 52\n",
      "Process for image 53\n",
      "Process for image 54\n",
      "Process for image 55\n",
      "Process for image 56\n",
      "Process for image 57\n",
      "Process for image 58\n",
      "Process for image 59\n",
      "Process for image 60\n",
      "Process for image 61\n",
      "Process for image 62\n",
      "Process for image 63\n",
      "Process for image 64\n",
      "Process for image 65\n",
      "Process for image 66\n",
      "Process for image 67\n",
      "Process for image 68\n",
      "Process for image 69\n",
      "Process for image 70\n",
      "Process for image 71\n",
      "Process for image 72\n",
      "Process for image 73\n",
      "Process for image 74\n",
      "Process for image 75\n",
      "Process for image 76\n",
      "Process for image 77\n",
      "Process for image 78\n",
      "Process for image 79\n",
      "Process for image 80\n",
      "Process for image 81\n",
      "Process for image 82\n",
      "Process for image 83\n",
      "Process for image 84\n",
      "Process for image 85\n",
      "Process for image 86\n",
      "Process for image 87\n",
      "Process for image 88\n",
      "Process for image 89\n",
      "Process for image 90\n",
      "Process for image 91\n",
      "Process for image 92\n",
      "Process for image 93\n",
      "Process for image 94\n",
      "Process for image 95\n",
      "Process for image 96\n",
      "Process for image 97\n",
      "Process for image 98\n",
      "Process for image 99\n",
      "Total time: 360.92509627342224\n"
     ]
    }
   ],
   "source": [
    "results = benchmark(test_images[:100], test_labels, './tmp/', model_in_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 88.35546875, 3.368110179901123],\n",
       " [2, 90.609375, 3.530409336090088],\n",
       " [1, 86.88671875, 3.2679519653320312],\n",
       " [0, 86.73046875, 3.619429111480713],\n",
       " [4, 88.60546875, 3.4474661350250244],\n",
       " [1, 86.9453125, 3.3622653484344482],\n",
       " [4, 88.25, 3.4326109886169434],\n",
       " [9, 87.94140625, 3.520963430404663],\n",
       " [6, 89.5078125, 3.4767587184906006],\n",
       " [9, 88.52734375, 3.4311928749084473],\n",
       " [0, 92.83984375, 3.568319082260132],\n",
       " [6, 87.61328125, 3.5399277210235596],\n",
       " [9, 92.84765625, 3.420233964920044],\n",
       " [0, 88.3359375, 4.561923265457153],\n",
       " [1, 87.609375, 3.2792582511901855],\n",
       " [5, 86.45703125, 3.5403053760528564],\n",
       " [9, 88.68359375, 3.5294783115386963],\n",
       " [7, 86.39453125, 3.408545970916748],\n",
       " [3, 88.41796875, 3.671759843826294],\n",
       " [4, 94.10546875, 3.428042411804199],\n",
       " [9, 88.31640625, 3.4201433658599854],\n",
       " [6, 94.33984375, 4.49481463432312],\n",
       " [6, 86.6640625, 3.4981234073638916],\n",
       " [5, 87.7578125, 3.3555214405059814],\n",
       " [4, 88.6328125, 3.366218328475952],\n",
       " [0, 88.65625, 3.7094602584838867],\n",
       " [7, 88.9609375, 3.2468111515045166],\n",
       " [4, 89.4296875, 3.430544376373291],\n",
       " [0, 92.31640625, 3.5896127223968506],\n",
       " [1, 86.39453125, 3.319504976272583],\n",
       " [3, 87.59765625, 4.478478908538818],\n",
       " [1, 87.7421875, 4.306854724884033],\n",
       " [3, 87.26953125, 3.4629833698272705],\n",
       " [4, 87.78515625, 3.488344669342041],\n",
       " [7, 88.83984375, 4.534254789352417],\n",
       " [2, 88.8046875, 3.509890079498291],\n",
       " [7, 94.00390625, 3.4104461669921875],\n",
       " [1, 88.01953125, 3.4460389614105225],\n",
       " [2, 93.5078125, 3.381673812866211],\n",
       " [1, 92.0078125, 3.3990132808685303],\n",
       " [1, 88.16796875, 4.245435953140259],\n",
       " [7, 87.7578125, 3.410574197769165],\n",
       " [4, 91.98828125, 3.476680278778076],\n",
       " [2, 87.1953125, 3.368715763092041],\n",
       " [3, 87.28125, 3.4399333000183105],\n",
       " [5, 87.06640625, 4.52068018913269],\n",
       " [1, 92.63671875, 3.347440481185913],\n",
       " [2, 88.5234375, 3.4980342388153076],\n",
       " [4, 88.84375, 3.5286169052124023],\n",
       " [4, 87.9609375, 3.3391494750976562],\n",
       " [6, 93.61328125, 3.3742685317993164],\n",
       " [3, 86.46484375, 3.5173940658569336],\n",
       " [5, 92.71875, 4.530240297317505],\n",
       " [5, 87.234375, 3.4811418056488037],\n",
       " [6, 87.44921875, 3.584144353866577],\n",
       " [0, 87.234375, 3.532278537750244],\n",
       " [4, 87.5703125, 3.579909324645996],\n",
       " [1, 88.56640625, 4.346356391906738],\n",
       " [9, 92.48046875, 4.4982452392578125],\n",
       " [5, 93.71484375, 3.366190195083618],\n",
       " [7, 87.30078125, 3.3788201808929443],\n",
       " [8, 91.94921875, 3.588327169418335],\n",
       " [9, 87.0625, 3.3987276554107666],\n",
       " [3, 91.07421875, 3.4097201824188232],\n",
       " [7, 88.33984375, 3.428684711456299],\n",
       " [4, 86.64453125, 3.3570289611816406],\n",
       " [6, 88.6953125, 3.5099644660949707],\n",
       " [4, 88.0703125, 4.476025104522705],\n",
       " [3, 88.0859375, 3.498767375946045],\n",
       " [0, 86.8203125, 3.4712092876434326],\n",
       " [7, 88.51171875, 3.4189329147338867],\n",
       " [0, 88.1484375, 3.613553524017334],\n",
       " [2, 93.8125, 4.626765251159668],\n",
       " [9, 92.20703125, 3.4824838638305664],\n",
       " [1, 88.46484375, 3.3112432956695557],\n",
       " [7, 92.7109375, 4.521037578582764],\n",
       " [3, 88.3984375, 3.399604320526123],\n",
       " [2, 88.609375, 3.3212759494781494],\n",
       " [9, 88.40625, 3.3415544033050537],\n",
       " [7, 88.30859375, 4.636007308959961],\n",
       " [7, 93.2890625, 3.365419387817383],\n",
       " [6, 88.12109375, 3.527874231338501],\n",
       " [2, 88.03515625, 3.5421321392059326],\n",
       " [7, 88.328125, 3.5234427452087402],\n",
       " [8, 87.0, 3.4800832271575928],\n",
       " [4, 93.86328125, 3.4905290603637695],\n",
       " [7, 87.41796875, 3.4808995723724365],\n",
       " [3, 88.69140625, 3.51847243309021],\n",
       " [6, 87.44140625, 3.518451452255249],\n",
       " [1, 88.4921875, 3.44099760055542],\n",
       " [3, 87.515625, 3.4897918701171875],\n",
       " [6, 87.453125, 3.393218517303467],\n",
       " [9, 88.95703125, 3.3550734519958496],\n",
       " [3, 86.63671875, 3.515322685241699],\n",
       " [1, 88.1953125, 3.3302536010742188],\n",
       " [4, 93.85546875, 4.664330720901489],\n",
       " [1, 91.49609375, 3.395179033279419],\n",
       " [7, 87.61328125, 3.416783571243286],\n",
       " [6, 87.30078125, 3.492586374282837],\n",
       " [9, 93.546875, 3.5445029735565186]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 8 Not match!\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if predictions[i] != results[i][0]:\n",
    "        print (\"Index\", i, \"Not match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
