{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 20:16:08.413462: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-31 20:16:08.433309: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 20:16:08.433333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 20:16:08.433860: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 20:16:08.437325: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 20:16:08.841452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch, struct, os, psutil, subprocess, time, threading\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use json file for model (results, config etc) management\n",
    "model_name = \"dnn_mnist_pt\"\n",
    "model_path = \"../../models/\"\n",
    "\n",
    "state_dict = torch.load(model_path + model_name + \".pth\", map_location=torch.device(\"cpu\"))\n",
    "list_vars = state_dict\n",
    "\n",
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "test_images_pt = torch.tensor(test_images).float()\n",
    "# Flatten and normalize the images\n",
    "test_images_pt = test_images_pt.view(-1, 28*28) / 255.0  # Flatten and normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 56)  # Flatten 28*28 and feed into 56 neurons\n",
    "        self.fc2 = nn.Linear(56, num_classes)  # 56 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "    \n",
    "model_pt = Net()\n",
    "model_pt.load_state_dict(state_dict)\n",
    "model_pt.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Ensure gradients are not computed\n",
    "    predictions = model_pt(test_images_pt)\n",
    "    predicted_labels = predictions.argmax(dim=1)\n",
    "\n",
    "predicted_labels = predicted_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp/' created successfully\n"
     ]
    }
   ],
   "source": [
    "folder = \"./tmp/\"\n",
    "\n",
    "# Create the directory 'tmp' in the current working directory\n",
    "try:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"Directory '{folder}' created successfully\")\n",
    "except OSError as error:\n",
    "    print(f\"Directory '{folder}' cannot be created. Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing variable: fc1.weight with shape:  (56, 784)\n",
      "Processing variable: fc1.bias with shape:  (56,)\n",
      "Processing variable: fc2.weight with shape:  (10, 56)\n",
      "Processing variable: fc2.bias with shape:  (10,)\n"
     ]
    }
   ],
   "source": [
    "fname_out = folder + \"ggml-model-\" + model_name + \".bin\"\n",
    "pack_fmt = \"!i\"\n",
    "\n",
    "fout = open(fname_out, \"w+b\")\n",
    "fout.write(struct.pack(pack_fmt, 0x67676d6c)) # magic: ggml in hex\n",
    "\n",
    "for name in list_vars.keys():\n",
    "    data = list_vars[name].squeeze().numpy()\n",
    "    print(\"Processing variable: \" + name + \" with shape: \", data.shape) \n",
    "    n_dims = len(data.shape)\n",
    "   \n",
    "    fout.write(struct.pack(pack_fmt, n_dims))\n",
    "    \n",
    "    data = data.astype(np.float32)\n",
    "    for i in range(n_dims):\n",
    "        fout.write(struct.pack(pack_fmt, data.shape[n_dims - 1 - i]))\n",
    "\n",
    "    # data\n",
    "    data = data.astype(\">f4\")\n",
    "    data.tofile(fout)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_from_file(data_file=\"input\", show=False):\n",
    "    try:\n",
    "        with open(data_file, 'rb') as file:\n",
    "            buf = file.read()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, e\n",
    "\n",
    "    digits = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    \n",
    "    if show:\n",
    "        c = \"\"\n",
    "        for row in range(28):\n",
    "            for col in range(28):\n",
    "                if buf[row * 28 + col] > 230:\n",
    "                    c += \"&\"\n",
    "                else:\n",
    "                    c += \"-\"\n",
    "            c += \"\\n\"\n",
    "        print(c)\n",
    "\n",
    "    return digits, None\n",
    "\n",
    "def save_img_to_file(image, data_file = \"input\"):\n",
    "    try:\n",
    "        # Convert to bytes\n",
    "        image_bytes = image.astype('uint8').tobytes()\n",
    "        \n",
    "        # Write to file\n",
    "        with open(data_file, 'wb') as file:\n",
    "            file.write(image_bytes)\n",
    "        \n",
    "        #print(f\"Image saved to {data_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_memory(pid, freq = 0.01):\n",
    "    p = psutil.Process(pid)\n",
    "    max_memory = 0\n",
    "    while True:\n",
    "        try:\n",
    "            mem = p.memory_info().rss / (1024 * 1024)\n",
    "            max_memory = max(max_memory, mem)\n",
    "        except psutil.NoSuchProcess:\n",
    "            break  # Process has finished\n",
    "        time.sleep(freq)  # Poll every second\n",
    "        \n",
    "    #print(f\"Maximum memory used: {max_memory} MB\")\n",
    "    return max_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 8\n",
    "img_out_path = folder + str(ind)\n",
    "save_img_to_file(test_images[ind], img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_file = \"./bin/vm\"\n",
    "program = \"./bin/gglm.bin\"\n",
    "model_in_path = fname_out\n",
    "\n",
    "command = [f\"{vm_file}\", f\"--basedir={folder}\",\n",
    "                f\"--program={program}\", f\"--model={model_in_path}\", \n",
    "                f\"--data={img_out_path}\", \"--mipsVMCompatible\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process ID: 487774\n",
      "Maximum memory used: 86.6953125 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Get the process ID\n",
    "pid = process.pid\n",
    "print(f\"Process ID: {pid}\")\n",
    "\n",
    "# Start memory monitoring in a separate thread\n",
    "monitor_thread = threading.Thread(target=monitor_memory, args=(pid,))\n",
    "monitor_thread.start()\n",
    "\n",
    "# Wait for the process to complete and capture output\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Wait for the monitoring thread to finish\n",
    "monitor_thread.join()\n",
    "\n",
    "stderr[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "------------------&&&-&&&---\n",
      "--------------&&&&&&&&&&&---\n",
      "-------------&&&&&&&--------\n",
      "-------------&-&------------\n",
      "---------&------------------\n",
      "--------&-------------------\n",
      "-------&&-------------------\n",
      "------&---------------------\n",
      "------&---------------------\n",
      "-----&&&--------------------\n",
      "-----&&&&&------------------\n",
      "------&&&&&&&&&&&&----------\n",
      "---------&&&&&&&&&&---------\n",
      "------------&&&&&&&---------\n",
      "------------&&---&&---------\n",
      "------------&&&-&&&---------\n",
      "-------------&&&&&----------\n",
      "--------------&&------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "digits, error = load_img_from_file(img_out_path,show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def benchmark(test_images, tmp_folder, model_in_path, vm_file = \"./bin/vm\", program = \"./bin/gglm.bin\", threaded = True):\n",
    "    benchmark_start_time = time.time()\n",
    "    veri_infer = []\n",
    "    mem_usage = []\n",
    "    time_cost = []\n",
    "    for ind, img in enumerate(test_images):\n",
    "        img_out_path = tmp_folder + str(ind)\n",
    "        save_img_to_file(img, img_out_path)\n",
    "\n",
    "        # Exclusion of Pre-processing\n",
    "        start_time = time.time()\n",
    "        command = [f\"{vm_file}\", f\"--basedir={folder}\",\n",
    "                f\"--program={program}\", f\"--model={model_in_path}\", \n",
    "                f\"--data={img_out_path}\", \"--mipsVMCompatible\"]\n",
    "        \n",
    "        print (\"Process for image\", ind)\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Get the process ID\n",
    "        pid = process.pid\n",
    "\n",
    "        if threaded:\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                future = executor.submit(monitor_memory, pid)\n",
    "                _, stderr = process.communicate()\n",
    "                max_memory = future.result()\n",
    "                #print(f\"Maximum memory used in multi-threaded mode: {max_memory} bytes\")\n",
    "        else:\n",
    "            max_memory = monitor_memory(pid)  # Run in the same thread\n",
    "            _, stderr = process.communicate()\n",
    "            #print(f\"Maximum memory used in single-threaded mode: {max_memory} bytes\")\n",
    "        veri_infer.append(int(stderr[-2]))\n",
    "        mem_usage.append(max_memory)\n",
    "        time_cost.append(time.time() - start_time)\n",
    "    \n",
    "    print (\"Total time:\", time.time() - benchmark_start_time)\n",
    "    #print (\"total mem:\", sum(mem))\n",
    "    return veri_infer, mem_usage, time_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process for image 0\n",
      "Process for image 1\n",
      "Process for image 2\n",
      "Process for image 3\n",
      "Process for image 4\n",
      "Process for image 5\n",
      "Process for image 6\n",
      "Process for image 7\n",
      "Process for image 8\n",
      "Process for image 9\n",
      "Process for image 10\n",
      "Process for image 11\n",
      "Process for image 12\n",
      "Process for image 13\n",
      "Process for image 14\n",
      "Process for image 15\n",
      "Process for image 16\n",
      "Process for image 17\n",
      "Process for image 18\n",
      "Process for image 19\n",
      "Process for image 20\n",
      "Process for image 21\n",
      "Process for image 22\n",
      "Process for image 23\n",
      "Process for image 24\n",
      "Process for image 25\n",
      "Process for image 26\n",
      "Process for image 27\n",
      "Process for image 28\n",
      "Process for image 29\n",
      "Process for image 30\n",
      "Process for image 31\n",
      "Process for image 32\n",
      "Process for image 33\n",
      "Process for image 34\n",
      "Process for image 35\n",
      "Process for image 36\n",
      "Process for image 37\n",
      "Process for image 38\n",
      "Process for image 39\n",
      "Process for image 40\n",
      "Process for image 41\n",
      "Process for image 42\n",
      "Process for image 43\n",
      "Process for image 44\n",
      "Process for image 45\n",
      "Process for image 46\n",
      "Process for image 47\n",
      "Process for image 48\n",
      "Process for image 49\n",
      "Process for image 50\n",
      "Process for image 51\n",
      "Process for image 52\n",
      "Process for image 53\n",
      "Process for image 54\n",
      "Process for image 55\n",
      "Process for image 56\n",
      "Process for image 57\n",
      "Process for image 58\n",
      "Process for image 59\n",
      "Process for image 60\n",
      "Process for image 61\n",
      "Process for image 62\n",
      "Process for image 63\n",
      "Process for image 64\n",
      "Process for image 65\n",
      "Process for image 66\n",
      "Process for image 67\n",
      "Process for image 68\n",
      "Process for image 69\n",
      "Process for image 70\n",
      "Process for image 71\n",
      "Process for image 72\n",
      "Process for image 73\n",
      "Process for image 74\n",
      "Process for image 75\n",
      "Process for image 76\n",
      "Process for image 77\n",
      "Process for image 78\n",
      "Process for image 79\n",
      "Process for image 80\n",
      "Process for image 81\n",
      "Process for image 82\n",
      "Process for image 83\n",
      "Process for image 84\n",
      "Process for image 85\n",
      "Process for image 86\n",
      "Process for image 87\n",
      "Process for image 88\n",
      "Process for image 89\n",
      "Process for image 90\n",
      "Process for image 91\n",
      "Process for image 92\n",
      "Process for image 93\n",
      "Process for image 94\n",
      "Process for image 95\n",
      "Process for image 96\n",
      "Process for image 97\n",
      "Process for image 98\n",
      "Process for image 99\n",
      "Process for image 100\n",
      "Process for image 101\n",
      "Process for image 102\n",
      "Process for image 103\n",
      "Process for image 104\n",
      "Process for image 105\n",
      "Process for image 106\n",
      "Process for image 107\n",
      "Process for image 108\n",
      "Process for image 109\n",
      "Process for image 110\n",
      "Process for image 111\n",
      "Process for image 112\n",
      "Process for image 113\n",
      "Process for image 114\n",
      "Process for image 115\n",
      "Process for image 116\n",
      "Process for image 117\n",
      "Process for image 118\n",
      "Process for image 119\n",
      "Process for image 120\n",
      "Process for image 121\n",
      "Process for image 122\n",
      "Process for image 123\n",
      "Process for image 124\n",
      "Process for image 125\n",
      "Process for image 126\n",
      "Process for image 127\n",
      "Process for image 128\n",
      "Process for image 129\n",
      "Process for image 130\n",
      "Process for image 131\n",
      "Process for image 132\n",
      "Process for image 133\n",
      "Process for image 134\n",
      "Process for image 135\n",
      "Process for image 136\n",
      "Process for image 137\n",
      "Process for image 138\n",
      "Process for image 139\n",
      "Process for image 140\n",
      "Process for image 141\n",
      "Process for image 142\n",
      "Process for image 143\n",
      "Process for image 144\n",
      "Process for image 145\n",
      "Process for image 146\n",
      "Process for image 147\n",
      "Process for image 148\n",
      "Process for image 149\n",
      "Process for image 150\n",
      "Process for image 151\n",
      "Process for image 152\n",
      "Process for image 153\n",
      "Process for image 154\n",
      "Process for image 155\n",
      "Process for image 156\n",
      "Process for image 157\n",
      "Process for image 158\n",
      "Process for image 159\n",
      "Process for image 160\n",
      "Process for image 161\n",
      "Process for image 162\n",
      "Process for image 163\n",
      "Process for image 164\n",
      "Process for image 165\n",
      "Process for image 166\n",
      "Process for image 167\n",
      "Process for image 168\n",
      "Process for image 169\n",
      "Process for image 170\n",
      "Process for image 171\n",
      "Process for image 172\n",
      "Process for image 173\n",
      "Process for image 174\n",
      "Process for image 175\n",
      "Process for image 176\n",
      "Process for image 177\n",
      "Process for image 178\n",
      "Process for image 179\n",
      "Process for image 180\n",
      "Process for image 181\n",
      "Process for image 182\n",
      "Process for image 183\n",
      "Process for image 184\n",
      "Process for image 185\n",
      "Process for image 186\n",
      "Process for image 187\n",
      "Process for image 188\n",
      "Process for image 189\n",
      "Process for image 190\n",
      "Process for image 191\n",
      "Process for image 192\n",
      "Process for image 193\n",
      "Process for image 194\n",
      "Process for image 195\n",
      "Process for image 196\n",
      "Process for image 197\n",
      "Process for image 198\n",
      "Process for image 199\n",
      "Process for image 200\n",
      "Process for image 201\n",
      "Process for image 202\n",
      "Process for image 203\n",
      "Process for image 204\n",
      "Process for image 205\n",
      "Process for image 206\n",
      "Process for image 207\n",
      "Process for image 208\n",
      "Process for image 209\n",
      "Process for image 210\n",
      "Process for image 211\n",
      "Process for image 212\n",
      "Process for image 213\n",
      "Process for image 214\n",
      "Process for image 215\n",
      "Process for image 216\n",
      "Process for image 217\n",
      "Process for image 218\n",
      "Process for image 219\n",
      "Process for image 220\n",
      "Process for image 221\n",
      "Process for image 222\n",
      "Process for image 223\n",
      "Process for image 224\n",
      "Process for image 225\n",
      "Process for image 226\n",
      "Process for image 227\n",
      "Process for image 228\n",
      "Process for image 229\n",
      "Process for image 230\n",
      "Process for image 231\n",
      "Process for image 232\n",
      "Process for image 233\n",
      "Process for image 234\n",
      "Process for image 235\n",
      "Process for image 236\n",
      "Process for image 237\n",
      "Process for image 238\n",
      "Process for image 239\n",
      "Process for image 240\n",
      "Process for image 241\n",
      "Process for image 242\n",
      "Process for image 243\n",
      "Process for image 244\n",
      "Process for image 245\n",
      "Process for image 246\n",
      "Process for image 247\n",
      "Process for image 248\n",
      "Process for image 249\n",
      "Total time: 913.8088672161102\n"
     ]
    }
   ],
   "source": [
    "veri_infer, mem_usage, time_cost = benchmark(test_images[:250], './tmp/', model_in_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(veri_infer, predicted_labels):\n",
    "    count = 0\n",
    "    for i in range(len(veri_infer)):\n",
    "        if veri_infer[i] != predicted_labels[i]:\n",
    "            count +=1\n",
    "            print (f\"Index {i} Not match!\")\n",
    "\n",
    "    return count/len(veri_infer)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = '../../benchmarks/benchmark_results.csv'\n",
    "\n",
    "columns = ['Framework', 'Architecture', '# Layers', '# Parameters', 'Testing Size', 'Accuracy Loss (%)', \n",
    "           'Avg Memory Usage (MB)', 'Std Memory Usage', 'Avg Proving Time (s)', 'Std Proving Time']\n",
    "\n",
    "# Check if the CSV file exists\n",
    "if not os.path.isfile(csv_path):\n",
    "    # Create a DataFrame with the specified columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv(csv_path, index=False)\n",
    "else:\n",
    "    print(f\"File '{csv_path}' already exists.\")\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 8 Not match!\n"
     ]
    }
   ],
   "source": [
    "new_row = {\n",
    "    'Framework': ['opml (pytorch)'],\n",
    "    'Architecture': ['Input-Dense-Dense (784 * 56 * 10)'],\n",
    "    '# Layers': [3],\n",
    "    '# Parameters': [44543],\n",
    "    'Testing Size': [len(veri_infer)],\n",
    "    'Accuracy Loss (%)': [calculate_loss(veri_infer, predicted_labels)],\n",
    "    'Avg Memory Usage (MB)': [sum(mem_usage) / len(mem_usage)],\n",
    "    'Std Memory Usage': [pd.Series(mem_usage).std()],\n",
    "    'Avg Proving Time (s)': [sum(time_cost) / len(time_cost)],\n",
    "    'Std Proving Time': [pd.Series(time_cost).std()]\n",
    "}\n",
    "\n",
    "new_row_df = pd.DataFrame(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_487671/2899595454.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Framework</th>\n",
       "      <th>Architecture</th>\n",
       "      <th># Layers</th>\n",
       "      <th># Parameters</th>\n",
       "      <th>Testing Size</th>\n",
       "      <th>Accuracy Loss (%)</th>\n",
       "      <th>Avg Memory Usage (MB)</th>\n",
       "      <th>Std Memory Usage</th>\n",
       "      <th>Avg Proving Time (s)</th>\n",
       "      <th>Std Proving Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opml (pytorch)</td>\n",
       "      <td>Input-Dense-Dense (784 * 56 * 10)</td>\n",
       "      <td>3</td>\n",
       "      <td>44543</td>\n",
       "      <td>250</td>\n",
       "      <td>0.4</td>\n",
       "      <td>88.998094</td>\n",
       "      <td>2.285579</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>0.440126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Framework                       Architecture # Layers # Parameters  \\\n",
       "0  opml (pytorch)  Input-Dense-Dense (784 * 56 * 10)        3        44543   \n",
       "\n",
       "  Testing Size  Accuracy Loss (%)  Avg Memory Usage (MB)  Std Memory Usage  \\\n",
       "0          250                0.4              88.998094          2.285579   \n",
       "\n",
       "   Avg Proving Time (s)  Std Proving Time  \n",
       "0              3.655122          0.440126  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
