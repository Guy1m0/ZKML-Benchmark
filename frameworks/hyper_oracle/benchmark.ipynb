{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, struct, os, psutil, subprocess, time, threading\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../models/input-dense-dense/784_56_10.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m784_56_10\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../models/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43march_folder\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m list_vars \u001b[38;5;241m=\u001b[39m state_dict\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load TensorFlow MNIST data\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../models/input-dense-dense/784_56_10.pth'"
     ]
    }
   ],
   "source": [
    "# TODO: use json file for model (results, config etc) management\n",
    "arch_folder = \"input-dense-dense/\"\n",
    "model_name = \"784_56_10\"\n",
    "model_path = \"../../models/\"\n",
    "\n",
    "state_dict = torch.load(model_path + arch_folder+ model_name + \".pth\")\n",
    "list_vars = state_dict\n",
    "\n",
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "test_images_pt = torch.tensor(test_images).float()\n",
    "# Flatten and normalize the images\n",
    "test_images_pt = test_images_pt.view(-1, 28*28) / 255.0  # Flatten and normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 56)  # Flatten 28*28 and feed into 56 neurons\n",
    "        self.fc2 = nn.Linear(56, num_classes)  # 56 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "    \n",
    "model_pt = Net()\n",
    "model_pt.load_state_dict(state_dict)\n",
    "model_pt.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Ensure gradients are not computed\n",
    "    predictions = model_pt(test_images_pt)\n",
    "    predicted_labels = predictions.argmax(dim=1)\n",
    "\n",
    "predicted_labels = predicted_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize and flatten the images\n",
    "train_images_tf = train_images.reshape((-1, 28*28)) / 255.0\n",
    "test_images_tf = test_images.reshape((-1, 28*28)) / 255.0\n",
    "\n",
    "# Convert to PyTorch format [batch_size, total pixels]\n",
    "# Since images are already normalized and flattened for TensorFlow, we can use the same arrays\n",
    "train_images_pt = torch.tensor(train_images_tf).float()\n",
    "test_images_pt = torch.tensor(test_images_tf).float()\n",
    "train_labels_pt = torch.tensor(train_labels)\n",
    "test_labels_pt = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the PyTorch model on the test images: 63.90000000%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create TensorDataset for test data\n",
    "test_dataset = TensorDataset(test_images_pt, test_labels_pt)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_pytorch_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the PyTorch model\n",
    "accuracy = evaluate_pytorch_model(model_pt, test_loader)\n",
    "print(f'Accuracy of the PyTorch model on the test images: {accuracy:.8f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./tmp/\"\n",
    "\n",
    "# Create the directory 'tmp' in the current working directory\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing variable: fc1.weight with shape:  (56, 784)\n",
      "Processing variable: fc1.bias with shape:  (56,)\n",
      "Processing variable: fc2.weight with shape:  (10, 56)\n",
      "Processing variable: fc2.bias with shape:  (10,)\n"
     ]
    }
   ],
   "source": [
    "fname_out = \"./bin/\" + arch_folder + \"ggml-model-\" + model_name + \".bin\"\n",
    "pack_fmt = \"!i\"\n",
    "\n",
    "os.makedirs(\"./bin/\" + arch_folder, exist_ok=True)\n",
    "\n",
    "fout = open(fname_out, \"w+b\")\n",
    "fout.write(struct.pack(pack_fmt, 0x67676d6c)) # magic: ggml in hex\n",
    "\n",
    "for name in list_vars.keys():\n",
    "    data = list_vars[name].squeeze().numpy()\n",
    "    print(\"Processing variable: \" + name + \" with shape: \", data.shape) \n",
    "    n_dims = len(data.shape)\n",
    "   \n",
    "    fout.write(struct.pack(pack_fmt, n_dims))\n",
    "    \n",
    "    data = data.astype(np.float32)\n",
    "    for i in range(n_dims):\n",
    "        fout.write(struct.pack(pack_fmt, data.shape[n_dims - 1 - i]))\n",
    "\n",
    "    # data\n",
    "    data = data.astype(\">f4\")\n",
    "    data.tofile(fout)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_from_file(data_file=\"input\", show=False):\n",
    "    try:\n",
    "        with open(data_file, 'rb') as file:\n",
    "            buf = file.read()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, e\n",
    "\n",
    "    digits = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    \n",
    "    if show:\n",
    "        c = \"\"\n",
    "        for row in range(28):\n",
    "            for col in range(28):\n",
    "                if buf[row * 28 + col] > 230:\n",
    "                    c += \"&\"\n",
    "                else:\n",
    "                    c += \"-\"\n",
    "            c += \"\\n\"\n",
    "        print(c)\n",
    "\n",
    "    return digits, None\n",
    "\n",
    "def save_img_to_file(image, data_file = \"input\"):\n",
    "    try:\n",
    "        # Convert to bytes\n",
    "        image_bytes = image.astype('uint8').tobytes()\n",
    "        \n",
    "        # Write to file\n",
    "        with open(data_file, 'wb') as file:\n",
    "            file.write(image_bytes)\n",
    "        \n",
    "        #print(f\"Image saved to {data_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_memory(pid, freq = 0.01):\n",
    "    p = psutil.Process(pid)\n",
    "    max_memory = 0\n",
    "    while True:\n",
    "        try:\n",
    "            mem = p.memory_info().rss / (1024 * 1024)\n",
    "            max_memory = max(max_memory, mem)\n",
    "        except psutil.NoSuchProcess:\n",
    "            break  # Process has finished\n",
    "        time.sleep(freq)  # Poll every second\n",
    "        \n",
    "    #print(f\"Maximum memory used: {max_memory} MB\")\n",
    "    return max_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 56\n",
    "img_out_path = folder + str(ind)\n",
    "save_img_to_file(test_images[ind], img_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_file = \"./bin/vm\"\n",
    "program = \"./bin/gglm.bin\"\n",
    "model_in_path = fname_out\n",
    "\n",
    "command = [f\"{vm_file}\", f\"--basedir={folder}\",\n",
    "                f\"--program={program}\", f\"--model={model_in_path}\", \n",
    "                f\"--data={img_out_path}\", \"--mipsVMCompatible\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process ID: 767774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Get the process ID\n",
    "pid = process.pid\n",
    "print(f\"Process ID: {pid}\")\n",
    "\n",
    "# Start memory monitoring in a separate thread\n",
    "monitor_thread = threading.Thread(target=monitor_memory, args=(pid,))\n",
    "monitor_thread.start()\n",
    "\n",
    "# Wait for the process to complete and capture output\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Wait for the monitoring thread to finish\n",
    "monitor_thread.join()\n",
    "\n",
    "stderr[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "---------&------------------\n",
      "---------&&-----------------\n",
      "--------&&&---------&&------\n",
      "--------&&----------&&------\n",
      "--------&&----------&&------\n",
      "--------&&---------&&-------\n",
      "--------&&---------&&-------\n",
      "--------&&---------&&-------\n",
      "-------&&&--------&&--------\n",
      "-------&&---------&&--------\n",
      "-------&&&&&&&&&&&&&--------\n",
      "-------&&&&&&&--&&&&--------\n",
      "------------------&---------\n",
      "-----------------&&---------\n",
      "-----------------&&---------\n",
      "-----------------&&---------\n",
      "----------------&&&---------\n",
      "----------------&&&---------\n",
      "----------------&&----------\n",
      "-----------------&----------\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "digits, error = load_img_from_file(img_out_path,show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def benchmark(test_images, tmp_folder, model_in_path, vm_file = \"./bin/vm\", program = \"./bin/gglm.bin\", threaded = True):\n",
    "    benchmark_start_time = time.time()\n",
    "    veri_infer = []\n",
    "    mem_usage = []\n",
    "    time_cost = []\n",
    "    for ind, img in enumerate(test_images):\n",
    "        img_out_path = tmp_folder + str(ind)\n",
    "        save_img_to_file(img, img_out_path)\n",
    "\n",
    "        # Exclusion of Pre-processing\n",
    "        start_time = time.time()\n",
    "        command = [f\"{vm_file}\", f\"--basedir={folder}\",\n",
    "                f\"--program={program}\", f\"--model={model_in_path}\", \n",
    "                f\"--data={img_out_path}\", \"--mipsVMCompatible\"]\n",
    "        \n",
    "        print (\"Process for image\", ind)\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Get the process ID\n",
    "        pid = process.pid\n",
    "\n",
    "        if threaded:\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                future = executor.submit(monitor_memory, pid)\n",
    "                _, stderr = process.communicate()\n",
    "                max_memory = future.result()\n",
    "                #print(f\"Maximum memory used in multi-threaded mode: {max_memory} bytes\")\n",
    "        else:\n",
    "            max_memory = monitor_memory(pid)  # Run in the same thread\n",
    "            _, stderr = process.communicate()\n",
    "            #print(f\"Maximum memory used in single-threaded mode: {max_memory} bytes\")\n",
    "        veri_infer.append(int(stderr[-2]))\n",
    "        mem_usage.append(max_memory)\n",
    "        time_cost.append(time.time() - start_time)\n",
    "    \n",
    "    print (\"Total time:\", time.time() - benchmark_start_time)\n",
    "    #print (\"total mem:\", sum(mem))\n",
    "    return veri_infer, mem_usage, time_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process for image 0\n",
      "Process for image 1\n",
      "Process for image 2\n",
      "Process for image 3\n",
      "Process for image 4\n",
      "Process for image 5\n",
      "Process for image 6\n",
      "Process for image 7\n",
      "Process for image 8\n",
      "Process for image 9\n",
      "Process for image 10\n",
      "Process for image 11\n",
      "Process for image 12\n",
      "Process for image 13\n",
      "Process for image 14\n",
      "Process for image 15\n",
      "Process for image 16\n",
      "Process for image 17\n",
      "Process for image 18\n",
      "Process for image 19\n",
      "Total time: 77.32435870170593\n"
     ]
    }
   ],
   "source": [
    "veri_infer, mem_usage, time_cost = benchmark(test_images[:20], './tmp/', model_in_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(veri_infer, predicted_labels):\n",
    "    count = 0\n",
    "    for i in range(len(veri_infer)):\n",
    "        if veri_infer[i] != predicted_labels[i]:\n",
    "            count +=1\n",
    "            print (f\"Index {i} Not match!\")\n",
    "\n",
    "    return count/len(veri_infer)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 9 Not match!\n",
      "Index 16 Not match!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(veri_infer, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../../benchmarks/benchmark_results.csv' already exists.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = '../../benchmarks/benchmark_results.csv'\n",
    "\n",
    "columns = ['Framework', 'Architecture', '# Layers', '# Parameters', 'Testing Size', 'Accuracy Loss (%)', \n",
    "           'Avg Memory Usage (MB)', 'Std Memory Usage', 'Avg Proving Time (s)', 'Std Proving Time']\n",
    "\n",
    "# Check if the CSV file exists\n",
    "if not os.path.isfile(csv_path):\n",
    "    # Create a DataFrame with the specified columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv(csv_path, index=False)\n",
    "else:\n",
    "    print(f\"File '{csv_path}' already exists.\")\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 9 Not match!\n",
      "Index 16 Not match!\n",
      "Index 20 Not match!\n",
      "Index 23 Not match!\n",
      "Index 25 Not match!\n",
      "Index 33 Not match!\n",
      "Index 34 Not match!\n",
      "Index 45 Not match!\n",
      "Index 52 Not match!\n",
      "Index 53 Not match!\n",
      "Index 55 Not match!\n",
      "Index 58 Not match!\n",
      "Index 62 Not match!\n",
      "Index 63 Not match!\n",
      "Index 66 Not match!\n",
      "Index 73 Not match!\n",
      "Index 78 Not match!\n",
      "Index 92 Not match!\n",
      "Index 105 Not match!\n",
      "Index 108 Not match!\n",
      "Index 118 Not match!\n",
      "Index 119 Not match!\n",
      "Index 120 Not match!\n",
      "Index 126 Not match!\n",
      "Index 129 Not match!\n",
      "Index 136 Not match!\n",
      "Index 149 Not match!\n",
      "Index 150 Not match!\n",
      "Index 151 Not match!\n",
      "Index 152 Not match!\n",
      "Index 153 Not match!\n",
      "Index 155 Not match!\n",
      "Index 158 Not match!\n",
      "Index 165 Not match!\n",
      "Index 175 Not match!\n",
      "Index 182 Not match!\n",
      "Index 185 Not match!\n",
      "Index 187 Not match!\n",
      "Index 194 Not match!\n",
      "Index 206 Not match!\n",
      "Index 209 Not match!\n",
      "Index 211 Not match!\n",
      "Index 214 Not match!\n",
      "Index 215 Not match!\n",
      "Index 217 Not match!\n",
      "Index 218 Not match!\n",
      "Index 219 Not match!\n",
      "Index 233 Not match!\n",
      "Index 234 Not match!\n",
      "Index 237 Not match!\n",
      "Index 240 Not match!\n",
      "Index 246 Not match!\n",
      "Index 247 Not match!\n",
      "Index 249 Not match!\n",
      "Index 252 Not match!\n",
      "Index 256 Not match!\n",
      "Index 257 Not match!\n",
      "Index 261 Not match!\n",
      "Index 280 Not match!\n",
      "Index 283 Not match!\n",
      "Index 289 Not match!\n",
      "Index 290 Not match!\n",
      "Index 294 Not match!\n",
      "Index 305 Not match!\n",
      "Index 307 Not match!\n",
      "Index 313 Not match!\n",
      "Index 315 Not match!\n",
      "Index 317 Not match!\n",
      "Index 318 Not match!\n",
      "Index 319 Not match!\n",
      "Index 321 Not match!\n",
      "Index 322 Not match!\n",
      "Index 336 Not match!\n",
      "Index 344 Not match!\n",
      "Index 346 Not match!\n",
      "Index 351 Not match!\n",
      "Index 352 Not match!\n",
      "Index 356 Not match!\n",
      "Index 359 Not match!\n",
      "Index 363 Not match!\n",
      "Index 364 Not match!\n",
      "Index 365 Not match!\n",
      "Index 367 Not match!\n",
      "Index 372 Not match!\n",
      "Index 380 Not match!\n",
      "Index 386 Not match!\n",
      "Index 389 Not match!\n",
      "Index 394 Not match!\n",
      "Index 395 Not match!\n",
      "Index 403 Not match!\n",
      "Index 406 Not match!\n",
      "Index 407 Not match!\n",
      "Index 417 Not match!\n",
      "Index 422 Not match!\n",
      "Index 424 Not match!\n",
      "Index 433 Not match!\n",
      "Index 441 Not match!\n",
      "Index 443 Not match!\n",
      "Index 449 Not match!\n",
      "Index 453 Not match!\n",
      "Index 459 Not match!\n",
      "Index 460 Not match!\n",
      "Index 465 Not match!\n",
      "Index 468 Not match!\n",
      "Index 478 Not match!\n",
      "Index 487 Not match!\n",
      "Index 488 Not match!\n",
      "Index 490 Not match!\n",
      "Index 491 Not match!\n",
      "Index 495 Not match!\n",
      "Index 498 Not match!\n",
      "Index 507 Not match!\n",
      "Index 509 Not match!\n",
      "Index 511 Not match!\n",
      "Index 516 Not match!\n",
      "Index 522 Not match!\n",
      "Index 524 Not match!\n",
      "Index 528 Not match!\n",
      "Index 530 Not match!\n",
      "Index 538 Not match!\n",
      "Index 540 Not match!\n",
      "Index 542 Not match!\n",
      "Index 543 Not match!\n",
      "Index 545 Not match!\n",
      "Index 551 Not match!\n",
      "Index 552 Not match!\n",
      "Index 558 Not match!\n",
      "Index 567 Not match!\n",
      "Index 569 Not match!\n",
      "Index 570 Not match!\n",
      "Index 575 Not match!\n",
      "Index 588 Not match!\n",
      "Index 593 Not match!\n",
      "Index 595 Not match!\n",
      "Index 598 Not match!\n",
      "Index 603 Not match!\n",
      "Index 604 Not match!\n",
      "Index 608 Not match!\n",
      "Index 612 Not match!\n",
      "Index 613 Not match!\n",
      "Index 618 Not match!\n",
      "Index 619 Not match!\n",
      "Index 630 Not match!\n",
      "Index 635 Not match!\n",
      "Index 639 Not match!\n",
      "Index 641 Not match!\n",
      "Index 645 Not match!\n",
      "Index 656 Not match!\n",
      "Index 658 Not match!\n",
      "Index 659 Not match!\n",
      "Index 671 Not match!\n",
      "Index 673 Not match!\n",
      "Index 674 Not match!\n",
      "Index 678 Not match!\n",
      "Index 684 Not match!\n",
      "Index 707 Not match!\n",
      "Index 713 Not match!\n",
      "Index 714 Not match!\n",
      "Index 720 Not match!\n",
      "Index 721 Not match!\n",
      "Index 739 Not match!\n",
      "Index 740 Not match!\n",
      "Index 750 Not match!\n",
      "Index 751 Not match!\n",
      "Index 763 Not match!\n",
      "Index 766 Not match!\n",
      "Index 778 Not match!\n",
      "Index 781 Not match!\n",
      "Index 785 Not match!\n",
      "Index 791 Not match!\n",
      "Index 797 Not match!\n",
      "Index 800 Not match!\n",
      "Index 801 Not match!\n",
      "Index 812 Not match!\n",
      "Index 813 Not match!\n",
      "Index 821 Not match!\n",
      "Index 829 Not match!\n",
      "Index 830 Not match!\n",
      "Index 833 Not match!\n",
      "Index 854 Not match!\n",
      "Index 856 Not match!\n",
      "Index 866 Not match!\n",
      "Index 869 Not match!\n",
      "Index 874 Not match!\n",
      "Index 876 Not match!\n",
      "Index 881 Not match!\n",
      "Index 885 Not match!\n",
      "Index 895 Not match!\n",
      "Index 896 Not match!\n",
      "Index 897 Not match!\n",
      "Index 898 Not match!\n",
      "Index 909 Not match!\n",
      "Index 915 Not match!\n",
      "Index 924 Not match!\n",
      "Index 932 Not match!\n",
      "Index 934 Not match!\n",
      "Index 939 Not match!\n",
      "Index 947 Not match!\n",
      "Index 951 Not match!\n",
      "Index 956 Not match!\n",
      "Index 959 Not match!\n",
      "Index 962 Not match!\n",
      "Index 965 Not match!\n",
      "Index 970 Not match!\n",
      "Index 972 Not match!\n",
      "Index 978 Not match!\n",
      "Index 982 Not match!\n",
      "Index 992 Not match!\n",
      "Index 999 Not match!\n"
     ]
    }
   ],
   "source": [
    "new_row = {\n",
    "    'Framework': ['opml (pytorch)'],\n",
    "    'Architecture': ['Input-Dense-Dense (784 * 56 * 10, w/ relu)'],\n",
    "    '# Layers': [3],\n",
    "    '# Parameters': [44543],\n",
    "    'Testing Size': [len(veri_infer)],\n",
    "    'Accuracy Loss (%)': [calculate_loss(veri_infer, predicted_labels)],\n",
    "    'Avg Memory Usage (MB)': [sum(mem_usage) / len(mem_usage)],\n",
    "    'Std Memory Usage': [pd.Series(mem_usage).std()],\n",
    "    'Avg Proving Time (s)': [sum(time_cost) / len(time_cost)],\n",
    "    'Std Proving Time': [pd.Series(time_cost).std()]\n",
    "}\n",
    "\n",
    "new_row_df = pd.DataFrame(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Framework</th>\n",
       "      <th>Architecture</th>\n",
       "      <th># Layers</th>\n",
       "      <th># Parameters</th>\n",
       "      <th>Testing Size</th>\n",
       "      <th>Accuracy Loss (%)</th>\n",
       "      <th>Avg Memory Usage (MB)</th>\n",
       "      <th>Std Memory Usage</th>\n",
       "      <th>Avg Proving Time (s)</th>\n",
       "      <th>Std Proving Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opml (pytorch)</td>\n",
       "      <td>Input-Dense-Dense (784 * 56 * 10)</td>\n",
       "      <td>3</td>\n",
       "      <td>44543</td>\n",
       "      <td>250</td>\n",
       "      <td>0.4</td>\n",
       "      <td>88.998094</td>\n",
       "      <td>2.285579</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>0.440126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opml (pytorch)</td>\n",
       "      <td>Input-Dense-Dense (784 * 56 * 10, w/ relu)</td>\n",
       "      <td>3</td>\n",
       "      <td>44543</td>\n",
       "      <td>1000</td>\n",
       "      <td>20.9</td>\n",
       "      <td>89.122078</td>\n",
       "      <td>2.247846</td>\n",
       "      <td>3.664727</td>\n",
       "      <td>0.433921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Framework                                Architecture  # Layers  \\\n",
       "0  opml (pytorch)           Input-Dense-Dense (784 * 56 * 10)         3   \n",
       "1  opml (pytorch)  Input-Dense-Dense (784 * 56 * 10, w/ relu)         3   \n",
       "\n",
       "   # Parameters  Testing Size  Accuracy Loss (%)  Avg Memory Usage (MB)  \\\n",
       "0         44543           250                0.4              88.998094   \n",
       "1         44543          1000               20.9              89.122078   \n",
       "\n",
       "   Std Memory Usage  Avg Proving Time (s)  Std Proving Time  \n",
       "0          2.285579              3.655122          0.440126  \n",
       "1          2.247846              3.664727          0.433921  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
