{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 18:05:05.382921: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-02 18:05:05.403004: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-02 18:05:05.403025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-02 18:05:05.403521: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-02 18:05:05.406915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-02 18:05:05.795555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test 196_25_10 DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 14 * 14\n",
    "layer_1 = 25\n",
    "n_class = 10\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(input_size,))\n",
    "out = tf.keras.layers.Dense(layer_1)(inputs)\n",
    "out = tf.keras.layers.ReLU()(out) # not support dor dense layer\n",
    "out = tf.keras.layers.Dense(n_class)(out)\n",
    "#out = Softmax()(out)\n",
    "model = tf.keras.Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 196)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25)                4925      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 25)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5185 (20.25 KB)\n",
      "Trainable params: 5185 (20.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../../models/\"\n",
    "arch_folder = \"input-dense-dense/\"\n",
    "model_name = \"c_aware_196_25_10.h5\"\n",
    "model_in_path = model_path+arch_folder+model_name\n",
    "\n",
    "model.load_weights(model_in_path)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize and flatten the images\n",
    "train_images_tf = train_images.reshape((-1, 28*28)) / 255.0\n",
    "test_images_tf = test_images.reshape((-1, 28*28)) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize for 14 * 14 images\n",
    "train_images_tf_reshaped = tf.reshape(train_images_tf, [-1, 28, 28, 1])  # Reshape to [num_samples, height, width, channels]\n",
    "test_images_tf_reshaped = tf.reshape(test_images_tf, [-1, 28, 28, 1])\n",
    "\n",
    "# Downsample images\n",
    "train_images_tf_downsampled = tf.image.resize(train_images_tf_reshaped, [14, 14], method='bilinear')\n",
    "test_images_tf_downsampled = tf.image.resize(test_images_tf_reshaped, [14, 14], method='bilinear')\n",
    "\n",
    "# Flatten the images back to [num_samples, 14*14]\n",
    "train_images_tf = tf.reshape(train_images_tf_downsampled, [-1, 14*14])\n",
    "test_images_tf = tf.reshape(test_images_tf_downsampled, [-1, 14*14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.8117 - accuracy: 0.9541 - 350ms/epoch - 1ms/step\n",
      "\n",
      "Test accuracy: 0.9541000127792358\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images_tf, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 21888242871839275222246405745257275088548364400416034343698204186575808495617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(layers, model, scalar = 36):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for ind in range(len(layers)-1):\n",
    "        w = [[int(model.weights[ind * 2].numpy()[i][j]*10**scalar) for j in range(layers[ind+1])] for i in range(layers[ind])]\n",
    "        b = [int(model.weights[ind * 2 + 1].numpy()[i]*10**(scalar * 2)) for i in range(layers[ind+1])]\n",
    "        \n",
    "        weights.append(w)\n",
    "        biases.append(b)\n",
    "\n",
    "    return weights, biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = transfer_weights([196,25,10], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-124483436346054082331709472319209472,\n",
       " -266745209693908690992144174381268992,\n",
       " 125370115041732800785437157077549056,\n",
       " 119624227285385135013574016348717056,\n",
       " -385843664407730101924536114693013504,\n",
       " -360206186771392871887340280444092416,\n",
       " 222950249910354639194961063352205312,\n",
       " 61239928007125854950088778125934592,\n",
       " 166527777910232544193034274289483776,\n",
       " 408954054117202740136896037186961408]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_mod(x):\n",
    "    return x if x < p // 2 else 0\n",
    "\n",
    "def DenseInt(nInputs, nOutputs, n, input, weights, bias):\n",
    "    #print (len(input), nInputs)\n",
    "    \n",
    "    Input = [str(input[i] % p) for i in range(nInputs)]\n",
    "    Weights = [[str(weights[i][j] % p) for j in range(nOutputs)] for i in range(nInputs)]\n",
    "    Bias = [str(bias[i] % p) for i in range(nOutputs)]\n",
    "    \n",
    "    out = [0 for _ in range(nOutputs)]\n",
    "    remainder = [None for _ in range(nOutputs)]\n",
    "    \n",
    "    for j in range(nOutputs):\n",
    "        for i in range(nInputs):\n",
    "            out[j] += input[i] * weights[i][j]\n",
    "        out[j] += bias[j]\n",
    "\n",
    "        remainder[j] = str(out[j] % n)\n",
    "        out[j] = out[j] // n % p\n",
    "        \n",
    "    return Input, Weights, Bias, out, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseInt_(nInputs, nOutputs, n, input, weights, bias):\n",
    "    Input = [str(input[i] % p) for i in range(nInputs)]\n",
    "    Weights = [[str(weights[i][j] % p) for j in range(nOutputs)] for i in range(nInputs)]\n",
    "    Bias = [str(bias[i] % p) for i in range(nOutputs)]\n",
    "\n",
    "    out = [0 for _ in range(nOutputs)]\n",
    "    remainder = [None for _ in range(nOutputs)]\n",
    "    \n",
    "    for j in range(nOutputs):\n",
    "        for i in range(nInputs):\n",
    "            out[j] += input[i] * weights[i][j]\n",
    "        out[j] += bias[j]\n",
    "        remainder[j] = str(out[j] % n)\n",
    "        out[j] = str(out[j] // n % p)\n",
    "        \n",
    "    return Input, Weights, Bias, out, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_json(layers, weights, biases, x_in, scalar=36, relu = False):\n",
    "    relu_outs = []\n",
    "    dense_weights = []\n",
    "    dense_biases = []\n",
    "    dense_outs = []\n",
    "    dense_remainders = []\n",
    "    x_ins = []\n",
    "\n",
    "    out = x_in\n",
    "    for ind in range(len(weights)):\n",
    "        nInputs = layers[ind]\n",
    "        nOutputs = layers[ind + 1]\n",
    "        #print (nInputs, nOutputs)\n",
    "        x_in, w, b, out, rem = DenseInt(nInputs, nOutputs, 10 ** scalar, \n",
    "                                     out, weights[ind], biases[ind])\n",
    "        \n",
    "        dense_outs.append(out)\n",
    "        if relu:\n",
    "            out = [x if x < p//2 else 0 for x in out]\n",
    "            relu_outs.append([str(x) for x in out])\n",
    "\n",
    "        #print (out)\n",
    "        dense_weights.append(w)\n",
    "        dense_biases.append(b)\n",
    "        \n",
    "        dense_remainders.append(rem)\n",
    "        x_ins.append(x_in)\n",
    "\n",
    "    dense_outs = [[str(x) for x in sub] for sub in dense_outs]\n",
    "        \n",
    "    return x_ins[0], dense_weights, dense_biases, dense_outs, dense_remainders, relu_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 56)                43960     \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 56)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 10)                570       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44530 (173.95 KB)\n",
      "Trainable params: 44530 (173.95 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = [784, 56, 10]\n",
    "inputs = tf.keras.layers.Input(shape=(784,))\n",
    "out = tf.keras.layers.Dense(56)(inputs)\n",
    "out = tf.keras.layers.ReLU()(out) # not support dor dense layer\n",
    "out = tf.keras.layers.Dense(10)(out)\n",
    "#out = Softmax()(out)\n",
    "\n",
    "simple_model = tf.keras.Model(inputs, out)\n",
    "\n",
    "simple_model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(1,784)\n",
    "\n",
    "X_in = [int(x*1e36) for x in X[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = transfer_weights(layers, simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21888242871839275222246405745257275088547712741010285124653134685975492047989',\n",
       " '64461780081078897374926454874303670',\n",
       " '206099086914864141015720331481235453',\n",
       " '301288055733862308976226566011151968',\n",
       " '21888242871839275222246405745257275088548082637687730584578687394167161939996',\n",
       " '21872647421375424758135125470329348',\n",
       " '74987286570992543954090709101517465',\n",
       " '21888242871839275222246405745257275088547587655272012960865672758172769230540',\n",
       " '1111638609321312424540851124796407115',\n",
       " '1855937309942566737994135755662048055']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in, dense_weights, dense_biases, dense_outs, dense_remainders, relu_outs = prepare_input_json(layers, weights, biases, X_in, relu=True)\n",
    "dense_outs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in, Dense32weights, Dense32bias, Dense32out, Dense32remainder = DenseInt_(784,56, 10**36, X_in, weights[0], biases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReLUout = [Dense32out[i] if int(Dense32out[i]) < p//2 else 0 for i in range(56)]\n",
    "Dense21in = [int(ReLUout[i]) for i in range(56)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21888242871839275222246405745257275088547712741010285124653134685975492047989',\n",
       " '64461780081078897374926454874303670',\n",
       " '206099086914864141015720331481235453',\n",
       " '301288055733862308976226566011151968',\n",
       " '21888242871839275222246405745257275088548082637687730584578687394167161939996',\n",
       " '21872647421375424758135125470329348',\n",
       " '74987286570992543954090709101517465',\n",
       " '21888242871839275222246405745257275088547587655272012960865672758172769230540',\n",
       " '1111638609321312424540851124796407115',\n",
       " '1855937309942566737994135755662048055']"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, Dense21weights, Dense21bias, Dense21out, Dense21remainder = DenseInt_(56, 10, 10**36, Dense21in, weights[1], biases[1])\n",
    "Dense21out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.6516593 ,  0.06446189,  0.2060991 ,  0.30128804, -0.28176275,\n",
       "         0.02187276,  0.07498729, -0.7767452 ,  1.1116385 ,  1.8559372 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "in_json = {\n",
    "    \"in\": x_in,\n",
    "    \"Dense32weights\": dense_weights[0],\n",
    "    \"Dense32bias\": dense_biases[0],\n",
    "    \"Dense32out\": dense_outs[0],\n",
    "    \"Dense32remainder\": dense_remainders[0],\n",
    "    \"ReLUout\": relu_outs[0], \n",
    "    \"Dense21weights\": dense_weights[1],\n",
    "    \"Dense21bias\": dense_biases[1],\n",
    "    \"Dense21out\": dense_outs[1],\n",
    "    \"Dense21remainder\": dense_remainders[1]\n",
    "}\n",
    "\n",
    "\n",
    "with open(\"./tmp/input.json\", \"w\") as f:\n",
    "    json.dump(in_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " '1740378166542656759482186281727063207',\n",
       " 0,\n",
       " '665993099727507384065029260156218697',\n",
       " 0,\n",
       " '69577348329897550250554733933848429',\n",
       " 0,\n",
       " '1476298976826797441633872004018772249',\n",
       " 0,\n",
       " 0,\n",
       " '944210392939385517650387649480375792',\n",
       " '356518878668041190610455646138776409',\n",
       " '566602428580131055096567038447823438',\n",
       " '1097513366205503365421702612922238755',\n",
       " '835816972746304142909475253183466632',\n",
       " 0,\n",
       " 0,\n",
       " '1099273191099292480449694720932948965',\n",
       " 0,\n",
       " '144493945312701031958715819998514811',\n",
       " 0,\n",
       " '160947886835453079542876893767116428',\n",
       " 0,\n",
       " 0,\n",
       " '739017511639276095775829576274234224',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '757892442836530559228984227040716457',\n",
       " '415601943532006337034280277131910761',\n",
       " '12310543291558788459229224797328546',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '452743524094830236747848819391631502',\n",
       " 0,\n",
       " '1293160281003872094798548686074372589',\n",
       " 0,\n",
       " 0,\n",
       " '115641193966956731293473882435038396',\n",
       " 0,\n",
       " '729732199508907024481784595377895346',\n",
       " 0,\n",
       " '127914070154402518361126973111992041',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '977306076171245541660415555219444027',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1272357048884769863525607911958459741']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLUout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1740378166542656759482186281727063207',\n",
       " '0',\n",
       " '665993099727507384065029260156218697',\n",
       " '0',\n",
       " '69577348329897550250554733933848429',\n",
       " '0',\n",
       " '1476298976826797441633872004018772249',\n",
       " '0',\n",
       " '0',\n",
       " '944210392939385517650387649480375792',\n",
       " '356518878668041190610455646138776409',\n",
       " '566602428580131055096567038447823438',\n",
       " '1097513366205503365421702612922238755',\n",
       " '835816972746304142909475253183466632',\n",
       " '0',\n",
       " '0',\n",
       " '1099273191099292480449694720932948965',\n",
       " '0',\n",
       " '144493945312701031958715819998514811',\n",
       " '0',\n",
       " '160947886835453079542876893767116428',\n",
       " '0',\n",
       " '0',\n",
       " '739017511639276095775829576274234224',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '757892442836530559228984227040716457',\n",
       " '415601943532006337034280277131910761',\n",
       " '12310543291558788459229224797328546',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '452743524094830236747848819391631502',\n",
       " '0',\n",
       " '1293160281003872094798548686074372589',\n",
       " '0',\n",
       " '0',\n",
       " '115641193966956731293473882435038396',\n",
       " '0',\n",
       " '729732199508907024481784595377895346',\n",
       " '0',\n",
       " '127914070154402518361126973111992041',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '977306076171245541660415555219444027',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1272357048884769863525607911958459741']"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_outs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.201047  ,  0.84194046, -0.3172891 ,  1.0736947 , -1.0347209 ,\n",
       "        -0.389936  ,  0.96934855,  0.91301656,  0.27011284, -0.561428  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil, time, threading, subprocess\n",
    "def monitor_memory(pid, freq = 0.01):\n",
    "    p = psutil.Process(pid)\n",
    "    max_memory = 0\n",
    "    while True:\n",
    "        try:\n",
    "            mem = p.memory_info().rss / (1024 * 1024)\n",
    "            max_memory = max(max_memory, mem)\n",
    "        except psutil.NoSuchProcess:\n",
    "            break  # Process has finished\n",
    "        time.sleep(freq)  # Poll every second\n",
    "        \n",
    "    print(f\"Maximum memory used: {max_memory} MB\")\n",
    "    return max_memory\n",
    "\n",
    "def run_bash(command):\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    # Get the process ID\n",
    "    pid = process.pid\n",
    "    print(f\"Process ID: {pid}\")\n",
    "\n",
    "    # Start memory monitoring in a separate thread\n",
    "    monitor_thread = threading.Thread(target=monitor_memory, args=(pid,))\n",
    "    monitor_thread.start()\n",
    "\n",
    "    # Wait for the process to complete and capture output\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    # Wait for the monitoring thread to finish\n",
    "    monitor_thread.join()\n",
    "    return stdout, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "circuit_folder = \"./golden_circuits/\"\n",
    "target_circom = \"784_56_10.circom\"\n",
    "target_folder = \"./tmp/\"\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "command = ['circom', circuit_folder + target_circom, \"--r1cs\", \"--wasm\", \"--sym\", \"-o\", target_folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mtemplate instances\u001b[0m: 15\n",
      "non-linear constraints: 73416\n",
      "linear constraints: 0\n",
      "public inputs: 0\n",
      "private inputs: 45502 (45380 belong to witness)\n",
      "public outputs: 10\n",
      "wires: 118629\n",
      "labels: 460243\n",
      "\u001b[32mWritten successfully:\u001b[0m ./tmp/784_56_10.r1cs\n",
      "\u001b[32mWritten successfully:\u001b[0m ./tmp/784_56_10.sym\n",
      "\u001b[32mWritten successfully:\u001b[0m ./tmp/784_56_10_js/784_56_10.wasm\n",
      "\u001b[32mEverything went okay\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['circom', './golden_circuits/784_56_10.circom', '--r1cs', '--wasm', '--sym', '-o', './tmp'], returncode=0)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = target_folder + target_circom[:-7] + \"_js/\"\n",
    "wit_file = json_folder + \"generate_witness.js\"\n",
    "wasm_file = json_folder + target_circom[:-7] + \".wasm\"\n",
    "input_path = target_folder + \"input.json\"\n",
    "\n",
    "command = ['node', wit_file, wasm_file, input_path, target_folder + \"witness.wtns\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['node',\n",
       " './tmp/784_56_10_js/generate_witness.js',\n",
       " './tmp/784_56_10_js/784_56_10.wasm',\n",
       " './tmp/input.json',\n",
       " './tmp/witness.wtns']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['node', './tmp/784_56_10_js/generate_witness.js', './tmp/784_56_10_js/784_56_10.wasm', './tmp/input.json', './tmp/witness.wtns'], returncode=0)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.05200598,  0.18067959, -1.1555531 , -0.4750196 , -0.50847775,\n",
       "         0.6045419 , -1.0021639 ,  0.38748404,  0.20723125, -0.13139105]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 04:44:02.687455: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-01 04:44:02.720314: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-01 04:44:02.720339: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-01 04:44:02.721000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-01 04:44:02.725827: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-01 04:44:03.349466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize and flatten the images\n",
    "train_images_tf = train_images.reshape((-1, 28*28)) / 255.0\n",
    "test_images_tf = test_images.reshape((-1, 28*28)) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model_tf = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28*28,)),  # Adjusted for 28x28 images\n",
    "    #keras.layers.Dense(128, activation='relu'),     # Increased number of neurons\n",
    "    keras.layers.Dense(56),      # Additional hidden layer\n",
    "    keras.layers.Dense(num_classes)  # Output layer for 10 classes\n",
    "])\n",
    "\n",
    "# model_tf.compile(optimizer='adam', \n",
    "#               loss='sparse_categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = tf.keras.models.load_model(model_path+arch_folder+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3146 - accuracy: 0.9234 - 217ms/epoch - 694us/step\n",
      "\n",
      "Test accuracy: 0.9233999848365784\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_tf.evaluate(test_images_tf, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming test_images_tf is your flattened and normalized test dataset\n",
    "scaled_test_images_tf = np.array([int(x * 1e36) for x in test_images_tf.flatten()]).reshape(test_images_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the weights and biases\n",
    "weights = []\n",
    "biases= []\n",
    "\n",
    "for layer in model_tf.layers:\n",
    "    #print ('new layer')\n",
    "    weight, bias = layer.get_weights()\n",
    "    scaled_weights = weight * 1e36\n",
    "    scaled_biases = bias * 1e72\n",
    "    weights.append(scaled_weights)\n",
    "    biases.append(scaled_biases)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using relu for dense layer is not supported by keras2circom\n",
    "def relu_mod(x, p):\n",
    "    return x if x < p // 2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseInt(nInputs, nOutputs, n, input, weights, bias, act = False):\n",
    "    Input = [str(input[i] % p) for i in range(nInputs)]\n",
    "    Weights = [[str(weights[i][j] % p) for j in range(nOutputs)] for i in range(nInputs)]\n",
    "    Bias = [str(bias[i] % p) for i in range(nOutputs)]\n",
    "\n",
    "    out = [0 for _ in range(nOutputs)]\n",
    "    remainder = [None for _ in range(nOutputs)]\n",
    "    \n",
    "    for j in range(nOutputs):\n",
    "        for i in range(nInputs):\n",
    "            out[j] += int(input[i] * weights[i][j])\n",
    "        out[j] += int(bias[j])\n",
    "\n",
    "        remainder[j] = str(out[j] % n)\n",
    "        out[j] = out[j] // n % p\n",
    "\n",
    "    if act:\n",
    "        out = [int(relu_mod(out[i], p)) for i in range(nOutputs)]\n",
    "\n",
    "    return Input, Weights, Bias, out, remainder    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 6\n",
    "X = test_images_tf[ind:ind+1]\n",
    "print (X.shape)\n",
    "pred = model_tf.predict(X)\n",
    "X_in = scaled_test_images_tf[ind]\n",
    "\n",
    "np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-9.5329070e-01,  1.4292629e+00, -8.4842488e-02,  2.8307574e+00,\n",
       "        -2.3221037e+00,  7.0742428e-02,  5.5277711e-01,  6.6419549e-02,\n",
       "        -1.0973787e-01,  1.1209676e+00, -3.1638861e-01, -1.3844252e+00,\n",
       "        -5.3046063e-02, -1.2403058e+00, -1.1619565e+00, -7.9521552e-02,\n",
       "        -3.3932751e-01,  8.1592131e-01, -3.9168000e-01,  4.8189560e-01,\n",
       "        -6.7942822e-01,  1.8367920e+00,  1.0939014e-01,  5.4528899e+00,\n",
       "        -2.8391507e-01,  2.5883527e+00, -1.7390031e-01, -2.0343879e-01,\n",
       "         8.3122027e-01,  2.7671874e-01, -1.0484387e+00, -1.5784721e-01,\n",
       "        -1.2740493e+00, -7.4017096e-01, -6.7795044e-01,  2.8966603e+00,\n",
       "        -1.0565984e+00,  6.9625092e-01, -7.3894083e-01, -5.9243518e-01,\n",
       "        -1.1391294e-01, -6.9581002e-02,  6.0503864e-01,  1.1942644e+00,\n",
       "        -2.2848437e+00,  6.9404769e-01,  2.3846364e-01, -1.1942775e+00,\n",
       "        -1.7259982e-01, -1.9012207e-01, -3.2332522e-01, -1.1359926e+00,\n",
       "         3.0215591e-02, -1.9402095e+00, -2.0712204e-01, -3.3997297e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Assuming model_tf is your original model\n",
    "# Extract the output of the second-to-last layer (the last dense layer before softmax)\n",
    "layer_output = model_tf.layers[0].output\n",
    "\n",
    "# Create a new model that gives the output of the last dense layer\n",
    "intermediate_model = keras.Model(inputs=model_tf.input, outputs=layer_output)\n",
    "\n",
    "intermediate_model.predict(X.reshape(1, -1))  # Reshape if necessary\n",
    "\n",
    "# 'output' now contains the output of the last dense layer before softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21888242871839275222246405745257275088547411109553182693019696267136279654625,\n",
       " 1429262742189608892055161120894574842,\n",
       " 21888242871839275222246405745257275088548279557790178464889343021438897624709,\n",
       " 2830757570204967967106890586558348539,\n",
       " 21888242871839275222246405745257275088546042296642297433340719353032481935672,\n",
       " 70742345249902255278650529196150687,\n",
       " 552776922231622311446666213875167399,\n",
       " 66419575272351726118602312065397687,\n",
       " 21888242871839275222246405745257275088548254662601433364243537257700439099999,\n",
       " 1120967573676751623773976896854759091,\n",
       " 21888242871839275222246405745257275088548048011794087370785156376648925069369,\n",
       " 21888242871839275222246405745257275088546979975406822561717231158235568905148,\n",
       " 21888242871839275222246405745257275088548311354453930159128493724373476611933,\n",
       " 21888242871839275222246405745257275088547124094657919326189376498548964114087,\n",
       " 21888242871839275222246405745257275088547202443968568112703218216218499619314,\n",
       " 21888242871839275222246405745257275088548284879099959031457116383991623394800,\n",
       " 21888242871839275222246405745257275088548025072887603462153558588640781509594,\n",
       " 815921343370741701672677333518195481,\n",
       " 21888242871839275222246405745257275088547972720629751010673514773911669900874,\n",
       " 481895555541138006029955402638926684,\n",
       " 21888242871839275222246405745257275088547684972045461403308394559110411737709,\n",
       " 1836791940112604049376119197102767472,\n",
       " 109390161942317928605960259380366395,\n",
       " 5452889280614731132322126398800540232,\n",
       " 21888242871839275222246405745257275088548080485310144715736235380530253533431,\n",
       " 2588352515006693227876192403532009962,\n",
       " 21888242871839275222246405745257275088548190499825748541992014201819359212703,\n",
       " 21888242871839275222246405745257275088548160961554651249251649371589808188006,\n",
       " 831220258236021622447576542392781234,\n",
       " 276718716619564611327900701589059671,\n",
       " 21888242871839275222246405745257275088547315961842096514351854750823804348656,\n",
       " 21888242871839275222246405745257275088548206553309687553412243345789758438336,\n",
       " 21888242871839275222246405745257275088547090351073845516972636571732328187210,\n",
       " 21888242871839275222246405745257275088547624229528936626377525550451144326270,\n",
       " 21888242871839275222246405745257275088547686450056205286188897147407035635378,\n",
       " 2896660236682057457655334883511267650,\n",
       " 21888242871839275222246405745257275088547307802002467241163813826711601420469,\n",
       " 696250882639606372401977226799515709,\n",
       " 21888242871839275222246405745257275088547625459606159623711600506493205147278,\n",
       " 21888242871839275222246405745257275088547771965266567865151708197891440434551,\n",
       " 21888242871839275222246405745257275088548250487658297921218971123020706996738,\n",
       " 21888242871839275222246405745257275088548294819385730380589975328722961062085,\n",
       " 605038589015535787648795388439201480,\n",
       " 1194264362427001983444860258556995086,\n",
       " 21888242871839275222246405745257275088546079556830747274784848024094668642372,\n",
       " 694047718295382835646386601043714596,\n",
       " 238463591846038959146823393548171987,\n",
       " 21888242871839275222246405745257275088547170122852183842739821786627443236113,\n",
       " 21888242871839275222246405745257275088548191800656750112124007335850402770574,\n",
       " 21888242871839275222246405745257275088548174278273947462710808675384303056042,\n",
       " 21888242871839275222246405745257275088548041075106113148425866792463785172298,\n",
       " 21888242871839275222246405745257275088547228408040113946545820617509328054971,\n",
       " 30215483420241567825333252729581146,\n",
       " 21888242871839275222246405745257275088546424190919858426970900473919576324530,\n",
       " 21888242871839275222246405745257275088548157278392762955986449133068244616863,\n",
       " 21888242871839275222246405745257275088548361000602151896480058542093384097066]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, _, dense_out_1, remainder = DenseInt(784, 56, 10**36, X_in, weights[0], biases[0], act=False)\n",
    "dense_out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.6443423e-09, 9.9486595e-01, 1.3254236e-03, 4.2857317e-04,\n",
       "        9.8289172e-07, 8.4703215e-06, 1.3793467e-06, 2.5933378e-03,\n",
       "        6.8582140e-04, 9.0050235e-05]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming model_tf is your original model\n",
    "# Extract the output of the second-to-last layer (the last dense layer before softmax)\n",
    "layer_output = model_tf.layers[1].output\n",
    "\n",
    "# Create a new model that gives the output of the last dense layer\n",
    "intermediate_model = keras.Model(inputs=model_tf.input, outputs=layer_output)\n",
    "\n",
    "intermediate_model.predict(X.reshape(1, -1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7735081885698525090671781120107247323615065383037025344961559877598561881588,\n",
       " 21804873014693066069609384386884114651109037589376155098374850002645650164233,\n",
       " 17999263188021509643811355194238820250977022962787785447268480961075937305244,\n",
       " 21324998268924886012428315205051215564239800920986807565515086703270456560467,\n",
       " 16059188698661913177761974199140049575163288439636430571166107416014577467585,\n",
       " 14732255293448927243090188448786532403436527249519021875340647289934294884659,\n",
       " 6821424371073475607027322913928733901969723771150172819978195505822527367491,\n",
       " 67713646206310789366372044325868952622343505541247674699983513498412536794,\n",
       " 14433190837606797695021663537720886627321264277759233479515138902368268233524,\n",
       " 8897477246040641569599502032963516731694805654261979179335584008834406234713]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, _, dense_out_2, remainder = DenseInt(56, 10, 10**36, dense_out_1, weights[1], biases[1], act=False)\n",
    "dense_out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_exp(x, p):\n",
    "    return pow(int(x), 1, p)  # Modular exponentiation\n",
    "\n",
    "def mod_softmax(out, p):\n",
    "    # Apply modular exponentiation and then normalize\n",
    "    exp_out = [mod_exp(x, p) for x in out]\n",
    "    sum_exp_out = sum(exp_out) % p\n",
    "    softmax_out = [x * pow(sum_exp_out, -1, p) % p for x in exp_out]  # Modular division\n",
    "    return [int(x) for x in softmax_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.6443423e-09, 9.9486595e-01, 1.3254236e-03, 4.2857317e-04,\n",
       "        9.8289172e-07, 8.4703215e-06, 1.3793467e-06, 2.5933378e-03,\n",
       "        6.8582140e-04, 9.0050235e-05]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.predict(X.reshape(1, -1))  # Reshape if necessary\n",
    "\n",
    "# 'output' now contains the output of the last dense layer before softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(dense_out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights_ = []\n",
    "biases_ = []\n",
    "\n",
    "weights = [[None for _ in range(56)] for _ in range(784)]\n",
    "for i in range(784):\n",
    "    for j in range(56):\n",
    "        weights[i][j] = int(model_tf.get_weights()[0][i][j]*1e36)\n",
    "        #print (i,j)\n",
    "biases = [int(b*1e72) for b in model_tf.get_weights()[1]]\n",
    "\n",
    "weights_.append(weights)\n",
    "biases_.append(biases)\n",
    "\n",
    "weights = [[None for _ in range(10)] for _ in range(56)]\n",
    "for i in range(56):\n",
    "    for j in range(10):\n",
    "        weights[i][j] = int(model_tf.get_weights()[2][i][j]*1e36)\n",
    "        #print (i,j)\n",
    "biases = [int(b*1e72) for b in model_tf.get_weights()[3]]\n",
    "\n",
    "weights_.append(weights)\n",
    "biases_.append(biases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_766371/3291663682.py:8: RuntimeWarning: invalid value encountered in cast\n",
      "  scaled_weights = (weight * 1e36).astype(int)\n",
      "/tmp/ipykernel_766371/3291663682.py:9: RuntimeWarning: invalid value encountered in cast\n",
      "  scaled_biases = (bias * 1e72).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Scale the weights and biases\n",
    "weights = []\n",
    "biases= []\n",
    "\n",
    "for layer in model_tf.layers:\n",
    "    #print ('new layer')\n",
    "    weight, bias = layer.get_weights()\n",
    "    scaled_weights = (weight * 1e36).astype(int)\n",
    "    scaled_biases = (bias * 1e72).astype(int)\n",
    "    weights.append(scaled_weights)\n",
    "    biases.append(scaled_biases)\n",
    "\n",
    "# using relu for dense layer is not supported by keras2circom\n",
    "def relu_mod(x, p):\n",
    "    return x if x < p // 2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseInt(nInputs, nOutputs, n, input, weights, bias, act = False):\n",
    "    Input = [str(input[i] % p) for i in range(nInputs)]\n",
    "    Weights = [[str(weights[i][j] % p) for j in range(nOutputs)] for i in range(nInputs)]\n",
    "    Bias = [str(bias[i] % p) for i in range(nOutputs)]\n",
    "\n",
    "    out = [0 for _ in range(nOutputs)]\n",
    "    remainder = [None for _ in range(nOutputs)]\n",
    "    \n",
    "    for j in range(nOutputs):\n",
    "        for i in range(nInputs):\n",
    "            out[j] += int(input[i] * weights[i][j])\n",
    "        out[j] += int(bias[j])\n",
    "\n",
    "        remainder[j] = str(out[j] % n)\n",
    "        out[j] = out[j] // n % p\n",
    "\n",
    "    if act:\n",
    "        out = [int(relu_mod(out[i], p)) for i in range(nOutputs)]\n",
    "\n",
    "    return Input, Weights, Bias, out, remainder    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dense_dense(nInputs, nHidden, nOutputs, X_in, weights, biases):\n",
    "    X_in, dense_42_weights, dense_42_bias, dense_42_out, dense_42_remainder = DenseInt(nInputs, nHidden, 10**36, X_in, weights[0], biases[0], act=True)\n",
    "    #print (dense_42_weights)\n",
    "    _, dense_43_weights, dense_43_bias, dense_43_out, dense_43_remainder = DenseInt(nHidden, nOutputs, 10**36, dense_42_out, weights[1], biases[1], act=True)\n",
    "\n",
    "    pred = np.argmax(dense_43_out)\n",
    "    in_json = {\n",
    "        \"in\": X_in,\n",
    "        \"dense_42_weights\": dense_42_weights,    \n",
    "        \"dense_42_bias\": dense_42_bias,     \n",
    "        \"dense_42_out\": dense_42_out,    \n",
    "        \"dense_42_remainder\": dense_42_remainder,     \n",
    "        \"dense_43_weights\": dense_43_weights,     \n",
    "        \"dense_43_bias\": dense_43_bias,\n",
    "        \"dense_43_out\": dense_43_out,\n",
    "        \"dense_43_remainder\": dense_43_remainder,\n",
    "        #\"dense_43_softmax_out\": int(pred)\n",
    "    }\n",
    "\n",
    "    return in_json, pred\n",
    "\n",
    "in_json, out = input_dense_dense(784, 56, 10, X_in, weights_, biases_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"model_input.json\", \"w\") as f:\n",
    "    json.dump(in_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(test_images, scaled_test_images, model, weights, biases):\n",
    "    for i in range(len(test_images)):\n",
    "        X = test_images[i:i+1]\n",
    "        pred = np.argmax(model.predict(X), axis = 1)\n",
    "\n",
    "        X_in = scaled_test_images[i]\n",
    "        in_json, out = input_dense_dense(784, 56, 10, X_in, weights, biases)\n",
    "        print(pred[0])\n",
    "        if pred[0] != out:\n",
    "            print (f\"Index {i} Not match!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "9\n",
      "Index 9 Not match!\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0\n",
      "Index 10 Not match!\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "9\n",
      "Index 16 Not match!\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "benchmark(test_images_tf[:20], scaled_test_images_tf, model_tf, weights_, biases_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_tf(model, test_images, batch_size=256):\n",
    "    predictions = []\n",
    "    for i in range(0, len(test_images), batch_size):\n",
    "        batch = test_images[i:i+batch_size]\n",
    "        pred = model.predict(batch)\n",
    "        predictions.extend(np.argmax(pred, axis=1))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = [int(pred) for pred in get_predictions_tf(model_tf, test_images_tf[:100])]\n",
    "with open('y_test.json', 'w+') as f:\n",
    "    json.dump(predicted_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_ = test_images.astype('float32')\n",
    "test_images_ /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"./x_test/\"\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "for i in range(size):\n",
    "    X_in = [str(int(x * float(10 ** 36))) for x in test_images_[i].flatten().tolist()]\n",
    "    X_in = np.array(X_in).reshape(28,28,1).tolist()\n",
    "\n",
    "    #print (X_in)\n",
    "    with open(f'{test_folder}{i}.json', 'w+') as f:\n",
    "        json.dump({\"in\": X_in}, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f\"./{circuit_folder}/circuit.json\") as f:\n",
    "    circuit = json.load(f)\n",
    "\n",
    "with open (\"y_test.json\") as f:\n",
    "    y_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[212], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 7\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m y_test[i] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect?\u001b[39m\u001b[38;5;124m\"\u001b[39m, correct)\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/frameworks/socathie/circuits/circuit.py:29\u001b[0m, in \u001b[0;36minference\u001b[0;34m(input, circuit)\u001b[0m\n\u001b[1;32m     26\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m output \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 29\u001b[0m out, remainder \u001b[38;5;241m=\u001b[39m \u001b[43mDenseInt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m56\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdense_42_weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdense_42_bias\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_42_out\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m     31\u001b[0m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_42_remainder\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m remainder\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/frameworks/socathie/keras2circom/util.py:59\u001b[0m, in \u001b[0;36mDenseInt\u001b[0;34m(nInputs, nOutputs, n, input, weights, bias)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nOutputs):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nInputs):\n\u001b[0;32m---> 59\u001b[0m         out[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mint\u001b[39m(weights[i][j])\n\u001b[1;32m     60\u001b[0m     out[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(bias[j])\n\u001b[1;32m     61\u001b[0m     remainder[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(out[j] \u001b[38;5;241m%\u001b[39m n)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'list'"
     ]
    }
   ],
   "source": [
    "from circuits.circuit import inference\n",
    "correct = 0\n",
    "for i in range(size):\n",
    "    with open(f\"{test_folder}{i}.json\", \"r\") as f:\n",
    "        input = json.load(f)\n",
    "    \n",
    "    out, _ = inference(input, circuit)\n",
    "    correct += 1 if out[0] == y_test[i] else 0\n",
    "    print (\"correct?\", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m in_json \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m\"\u001b[39m: X_in,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m: weights,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m: bias,\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mout\u001b[49m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremainder\u001b[39m\u001b[38;5;124m\"\u001b[39m: remainder\n\u001b[1;32m      7\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "in_json = {\n",
    "    \"in\": X_in,\n",
    "    \"weights\": weights,\n",
    "    \"bias\": bias,\n",
    "    \"out\": out,\n",
    "    \"remainder\": remainder\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dense_input.json\", \"w\") as f:\n",
    "    json.dump(in_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
