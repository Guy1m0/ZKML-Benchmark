{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 21:40:08.791675: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-23 21:40:08.812082: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-23 21:40:08.812103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-23 21:40:08.812680: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-23 21:40:08.816062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 21:40:09.203421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 21:45:14.818795: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-23 21:45:14.868079: I external/local_xla/xla/service/service.cc:168] XLA service 0x5600ec013ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-23 21:45:14.868098: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-01-23 21:45:14.872936: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706017514.918089   71597 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.8231 - accuracy: 0.7373 - val_loss: 0.2165 - val_accuracy: 0.9373\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2051 - accuracy: 0.9391 - val_loss: 0.1294 - val_accuracy: 0.9618\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1313 - accuracy: 0.9601 - val_loss: 0.0896 - val_accuracy: 0.9747\n",
      "313/313 - 0s - loss: 0.1025 - accuracy: 0.9677 - 208ms/epoch - 665us/step\n",
      "\n",
      "Test accuracy: 0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "# Define the LeNet model in TensorFlow\n",
    "model_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='sigmoid'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(84, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10)  # Assuming 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_tf.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_tf.fit(train_images, train_labels, epochs=3, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model_tf.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicLeNetPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicLeNetPT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.conv1(x))\n",
    "\n",
    "model_pt_basic = BasicLeNetPT()\n",
    "\n",
    "model_tf_basic = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Transfer weights for TensorFlow\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_tf_basic.layers[0].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for PyTorch\n",
    "with torch.no_grad():\n",
    "    model_pt_basic.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "    model_pt_basic.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a controlled input (e.g., an array of ones)\n",
    "controlled_input = np.ones((1, 28, 28, 1), dtype=np.float32)  # For TensorFlow\n",
    "controlled_input_pt = torch.from_numpy(controlled_input).permute(0, 3, 1, 2)  # For PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "TensorFlow Basic Model Output: [[[[9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   ...\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   ...\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   ...\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   ...\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   ...\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   ...\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]\n",
      "   [9.9660897e-01 2.1650463e-01 4.8949671e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]]]\n",
      "PyTorch Basic Model Output: [[[[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]]\n",
      "\n",
      "\n",
      " [[[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]]\n",
      "\n",
      "\n",
      " [[[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]]\n",
      "\n",
      "\n",
      " [[[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]]\n",
      "\n",
      "\n",
      " [[[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]\n",
      "\n",
      "  [[9.9660897e-01 2.1650463e-01 4.8949677e-01 8.8328234e-04\n",
      "    7.6754862e-01 3.5114321e-05]]]]\n"
     ]
    }
   ],
   "source": [
    "# Test TensorFlow Basic Model\n",
    "output_tf_basic = model_tf_basic.predict(controlled_input)\n",
    "\n",
    "# Test PyTorch Basic Model\n",
    "model_pt_basic.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt_basic = model_pt_basic(controlled_input_pt)\n",
    "\n",
    "# Compare outputs\n",
    "print(\"TensorFlow Basic Model Output:\", output_tf_basic)\n",
    "print(\"PyTorch Basic Model Output:\", output_pt_basic.cpu().permute(3,2,0,1).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TensorFlow\u001b[39;00m\n\u001b[1;32m      2\u001b[0m intermediate_model_tf_basic2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mmodel_tf_basic\u001b[38;5;241m.\u001b[39minputs,\n\u001b[0;32m----> 3\u001b[0m                                               outputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_tf_basic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m      4\u001b[0m intermediate_output_tf_basic2 \u001b[38;5;241m=\u001b[39m intermediate_model_tf_basic2\u001b[38;5;241m.\u001b[39mpredict(controlled_input)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "intermediate_model_tf_basic2 = tf.keras.Model(inputs=model_tf_basic.inputs,\n",
    "                                              outputs=model_tf_basic.layers[1].output)\n",
    "intermediate_output_tf_basic2 = intermediate_model_tf_basic2.predict(controlled_input)\n",
    "\n",
    "# PyTorch\n",
    "with torch.no_grad():\n",
    "    intermediate_output_pt_basic2 = model_pt_basic.conv1(controlled_input_pt)\n",
    "    intermediate_output_pt_basic2 = torch.sigmoid(intermediate_output_pt_basic2)\n",
    "    intermediate_output_pt_basic2 = model_pt_basic.conv2(intermediate_output_pt_basic2)\n",
    "\n",
    "# Print and compare intermediate outputs after the second layer\n",
    "print(\"Intermediate Output TensorFlow Basic Model (Layer 2):\", intermediate_output_tf_basic2)\n",
    "print(\"Intermediate Output PyTorch Basic Model (Layer 2):\", intermediate_output_pt_basic2.permute(0, 2, 3, 1).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
