{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 11:30:34.889148: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-28 11:30:34.921168: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-28 11:30:34.921197: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-28 11:30:34.921918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-28 11:30:34.926662: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 11:30:35.591317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "# Convert to PyTorch format [batch_size, channels, height, width]\n",
    "train_images_pt = torch.tensor(train_images).permute(0, 3, 1, 2).float()\n",
    "test_images_pt = torch.tensor(test_images).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# If additional normalization is required for your PyTorch model, apply it here\n",
    "# For example, if you use transforms.Normalize((0.1307,), (0.3081,)) in PyTorch, apply similar normalization\n",
    "mean, std = 0.1307, 0.3081\n",
    "train_images_pt = (train_images_pt - mean) / std\n",
    "test_images_pt = (test_images_pt - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 11:30:36.614562: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.615241: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.615327: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.616468: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.616563: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.616639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.705102: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.705214: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.705301: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 11:30:36.705374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20311 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 11:30:37.798508: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-01-28 11:30:37.897090: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-01-28 11:30:37.897099: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
      "2024-01-28 11:30:37.897122: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-01-28 11:30:38.089713: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 11:30:38.163125: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3914320ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-28 11:30:38.163137: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-01-28 11:30:38.166565: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706412638.196280   20447 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.8812 - accuracy: 0.7149 - val_loss: 0.2320 - val_accuracy: 0.9333\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2228 - accuracy: 0.9325 - val_loss: 0.1445 - val_accuracy: 0.9580\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1477 - accuracy: 0.9541 - val_loss: 0.0962 - val_accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "# Define the LeNet model in TensorFlow\n",
    "model_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='sigmoid'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(84, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10)  # Assuming 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_tf.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_tf.fit(train_images, train_labels, epochs=3, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1121 - accuracy: 0.9651 - 253ms/epoch - 809us/step\n",
      "\n",
      "Test accuracy: 0.9650999903678894\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_tf.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class LeNetPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetPT, self).__init__()\n",
    "        # Convolutional encoder\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # 1 input channel, 6 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel\n",
    "\n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(16 *4 * 4,120) # 256 * 120\n",
    "        self.fc2 = nn.Linear(120, 84)         # 120 inputs, 84 outputs\n",
    "        self.fc3 = nn.Linear(84, 10)          # 84 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # TODO: figure out the resize, currently work on batch_size = 1\n",
    "        batch_size = x.size(0)\n",
    "        x = x.reshape(x.size(0),16,-1)  # 16 output channels\n",
    "        x = np.transpose(x, (0,2,1)).reshape(batch_size,-1)\n",
    "        #x = x.reshape(batch_size,-1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)  # No activation function here, will use CrossEntropyLoss later\n",
    "        return x\n",
    "    \n",
    "\n",
    "model_pt = LeNetPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "model_pt.fc1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second dense layer (fc2) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[6].get_weights()\n",
    "model_pt.fc2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the third dense layer (fc3) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[7].get_weights()\n",
    "model_pt.fc3.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc3.bias = nn.Parameter(torch.from_numpy(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a controlled input (e.g., an array of ones)\n",
    "# controlled_input_tf = np.ones((1, 28, 28, 1), dtype=np.float32)  # For TensorFlow\n",
    "# controlled_input_pt = torch.from_numpy(controlled_input_tf).permute(0, 3, 1, 2)  # For PyTorch\n",
    "\n",
    "# Select the image for TensorFlow\n",
    "controlled_input_tf = test_images[36][np.newaxis, ]  # No reshape needed as it's already in (28, 28, 1) format\n",
    "controlled_input_pt = torch.tensor(controlled_input_tf).float().permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "TF Basic Model Output: [[-1.6124442  -1.3553426   2.4211276   2.095878   -2.457887   -2.1878283\n",
      "  -8.359751    7.455803   -2.1234655   0.07171768]]\n",
      "PT Basic Model Output: [[-1.6124436  -1.355343    2.4211273   2.095877   -2.4578862  -2.1878288\n",
      "  -8.359749    7.4558034  -2.1234653   0.07171769]]\n"
     ]
    }
   ],
   "source": [
    "# Test PyTorch Basic Model\n",
    "model_pt.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt = model_pt(controlled_input_pt)\n",
    "\n",
    "output_tf = model_tf.predict(controlled_input_tf) \n",
    "print(\"TF Basic Model Output:\", output_tf)\n",
    "print(\"PT Basic Model Output:\", output_pt.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your model expects a single-channel (grayscale) image with 28x28 resolution\n",
    "dummy_input_shape = (1, 1, 28, 28)  # Batch size of 1, 1 channel, 28x28 pixels\n",
    "\n",
    "# Create a dummy input tensor with random data\n",
    "dummy_input = torch.randn(dummy_input_shape).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 96.26%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming the TensorFlow MNIST data has already been loaded\n",
    "# Convert test_images to PyTorch tensor and permute\n",
    "test_images_pt = torch.tensor(test_images).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Assuming test_labels are already loaded\n",
    "test_dataset = TensorDataset(test_images_pt, torch.tensor(test_labels))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = evaluate_model(model_pt, test_loader)\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicLeNetPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicLeNetPT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.conv1(x))\n",
    "\n",
    "model_pt_basic = BasicLeNetPT()\n",
    "\n",
    "model_tf_basic = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Transfer weights for TensorFlow\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_tf_basic.layers[0].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for PyTorch\n",
    "with torch.no_grad():\n",
    "    model_pt_basic.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "    model_pt_basic.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the image for TensorFlow\n",
    "controlled_input = test_images[36][np.newaxis, ]  # No reshape needed as it's already in (28, 28, 1) format\n",
    "controlled_input_pt = torch.tensor(controlled_input_tf).float().permute(0, 3, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "TensorFlow Basic Model Output: [[[[0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   ...\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]]\n",
      "\n",
      "  [[0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   ...\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]]\n",
      "\n",
      "  [[0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   ...\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   ...\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]]\n",
      "\n",
      "  [[0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   ...\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]]\n",
      "\n",
      "  [[0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   ...\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]\n",
      "   [0.3405072  0.37062928 0.6257144  0.33070144 0.6428052  0.62785596]]]]\n",
      "PyTorch Basic Model Output: [[[[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]]\n",
      "\n",
      "\n",
      " [[[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]]\n",
      "\n",
      "\n",
      " [[[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]]\n",
      "\n",
      "\n",
      " [[[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]]\n",
      "\n",
      "\n",
      " [[[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]\n",
      "\n",
      "  [[0.34050718 0.37062928 0.6257144  0.33070144 0.6428052  0.627856  ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Test TensorFlow Basic Model\n",
    "output_tf_basic = model_tf_basic.predict(controlled_input)\n",
    "\n",
    "# Test PyTorch Basic Model\n",
    "model_pt_basic.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt_basic = model_pt_basic(controlled_input_pt)\n",
    "\n",
    "# Compare outputs\n",
    "print(\"TensorFlow Basic Model Output:\", output_tf_basic)\n",
    "print(\"PyTorch Basic Model Output:\", output_pt_basic.cpu().permute(3,2,0,1).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define a basic LeNet model in PyTorch with two convolutional layers\n",
    "class BasicLeNetPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicLeNetPT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        x = torch.sigmoid(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "model_pt_basic = BasicLeNetPT()\n",
    "\n",
    "# Create a basic LeNet model in TensorFlow with two convolutional layers\n",
    "model_tf_basic = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_tf_basic.layers[0].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_tf_basic.layers[1].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt_basic\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt_basic.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt_basic\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt_basic.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the image for TensorFlow\n",
    "controlled_input = test_images[36][np.newaxis, ]  # No reshape needed as it's already in (28, 28, 1) format\n",
    "controlled_input_pt = torch.tensor(controlled_input_tf).float().permute(0, 3, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "TensorFlow Basic Model Output: [[[[2.57586502e-02 6.63225278e-02 3.52370068e-02 ... 2.83964783e-01\n",
      "    3.78392786e-01 1.71559360e-02]\n",
      "   [3.18357944e-02 9.97148827e-02 3.43728028e-02 ... 4.42336261e-01\n",
      "    4.03742552e-01 2.45979186e-02]\n",
      "   [4.90795746e-02 1.39458686e-01 3.03143449e-02 ... 5.38973391e-01\n",
      "    4.56746191e-01 3.97939608e-02]\n",
      "   ...\n",
      "   [4.77694720e-02 6.36636093e-02 3.90103497e-02 ... 3.89785856e-01\n",
      "    2.98766255e-01 4.16699834e-02]\n",
      "   [3.69360596e-02 6.63337857e-02 3.34584303e-02 ... 2.79973477e-01\n",
      "    3.29799414e-01 2.47441996e-02]\n",
      "   [3.33412029e-02 6.84268177e-02 3.02623659e-02 ... 2.24366948e-01\n",
      "    3.36898059e-01 1.78801026e-02]]\n",
      "\n",
      "  [[5.97592928e-02 1.66600794e-01 2.22794805e-02 ... 6.77564323e-01\n",
      "    2.82137245e-01 2.98533738e-02]\n",
      "   [2.17131585e-01 3.99079263e-01 1.07417926e-02 ... 8.41790795e-01\n",
      "    1.99286669e-01 6.10251874e-02]\n",
      "   [6.20349586e-01 6.13339841e-01 3.73514532e-03 ... 8.61602783e-01\n",
      "    9.75781530e-02 9.39734802e-02]\n",
      "   ...\n",
      "   [1.52095690e-01 8.14687684e-02 2.45576277e-02 ... 6.36375546e-01\n",
      "    1.23061843e-01 7.08035752e-02]\n",
      "   [6.11019693e-02 6.93565235e-02 3.26103307e-02 ... 4.33324426e-01\n",
      "    2.50361592e-01 4.17261422e-02]\n",
      "   [3.77909318e-02 6.92977309e-02 3.11484374e-02 ... 2.64988542e-01\n",
      "    3.28791142e-01 2.22917497e-02]]\n",
      "\n",
      "  [[4.54244375e-01 6.34751558e-01 6.93472940e-03 ... 8.90267313e-01\n",
      "    6.14309534e-02 5.34798540e-02]\n",
      "   [9.40072060e-01 9.21375930e-01 1.55194674e-03 ... 8.59239280e-01\n",
      "    8.29542615e-03 6.66806772e-02]\n",
      "   [9.95082974e-01 9.78631854e-01 2.49795878e-04 ... 6.99787557e-01\n",
      "    5.25148644e-04 3.16865630e-02]\n",
      "   ...\n",
      "   [5.31833708e-01 1.59883171e-01 4.85916715e-03 ... 6.84716821e-01\n",
      "    1.49780158e-02 2.01880261e-02]\n",
      "   [1.44799292e-01 9.11357999e-02 1.81292444e-02 ... 5.52146673e-01\n",
      "    1.06342860e-01 3.54126468e-02]\n",
      "   [5.24092503e-02 7.51833916e-02 2.80127507e-02 ... 3.23216081e-01\n",
      "    2.70679325e-01 2.54853796e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   [3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   [3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   ...\n",
      "   [6.24977704e-03 2.38206275e-02 1.07319355e-01 ... 8.59376848e-01\n",
      "    9.35030997e-01 4.85371172e-01]\n",
      "   [2.07196195e-02 4.03216407e-02 6.50104582e-02 ... 5.74824274e-01\n",
      "    6.84800029e-01 1.87931776e-01]\n",
      "   [3.15484479e-02 5.39612882e-02 4.36594374e-02 ... 2.75653362e-01\n",
      "    4.19311076e-01 5.43564409e-02]]\n",
      "\n",
      "  [[3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   [3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   [3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   ...\n",
      "   [2.31769219e-01 6.55437261e-02 4.88672964e-03 ... 2.39547536e-01\n",
      "    6.23090900e-02 4.83483728e-03]\n",
      "   [1.37919381e-01 7.05952495e-02 1.10017816e-02 ... 1.64588302e-01\n",
      "    8.84932950e-02 6.79437164e-03]\n",
      "   [7.02039152e-02 6.92757890e-02 1.94949787e-02 ... 1.49356633e-01\n",
      "    1.54885590e-01 9.42626130e-03]]\n",
      "\n",
      "  [[3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   [3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   [3.26236002e-02 6.87427521e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967482e-01 1.70121044e-02]\n",
      "   ...\n",
      "   [1.49817616e-01 7.92565718e-02 9.20786057e-03 ... 1.06855400e-01\n",
      "    7.06348866e-02 3.20416456e-03]\n",
      "   [8.63435417e-02 7.42657036e-02 1.64080802e-02 ... 1.25924468e-01\n",
      "    1.26676038e-01 6.00850303e-03]\n",
      "   [5.47261871e-02 7.06891865e-02 2.33658031e-02 ... 1.58357978e-01\n",
      "    2.03250334e-01 9.71523207e-03]]]]\n",
      "PyTorch Basic Model Output: [[[[2.57586502e-02 6.63224906e-02 3.52370068e-02 ... 2.83964783e-01\n",
      "    3.78392875e-01 1.71559360e-02]]\n",
      "\n",
      "  [[5.97592779e-02 1.66600764e-01 2.22794805e-02 ... 6.77564263e-01\n",
      "    2.82137245e-01 2.98533775e-02]]\n",
      "\n",
      "  [[4.54244316e-01 6.34751618e-01 6.93472940e-03 ... 8.90267313e-01\n",
      "    6.14309087e-02 5.34798391e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]]\n",
      "\n",
      "\n",
      " [[[3.18357795e-02 9.97148678e-02 3.43728028e-02 ... 4.42336202e-01\n",
      "    4.03742582e-01 2.45979261e-02]]\n",
      "\n",
      "  [[2.17131525e-01 3.99079233e-01 1.07417936e-02 ... 8.41790795e-01\n",
      "    1.99286610e-01 6.10251650e-02]]\n",
      "\n",
      "  [[9.40072060e-01 9.21375930e-01 1.55194756e-03 ... 8.59239280e-01\n",
      "    8.29542242e-03 6.66806549e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]]\n",
      "\n",
      "\n",
      " [[[4.90795560e-02 1.39458671e-01 3.03143486e-02 ... 5.38973391e-01\n",
      "    4.56746191e-01 3.97939570e-02]]\n",
      "\n",
      "  [[6.20349526e-01 6.13339841e-01 3.73514532e-03 ... 8.61602783e-01\n",
      "    9.75781158e-02 9.39734504e-02]]\n",
      "\n",
      "  [[9.95082974e-01 9.78631854e-01 2.49795616e-04 ... 6.99787498e-01\n",
      "    5.25148644e-04 3.16865630e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]\n",
      "\n",
      "  [[3.26235890e-02 6.87427223e-02 2.99267173e-02 ... 2.14654878e-01\n",
      "    3.28967601e-01 1.70121137e-02]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[4.77694571e-02 6.36635795e-02 3.90103497e-02 ... 3.89785856e-01\n",
      "    2.98766285e-01 4.16699983e-02]]\n",
      "\n",
      "  [[1.52095675e-01 8.14687535e-02 2.45576296e-02 ... 6.36375487e-01\n",
      "    1.23061873e-01 7.08035752e-02]]\n",
      "\n",
      "  [[5.31833708e-01 1.59883186e-01 4.85916482e-03 ... 6.84716761e-01\n",
      "    1.49780223e-02 2.01880205e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.24977658e-03 2.38206275e-02 1.07319355e-01 ... 8.59376967e-01\n",
      "    9.35030997e-01 4.85371083e-01]]\n",
      "\n",
      "  [[2.31769204e-01 6.55437112e-02 4.88673383e-03 ... 2.39547491e-01\n",
      "    6.23091199e-02 4.83484007e-03]]\n",
      "\n",
      "  [[1.49817556e-01 7.92565420e-02 9.20786895e-03 ... 1.06855378e-01\n",
      "    7.06349164e-02 3.20416573e-03]]]\n",
      "\n",
      "\n",
      " [[[3.69360521e-02 6.63337708e-02 3.34584452e-02 ... 2.79973477e-01\n",
      "    3.29799443e-01 2.47442108e-02]]\n",
      "\n",
      "  [[6.11019470e-02 6.93565086e-02 3.26103456e-02 ... 4.33324426e-01\n",
      "    2.50361621e-01 4.17261459e-02]]\n",
      "\n",
      "  [[1.44799292e-01 9.11357775e-02 1.81292575e-02 ... 5.52146614e-01\n",
      "    1.06342912e-01 3.54126357e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.07196139e-02 4.03216407e-02 6.50104210e-02 ... 5.74824274e-01\n",
      "    6.84800148e-01 1.87931776e-01]]\n",
      "\n",
      "  [[1.37919426e-01 7.05952719e-02 1.10017927e-02 ... 1.64588258e-01\n",
      "    8.84932950e-02 6.79437444e-03]]\n",
      "\n",
      "  [[8.63435268e-02 7.42657036e-02 1.64080877e-02 ... 1.25924423e-01\n",
      "    1.26676068e-01 6.00850908e-03]]]\n",
      "\n",
      "\n",
      " [[[3.33412029e-02 6.84268028e-02 3.02623659e-02 ... 2.24366948e-01\n",
      "    3.36898178e-01 1.78801119e-02]]\n",
      "\n",
      "  [[3.77909243e-02 6.92977309e-02 3.11484300e-02 ... 2.64988512e-01\n",
      "    3.28791171e-01 2.22917609e-02]]\n",
      "\n",
      "  [[5.24092391e-02 7.51833618e-02 2.80127656e-02 ... 3.23216081e-01\n",
      "    2.70679414e-01 2.54853796e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.15484479e-02 5.39612770e-02 4.36594374e-02 ... 2.75653362e-01\n",
      "    4.19311136e-01 5.43564595e-02]]\n",
      "\n",
      "  [[7.02039376e-02 6.92757964e-02 1.94949880e-02 ... 1.49356574e-01\n",
      "    1.54885575e-01 9.42626130e-03]]\n",
      "\n",
      "  [[5.47261871e-02 7.06892014e-02 2.33658254e-02 ... 1.58358023e-01\n",
      "    2.03250408e-01 9.71522741e-03]]]]\n"
     ]
    }
   ],
   "source": [
    "# Test TensorFlow Basic Model\n",
    "output_tf_basic = model_tf_basic.predict(controlled_input)\n",
    "\n",
    "# Test PyTorch Basic Model\n",
    "model_pt_basic.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt_basic = model_pt_basic(controlled_input_pt)\n",
    "\n",
    "\n",
    "# Compare outputs\n",
    "print(\"TensorFlow Basic Model Output:\", output_tf_basic)\n",
    "print(\"PyTorch Basic Model Output:\", output_pt_basic.cpu().permute(3,2,0,1).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AvgPool + Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a basic LeNet model in PyTorch with two convolutional layers\n",
    "class BasicLeNetPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicLeNetPT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # Flattening the tensor to the correct size\n",
    "        print ('x:', x.shape)\n",
    "        #x = x.permute(3,2,0,1)\n",
    "        x = x.reshape(x.size(0),16, -1)  # Reshape to [batch_size, 16*4*4]\n",
    "        x = np.transpose(x, (0,2,1))\n",
    "        print ('new x:', x)\n",
    "        x = x.reshape(1,-1)\n",
    "        #x = x.reshape(1,-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "model_pt_basic = BasicLeNetPT()\n",
    "\n",
    "# Create a basic LeNet model in TensorFlow with two convolutional layers\n",
    "model_tf_basic = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='sigmoid'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[\n",
    "         [[3.5723e-01, 4.5777e-02, 5.6642e-02, 4.2337e-01],\n",
    "          [2.1288e-01, 5.0078e-01, 1.6339e-01, 2.9913e-01],\n",
    "          [9.1992e-01, 8.7455e-01, 2.3724e-01, 6.8523e-01],\n",
    "          [8.1138e-01, 1.9003e-01, 6.3758e-03, 1.2055e-01]],\n",
    "\n",
    "         [[4.8308e-01, 3.1106e-01, 5.4154e-01, 1.1745e-01],\n",
    "          [7.9991e-03, 1.9359e-02, 3.3432e-01, 2.2252e-01],\n",
    "          [1.2991e-02, 1.6436e-02, 2.4286e-01, 1.6083e-01],\n",
    "          [5.4464e-03, 1.3997e-01, 4.2180e-01, 1.8740e-01]],\n",
    "\n",
    "         [[3.2170e-01, 2.7298e-01, 3.5326e-02, 7.6450e-01],\n",
    "          [9.5109e-01, 4.1637e-01, 1.7059e-01, 9.9765e-01],\n",
    "          [3.9638e-01, 4.9827e-03, 4.1401e-01, 9.7265e-01],\n",
    "          [3.7518e-02, 2.6161e-04, 8.0465e-01, 9.4228e-01]],\n",
    "\n",
    "         [[9.6234e-01, 6.3446e-01, 7.8497e-01, 9.9889e-01],\n",
    "          [1.0425e-01, 2.9717e-01, 1.7846e-01, 9.6586e-01],\n",
    "          [9.5296e-01, 8.5555e-01, 7.1479e-01, 9.9898e-01],\n",
    "          [9.1078e-01, 3.7230e-01, 6.3753e-01, 7.8140e-01]],\n",
    "\n",
    "         [[5.4403e-01, 4.5540e-01, 6.0395e-01, 9.8221e-01],\n",
    "          [2.6451e-01, 5.5743e-01, 5.3958e-01, 6.8985e-01],\n",
    "          [9.3700e-01, 9.5921e-01, 9.8059e-01, 9.9786e-01],\n",
    "          [7.8612e-01, 4.2739e-01, 1.7482e-01, 3.6958e-01]],\n",
    "\n",
    "         [[6.6020e-01, 9.9102e-01, 8.3870e-01, 3.3561e-01],\n",
    "          [2.5659e-01, 1.8054e-03, 2.7322e-03, 5.8188e-02],\n",
    "          [5.8673e-03, 9.5297e-03, 7.6039e-03, 7.4197e-02],\n",
    "          [9.2970e-02, 2.6396e-01, 4.9441e-01, 4.9260e-01]],\n",
    "\n",
    "         [[9.9502e-01, 7.5909e-01, 9.0809e-01, 9.5490e-01],\n",
    "          [3.1568e-03, 3.8385e-02, 8.8143e-02, 1.9937e-01],\n",
    "          [1.7792e-01, 8.2782e-01, 7.9667e-01, 6.2599e-01],\n",
    "          [5.7518e-01, 8.6944e-01, 5.0264e-01, 3.9224e-01]],\n",
    "\n",
    "         [[3.7335e-01, 5.2908e-01, 3.8880e-01, 1.5501e-01],\n",
    "          [8.6459e-01, 4.9262e-01, 1.8903e-01, 7.1074e-01],\n",
    "          [4.4185e-02, 1.1017e-02, 1.0341e-01, 2.1341e-01],\n",
    "          [6.5215e-02, 1.9144e-01, 8.4518e-01, 7.6709e-01]],\n",
    "\n",
    "         [[7.8185e-01, 5.3509e-01, 9.5149e-01, 8.1755e-01],\n",
    "          [1.2340e-03, 1.0570e-01, 4.1592e-01, 1.9644e-01],\n",
    "          [3.0448e-01, 9.1760e-01, 8.7980e-01, 3.5192e-01],\n",
    "          [6.8204e-01, 8.5161e-01, 3.2074e-01, 8.7232e-02]],\n",
    "\n",
    "         [[9.8841e-01, 8.7884e-01, 9.8269e-01, 7.6363e-01],\n",
    "          [5.2841e-02, 3.8924e-02, 7.4685e-01, 1.8598e-01],\n",
    "          [8.0211e-02, 6.9800e-01, 9.5531e-01, 2.6941e-01],\n",
    "          [4.7938e-01, 9.8505e-01, 7.3865e-01, 1.8938e-01]],\n",
    "\n",
    "         [[9.9835e-01, 9.6591e-01, 9.8631e-01, 9.1282e-01],\n",
    "          [2.0500e-01, 2.2773e-02, 7.6318e-01, 4.7738e-01],\n",
    "          [1.2892e-01, 6.3485e-01, 9.8153e-01, 4.7129e-01],\n",
    "          [4.9836e-01, 9.7686e-01, 8.6751e-01, 4.1846e-01]],\n",
    "\n",
    "         [[8.2326e-01, 8.1415e-01, 4.7680e-01, 7.0314e-01],\n",
    "          [9.8579e-01, 9.8720e-01, 9.1869e-01, 5.0148e-01],\n",
    "          [9.9050e-01, 9.9447e-01, 7.9113e-01, 4.7052e-01],\n",
    "          [9.9750e-01, 9.9385e-01, 7.4088e-01, 5.6988e-01]],\n",
    "\n",
    "         [[9.5119e-01, 8.7655e-01, 5.0090e-01, 9.9662e-01],\n",
    "          [7.9699e-01, 1.8493e-01, 2.5544e-01, 9.4455e-01],\n",
    "          [4.4179e-01, 3.3896e-02, 7.5910e-01, 9.4222e-01],\n",
    "          [4.1240e-01, 1.8616e-01, 9.9598e-01, 7.0146e-01]],\n",
    "\n",
    "         [[1.3385e-01, 3.2317e-03, 1.8571e-02, 5.8818e-03],\n",
    "          [8.2051e-02, 5.2408e-01, 5.1842e-01, 5.3531e-03],\n",
    "          [6.4661e-01, 9.6453e-01, 3.2730e-01, 3.9188e-02],\n",
    "          [3.0446e-01, 4.3663e-01, 9.8731e-04, 5.5072e-03]],\n",
    "\n",
    "         [[8.7332e-01, 4.1994e-01, 1.0308e-01, 6.9599e-02],\n",
    "          [1.2927e-03, 3.6074e-04, 3.5211e-01, 1.5637e-02],\n",
    "          [1.0480e-03, 1.9545e-01, 6.5611e-01, 9.4675e-03],\n",
    "          [6.2039e-03, 6.5116e-01, 4.0032e-01, 1.3742e-03]],\n",
    "\n",
    "         [[6.5252e-02, 2.9379e-02, 1.9423e-01, 1.0593e-02],\n",
    "          [1.9242e-01, 8.0646e-01, 7.9053e-01, 1.0609e-02],\n",
    "          [8.1746e-01, 9.8786e-01, 4.0663e-01, 1.6456e-02],\n",
    "          [8.3385e-01, 9.3526e-01, 7.4338e-03, 8.6007e-02]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reshape(1,16,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.5723e-01, 4.8308e-01, 3.2170e-01, 9.6234e-01, 5.4403e-01,\n",
       "         6.6020e-01, 9.9502e-01, 3.7335e-01, 7.8185e-01, 9.8841e-01,\n",
       "         9.9835e-01, 8.2326e-01, 9.5119e-01, 1.3385e-01, 8.7332e-01,\n",
       "         6.5252e-02],\n",
       "        [4.5777e-02, 3.1106e-01, 2.7298e-01, 6.3446e-01, 4.5540e-01,\n",
       "         9.9102e-01, 7.5909e-01, 5.2908e-01, 5.3509e-01, 8.7884e-01,\n",
       "         9.6591e-01, 8.1415e-01, 8.7655e-01, 3.2317e-03, 4.1994e-01,\n",
       "         2.9379e-02],\n",
       "        [5.6642e-02, 5.4154e-01, 3.5326e-02, 7.8497e-01, 6.0395e-01,\n",
       "         8.3870e-01, 9.0809e-01, 3.8880e-01, 9.5149e-01, 9.8269e-01,\n",
       "         9.8631e-01, 4.7680e-01, 5.0090e-01, 1.8571e-02, 1.0308e-01,\n",
       "         1.9423e-01],\n",
       "        [4.2337e-01, 1.1745e-01, 7.6450e-01, 9.9889e-01, 9.8221e-01,\n",
       "         3.3561e-01, 9.5490e-01, 1.5501e-01, 8.1755e-01, 7.6363e-01,\n",
       "         9.1282e-01, 7.0314e-01, 9.9662e-01, 5.8818e-03, 6.9599e-02,\n",
       "         1.0593e-02],\n",
       "        [2.1288e-01, 7.9991e-03, 9.5109e-01, 1.0425e-01, 2.6451e-01,\n",
       "         2.5659e-01, 3.1568e-03, 8.6459e-01, 1.2340e-03, 5.2841e-02,\n",
       "         2.0500e-01, 9.8579e-01, 7.9699e-01, 8.2051e-02, 1.2927e-03,\n",
       "         1.9242e-01],\n",
       "        [5.0078e-01, 1.9359e-02, 4.1637e-01, 2.9717e-01, 5.5743e-01,\n",
       "         1.8054e-03, 3.8385e-02, 4.9262e-01, 1.0570e-01, 3.8924e-02,\n",
       "         2.2773e-02, 9.8720e-01, 1.8493e-01, 5.2408e-01, 3.6074e-04,\n",
       "         8.0646e-01],\n",
       "        [1.6339e-01, 3.3432e-01, 1.7059e-01, 1.7846e-01, 5.3958e-01,\n",
       "         2.7322e-03, 8.8143e-02, 1.8903e-01, 4.1592e-01, 7.4685e-01,\n",
       "         7.6318e-01, 9.1869e-01, 2.5544e-01, 5.1842e-01, 3.5211e-01,\n",
       "         7.9053e-01],\n",
       "        [2.9913e-01, 2.2252e-01, 9.9765e-01, 9.6586e-01, 6.8985e-01,\n",
       "         5.8188e-02, 1.9937e-01, 7.1074e-01, 1.9644e-01, 1.8598e-01,\n",
       "         4.7738e-01, 5.0148e-01, 9.4455e-01, 5.3531e-03, 1.5637e-02,\n",
       "         1.0609e-02],\n",
       "        [9.1992e-01, 1.2991e-02, 3.9638e-01, 9.5296e-01, 9.3700e-01,\n",
       "         5.8673e-03, 1.7792e-01, 4.4185e-02, 3.0448e-01, 8.0211e-02,\n",
       "         1.2892e-01, 9.9050e-01, 4.4179e-01, 6.4661e-01, 1.0480e-03,\n",
       "         8.1746e-01],\n",
       "        [8.7455e-01, 1.6436e-02, 4.9827e-03, 8.5555e-01, 9.5921e-01,\n",
       "         9.5297e-03, 8.2782e-01, 1.1017e-02, 9.1760e-01, 6.9800e-01,\n",
       "         6.3485e-01, 9.9447e-01, 3.3896e-02, 9.6453e-01, 1.9545e-01,\n",
       "         9.8786e-01],\n",
       "        [2.3724e-01, 2.4286e-01, 4.1401e-01, 7.1479e-01, 9.8059e-01,\n",
       "         7.6039e-03, 7.9667e-01, 1.0341e-01, 8.7980e-01, 9.5531e-01,\n",
       "         9.8153e-01, 7.9113e-01, 7.5910e-01, 3.2730e-01, 6.5611e-01,\n",
       "         4.0663e-01],\n",
       "        [6.8523e-01, 1.6083e-01, 9.7265e-01, 9.9898e-01, 9.9786e-01,\n",
       "         7.4197e-02, 6.2599e-01, 2.1341e-01, 3.5192e-01, 2.6941e-01,\n",
       "         4.7129e-01, 4.7052e-01, 9.4222e-01, 3.9188e-02, 9.4675e-03,\n",
       "         1.6456e-02],\n",
       "        [8.1138e-01, 5.4464e-03, 3.7518e-02, 9.1078e-01, 7.8612e-01,\n",
       "         9.2970e-02, 5.7518e-01, 6.5215e-02, 6.8204e-01, 4.7938e-01,\n",
       "         4.9836e-01, 9.9750e-01, 4.1240e-01, 3.0446e-01, 6.2039e-03,\n",
       "         8.3385e-01],\n",
       "        [1.9003e-01, 1.3997e-01, 2.6161e-04, 3.7230e-01, 4.2739e-01,\n",
       "         2.6396e-01, 8.6944e-01, 1.9144e-01, 8.5161e-01, 9.8505e-01,\n",
       "         9.7686e-01, 9.9385e-01, 1.8616e-01, 4.3663e-01, 6.5116e-01,\n",
       "         9.3526e-01],\n",
       "        [6.3758e-03, 4.2180e-01, 8.0465e-01, 6.3753e-01, 1.7482e-01,\n",
       "         4.9441e-01, 5.0264e-01, 8.4518e-01, 3.2074e-01, 7.3865e-01,\n",
       "         8.6751e-01, 7.4088e-01, 9.9598e-01, 9.8731e-04, 4.0032e-01,\n",
       "         7.4338e-03],\n",
       "        [1.2055e-01, 1.8740e-01, 9.4228e-01, 7.8140e-01, 3.6958e-01,\n",
       "         4.9260e-01, 3.9224e-01, 7.6709e-01, 8.7232e-02, 1.8938e-01,\n",
       "         4.1846e-01, 5.6988e-01, 7.0146e-01, 5.5072e-03, 1.3742e-03,\n",
       "         8.6007e-02]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(b, (0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_tf_basic.layers[0].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_tf_basic.layers[2].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt_basic\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt_basic.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt_basic\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt_basic.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the image for TensorFlow\n",
    "controlled_input = test_images[36][np.newaxis, ]  # No reshape needed as it's already in (28, 28, 1) format\n",
    "controlled_input_pt = torch.tensor(controlled_input).float().permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "x: torch.Size([1, 16, 4, 4])\n",
      "new x: tensor([[[3.5723e-01, 4.8308e-01, 3.2170e-01, 9.6234e-01, 5.4403e-01,\n",
      "          6.6020e-01, 9.9502e-01, 3.7335e-01, 7.8185e-01, 9.8841e-01,\n",
      "          9.9835e-01, 8.2326e-01, 9.5119e-01, 1.3385e-01, 8.7332e-01,\n",
      "          6.5252e-02],\n",
      "         [4.5777e-02, 3.1106e-01, 2.7298e-01, 6.3446e-01, 4.5540e-01,\n",
      "          9.9102e-01, 7.5909e-01, 5.2908e-01, 5.3509e-01, 8.7884e-01,\n",
      "          9.6591e-01, 8.1415e-01, 8.7655e-01, 3.2317e-03, 4.1994e-01,\n",
      "          2.9379e-02],\n",
      "         [5.6642e-02, 5.4154e-01, 3.5326e-02, 7.8497e-01, 6.0395e-01,\n",
      "          8.3870e-01, 9.0809e-01, 3.8880e-01, 9.5149e-01, 9.8269e-01,\n",
      "          9.8631e-01, 4.7680e-01, 5.0090e-01, 1.8571e-02, 1.0308e-01,\n",
      "          1.9423e-01],\n",
      "         [4.2337e-01, 1.1745e-01, 7.6450e-01, 9.9889e-01, 9.8221e-01,\n",
      "          3.3561e-01, 9.5490e-01, 1.5501e-01, 8.1755e-01, 7.6363e-01,\n",
      "          9.1282e-01, 7.0314e-01, 9.9662e-01, 5.8818e-03, 6.9599e-02,\n",
      "          1.0593e-02],\n",
      "         [2.1288e-01, 7.9991e-03, 9.5109e-01, 1.0425e-01, 2.6451e-01,\n",
      "          2.5659e-01, 3.1568e-03, 8.6459e-01, 1.2340e-03, 5.2841e-02,\n",
      "          2.0500e-01, 9.8579e-01, 7.9699e-01, 8.2051e-02, 1.2927e-03,\n",
      "          1.9242e-01],\n",
      "         [5.0078e-01, 1.9359e-02, 4.1637e-01, 2.9717e-01, 5.5743e-01,\n",
      "          1.8054e-03, 3.8385e-02, 4.9262e-01, 1.0570e-01, 3.8924e-02,\n",
      "          2.2773e-02, 9.8720e-01, 1.8493e-01, 5.2408e-01, 3.6074e-04,\n",
      "          8.0646e-01],\n",
      "         [1.6339e-01, 3.3432e-01, 1.7059e-01, 1.7846e-01, 5.3958e-01,\n",
      "          2.7322e-03, 8.8143e-02, 1.8903e-01, 4.1592e-01, 7.4685e-01,\n",
      "          7.6318e-01, 9.1869e-01, 2.5544e-01, 5.1842e-01, 3.5211e-01,\n",
      "          7.9053e-01],\n",
      "         [2.9913e-01, 2.2252e-01, 9.9765e-01, 9.6586e-01, 6.8985e-01,\n",
      "          5.8188e-02, 1.9937e-01, 7.1074e-01, 1.9644e-01, 1.8598e-01,\n",
      "          4.7738e-01, 5.0148e-01, 9.4455e-01, 5.3531e-03, 1.5637e-02,\n",
      "          1.0609e-02],\n",
      "         [9.1992e-01, 1.2991e-02, 3.9638e-01, 9.5296e-01, 9.3700e-01,\n",
      "          5.8673e-03, 1.7792e-01, 4.4185e-02, 3.0448e-01, 8.0211e-02,\n",
      "          1.2892e-01, 9.9050e-01, 4.4179e-01, 6.4661e-01, 1.0480e-03,\n",
      "          8.1746e-01],\n",
      "         [8.7455e-01, 1.6436e-02, 4.9827e-03, 8.5555e-01, 9.5921e-01,\n",
      "          9.5297e-03, 8.2782e-01, 1.1017e-02, 9.1760e-01, 6.9800e-01,\n",
      "          6.3485e-01, 9.9447e-01, 3.3896e-02, 9.6453e-01, 1.9545e-01,\n",
      "          9.8786e-01],\n",
      "         [2.3724e-01, 2.4286e-01, 4.1401e-01, 7.1479e-01, 9.8059e-01,\n",
      "          7.6039e-03, 7.9667e-01, 1.0341e-01, 8.7980e-01, 9.5531e-01,\n",
      "          9.8153e-01, 7.9113e-01, 7.5910e-01, 3.2730e-01, 6.5611e-01,\n",
      "          4.0663e-01],\n",
      "         [6.8523e-01, 1.6083e-01, 9.7265e-01, 9.9898e-01, 9.9786e-01,\n",
      "          7.4197e-02, 6.2599e-01, 2.1341e-01, 3.5192e-01, 2.6941e-01,\n",
      "          4.7129e-01, 4.7052e-01, 9.4222e-01, 3.9188e-02, 9.4675e-03,\n",
      "          1.6456e-02],\n",
      "         [8.1138e-01, 5.4464e-03, 3.7518e-02, 9.1078e-01, 7.8612e-01,\n",
      "          9.2970e-02, 5.7518e-01, 6.5215e-02, 6.8204e-01, 4.7938e-01,\n",
      "          4.9836e-01, 9.9750e-01, 4.1240e-01, 3.0446e-01, 6.2039e-03,\n",
      "          8.3385e-01],\n",
      "         [1.9003e-01, 1.3997e-01, 2.6161e-04, 3.7230e-01, 4.2739e-01,\n",
      "          2.6396e-01, 8.6944e-01, 1.9144e-01, 8.5161e-01, 9.8505e-01,\n",
      "          9.7686e-01, 9.9385e-01, 1.8616e-01, 4.3663e-01, 6.5116e-01,\n",
      "          9.3526e-01],\n",
      "         [6.3758e-03, 4.2180e-01, 8.0465e-01, 6.3753e-01, 1.7482e-01,\n",
      "          4.9441e-01, 5.0264e-01, 8.4518e-01, 3.2074e-01, 7.3865e-01,\n",
      "          8.6751e-01, 7.4088e-01, 9.9598e-01, 9.8731e-04, 4.0032e-01,\n",
      "          7.4338e-03],\n",
      "         [1.2055e-01, 1.8740e-01, 9.4228e-01, 7.8140e-01, 3.6958e-01,\n",
      "          4.9260e-01, 3.9224e-01, 7.6709e-01, 8.7232e-02, 1.8938e-01,\n",
      "          4.1846e-01, 5.6988e-01, 7.0146e-01, 5.5072e-03, 1.3742e-03,\n",
      "          8.6007e-02]]])\n",
      "TensorFlow Basic Model Output: [[3.57232213e-01 4.83077317e-01 3.21702063e-01 9.62339520e-01\n",
      "  5.44033051e-01 6.60195708e-01 9.95018661e-01 3.73347670e-01\n",
      "  7.81851292e-01 9.88408864e-01 9.98347521e-01 8.23257387e-01\n",
      "  9.51187968e-01 1.33854970e-01 8.73318195e-01 6.52517453e-02\n",
      "  4.57774997e-02 3.11057568e-01 2.72976041e-01 6.34455085e-01\n",
      "  4.55401689e-01 9.91024733e-01 7.59088993e-01 5.29080808e-01\n",
      "  5.35093784e-01 8.78842413e-01 9.65907812e-01 8.14149439e-01\n",
      "  8.76549482e-01 3.23166419e-03 4.19935286e-01 2.93786861e-02\n",
      "  5.66421859e-02 5.41537523e-01 3.53259370e-02 7.84972310e-01\n",
      "  6.03945017e-01 8.38702083e-01 9.08087730e-01 3.88801754e-01\n",
      "  9.51492488e-01 9.82689023e-01 9.86314654e-01 4.76803571e-01\n",
      "  5.00899136e-01 1.85709819e-02 1.03076905e-01 1.94234550e-01\n",
      "  4.23373699e-01 1.17446095e-01 7.64497101e-01 9.98888493e-01\n",
      "  9.82214570e-01 3.35606694e-01 9.54902351e-01 1.55010834e-01\n",
      "  8.17547679e-01 7.63632178e-01 9.12824035e-01 7.03142285e-01\n",
      "  9.96616840e-01 5.88184362e-03 6.95988983e-02 1.05933612e-02\n",
      "  2.12877616e-01 7.99911935e-03 9.51091766e-01 1.04254708e-01\n",
      "  2.64506042e-01 2.56594628e-01 3.15678446e-03 8.64587665e-01\n",
      "  1.23402383e-03 5.28405160e-02 2.04996645e-01 9.85785842e-01\n",
      "  7.96987891e-01 8.20507780e-02 1.29268784e-03 1.92418933e-01\n",
      "  5.00782311e-01 1.93591081e-02 4.16373104e-01 2.97172904e-01\n",
      "  5.57428122e-01 1.80544984e-03 3.83853279e-02 4.92624104e-01\n",
      "  1.05703786e-01 3.89236994e-02 2.27727517e-02 9.87201095e-01\n",
      "  1.84929326e-01 5.24077058e-01 3.60735576e-04 8.06462228e-01\n",
      "  1.63393706e-01 3.34315389e-01 1.70586184e-01 1.78462937e-01\n",
      "  5.39582729e-01 2.73218472e-03 8.81430134e-02 1.89029187e-01\n",
      "  4.15919125e-01 7.46853709e-01 7.63181567e-01 9.18691397e-01\n",
      "  2.55443126e-01 5.18415332e-01 3.52109820e-01 7.90525854e-01\n",
      "  2.99134105e-01 2.22518861e-01 9.97653544e-01 9.65861976e-01\n",
      "  6.89853668e-01 5.81882149e-02 1.99367106e-01 7.10739732e-01\n",
      "  1.96436599e-01 1.85983658e-01 4.77382600e-01 5.01480937e-01\n",
      "  9.44546819e-01 5.35311177e-03 1.56374667e-02 1.06086796e-02\n",
      "  9.19916630e-01 1.29908975e-02 3.96382332e-01 9.52958167e-01\n",
      "  9.36999679e-01 5.86732617e-03 1.77921146e-01 4.41846251e-02\n",
      "  3.04482847e-01 8.02115053e-02 1.28919661e-01 9.90502596e-01\n",
      "  4.41786408e-01 6.46609306e-01 1.04798179e-03 8.17458153e-01\n",
      "  8.74549508e-01 1.64358672e-02 4.98267496e-03 8.55554044e-01\n",
      "  9.59214091e-01 9.52967070e-03 8.27818632e-01 1.10169053e-02\n",
      "  9.17604685e-01 6.98002458e-01 6.34847879e-01 9.94470179e-01\n",
      "  3.38960551e-02 9.64529276e-01 1.95446759e-01 9.87864792e-01\n",
      "  2.37243444e-01 2.42855191e-01 4.14008319e-01 7.14788198e-01\n",
      "  9.80586767e-01 7.60391634e-03 7.96666384e-01 1.03408299e-01\n",
      "  8.79802108e-01 9.55314875e-01 9.81531799e-01 7.91126013e-01\n",
      "  7.59101093e-01 3.27301085e-01 6.56107008e-01 4.06631827e-01\n",
      "  6.85233474e-01 1.60829976e-01 9.72645402e-01 9.98982131e-01\n",
      "  9.97861922e-01 7.41970986e-02 6.25991881e-01 2.13413447e-01\n",
      "  3.51916313e-01 2.69409060e-01 4.71292436e-01 4.70524073e-01\n",
      "  9.42216039e-01 3.91883105e-02 9.46748350e-03 1.64562594e-02\n",
      "  8.11382532e-01 5.44641819e-03 3.75184491e-02 9.10776258e-01\n",
      "  7.86120057e-01 9.29698944e-02 5.75178385e-01 6.52152896e-02\n",
      "  6.82038188e-01 4.79376137e-01 4.98357773e-01 9.97499943e-01\n",
      "  4.12399888e-01 3.04455817e-01 6.20391779e-03 8.33852172e-01\n",
      "  1.90025538e-01 1.39968783e-01 2.61611480e-04 3.72300446e-01\n",
      "  4.27388191e-01 2.63962865e-01 8.69443238e-01 1.91437781e-01\n",
      "  8.51610661e-01 9.85045612e-01 9.76858616e-01 9.93846118e-01\n",
      "  1.86162621e-01 4.36632395e-01 6.51163340e-01 9.35263872e-01\n",
      "  6.37583993e-03 4.21798557e-01 8.04645717e-01 6.37525082e-01\n",
      "  1.74816191e-01 4.94409949e-01 5.02642274e-01 8.45181823e-01\n",
      "  3.20738941e-01 7.38646269e-01 8.67506683e-01 7.40876436e-01\n",
      "  9.95983660e-01 9.87309497e-04 4.00323272e-01 7.43381958e-03\n",
      "  1.20552287e-01 1.87401056e-01 9.42277551e-01 7.81402886e-01\n",
      "  3.69577497e-01 4.92598057e-01 3.92241776e-01 7.67088771e-01\n",
      "  8.72324258e-02 1.89384505e-01 4.18464899e-01 5.69880784e-01\n",
      "  7.01465011e-01 5.50722983e-03 1.37420627e-03 8.60068649e-02]]\n",
      "PyTorch Basic Model Output: [[3.57232213e-01 4.83077288e-01 3.21702123e-01 9.62339520e-01\n",
      "  5.44033051e-01 6.60195708e-01 9.95018721e-01 3.73347700e-01\n",
      "  7.81851292e-01 9.88408864e-01 9.98347521e-01 8.23257446e-01\n",
      "  9.51187968e-01 1.33854970e-01 8.73318195e-01 6.52517453e-02\n",
      "  4.57774922e-02 3.11057627e-01 2.72975981e-01 6.34455144e-01\n",
      "  4.55401689e-01 9.91024733e-01 7.59088993e-01 5.29080749e-01\n",
      "  5.35093844e-01 8.78842354e-01 9.65907812e-01 8.14149439e-01\n",
      "  8.76549482e-01 3.23166442e-03 4.19935286e-01 2.93786842e-02\n",
      "  5.66421822e-02 5.41537523e-01 3.53259370e-02 7.84972310e-01\n",
      "  6.03945017e-01 8.38702023e-01 9.08087730e-01 3.88801724e-01\n",
      "  9.51492488e-01 9.82689023e-01 9.86314595e-01 4.76803541e-01\n",
      "  5.00899136e-01 1.85709819e-02 1.03076920e-01 1.94234565e-01\n",
      "  4.23373699e-01 1.17446065e-01 7.64497101e-01 9.98888493e-01\n",
      "  9.82214510e-01 3.35606635e-01 9.54902291e-01 1.55010879e-01\n",
      "  8.17547679e-01 7.63632119e-01 9.12824035e-01 7.03142345e-01\n",
      "  9.96616840e-01 5.88184316e-03 6.95989057e-02 1.05933612e-02\n",
      "  2.12877631e-01 7.99911655e-03 9.51091707e-01 1.04254700e-01\n",
      "  2.64506012e-01 2.56594628e-01 3.15678585e-03 8.64587665e-01\n",
      "  1.23402418e-03 5.28405122e-02 2.04996660e-01 9.85785902e-01\n",
      "  7.96987832e-01 8.20507929e-02 1.29268609e-03 1.92418933e-01\n",
      "  5.00782311e-01 1.93591118e-02 4.16373134e-01 2.97172904e-01\n",
      "  5.57428181e-01 1.80544797e-03 3.83853205e-02 4.92624074e-01\n",
      "  1.05703771e-01 3.89236920e-02 2.27727517e-02 9.87201095e-01\n",
      "  1.84929281e-01 5.24076998e-01 3.60735576e-04 8.06462288e-01\n",
      "  1.63393706e-01 3.34315389e-01 1.70586184e-01 1.78462952e-01\n",
      "  5.39582670e-01 2.73218565e-03 8.81430209e-02 1.89029187e-01\n",
      "  4.15919095e-01 7.46853650e-01 7.63181567e-01 9.18691456e-01\n",
      "  2.55443126e-01 5.18415332e-01 3.52109849e-01 7.90525794e-01\n",
      "  2.99134135e-01 2.22518846e-01 9.97653604e-01 9.65861917e-01\n",
      "  6.89853668e-01 5.81882372e-02 1.99367106e-01 7.10739672e-01\n",
      "  1.96436629e-01 1.85983658e-01 4.77382571e-01 5.01480997e-01\n",
      "  9.44546878e-01 5.35311177e-03 1.56374630e-02 1.06086768e-02\n",
      "  9.19916570e-01 1.29908994e-02 3.96382332e-01 9.52958167e-01\n",
      "  9.36999619e-01 5.86732430e-03 1.77921161e-01 4.41846065e-02\n",
      "  3.04482877e-01 8.02114978e-02 1.28919661e-01 9.90502596e-01\n",
      "  4.41786349e-01 6.46609187e-01 1.04798179e-03 8.17458212e-01\n",
      "  8.74549389e-01 1.64358709e-02 4.98267915e-03 8.55554104e-01\n",
      "  9.59214091e-01 9.52967070e-03 8.27818692e-01 1.10168988e-02\n",
      "  9.17604685e-01 6.98002458e-01 6.34847879e-01 9.94470119e-01\n",
      "  3.38960513e-02 9.64529276e-01 1.95446759e-01 9.87864852e-01\n",
      "  2.37243503e-01 2.42855206e-01 4.14008290e-01 7.14788258e-01\n",
      "  9.80586767e-01 7.60391494e-03 7.96666265e-01 1.03408307e-01\n",
      "  8.79802108e-01 9.55314934e-01 9.81531799e-01 7.91125953e-01\n",
      "  7.59101033e-01 3.27301085e-01 6.56107008e-01 4.06631827e-01\n",
      "  6.85233533e-01 1.60829961e-01 9.72645402e-01 9.98982131e-01\n",
      "  9.97861922e-01 7.41971508e-02 6.25991821e-01 2.13413417e-01\n",
      "  3.51916254e-01 2.69409090e-01 4.71292406e-01 4.70524073e-01\n",
      "  9.42216039e-01 3.91883105e-02 9.46748443e-03 1.64562650e-02\n",
      "  8.11382651e-01 5.44641819e-03 3.75184305e-02 9.10776258e-01\n",
      "  7.86120117e-01 9.29698795e-02 5.75178385e-01 6.52152821e-02\n",
      "  6.82038188e-01 4.79376167e-01 4.98357713e-01 9.97499943e-01\n",
      "  4.12399888e-01 3.04455936e-01 6.20391779e-03 8.33852291e-01\n",
      "  1.90025538e-01 1.39968783e-01 2.61611422e-04 3.72300446e-01\n",
      "  4.27388161e-01 2.63962865e-01 8.69443178e-01 1.91437781e-01\n",
      "  8.51610661e-01 9.85045612e-01 9.76858675e-01 9.93846118e-01\n",
      "  1.86162621e-01 4.36632395e-01 6.51163340e-01 9.35263872e-01\n",
      "  6.37584087e-03 4.21798557e-01 8.04645777e-01 6.37525082e-01\n",
      "  1.74816176e-01 4.94409919e-01 5.02642214e-01 8.45181823e-01\n",
      "  3.20738882e-01 7.38646269e-01 8.67506683e-01 7.40876496e-01\n",
      "  9.95983660e-01 9.87308566e-04 4.00323242e-01 7.43382145e-03\n",
      "  1.20552324e-01 1.87401041e-01 9.42277551e-01 7.81402826e-01\n",
      "  3.69577557e-01 4.92598057e-01 3.92241716e-01 7.67088771e-01\n",
      "  8.72324109e-02 1.89384505e-01 4.18464839e-01 5.69880843e-01\n",
      "  7.01464951e-01 5.50723076e-03 1.37420651e-03 8.60068873e-02]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test TensorFlow Basic Model\n",
    "output_tf_basic = model_tf_basic.predict(controlled_input)\n",
    "\n",
    "# Test PyTorch Basic Model\n",
    "model_pt_basic.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt_basic = model_pt_basic(controlled_input_pt)\n",
    "\n",
    "\n",
    "# Compare outputs\n",
    "print(\"TensorFlow Basic Model Output:\", output_tf_basic)\n",
    "print(\"PyTorch Basic Model Output:\", output_pt_basic.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a basic LeNet model in PyTorch with two convolutional layers\n",
    "class BasicLeNetPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicLeNetPT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(256, 120) # 120 * 256\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        x = x.reshape(x.size(0),-1).reshape(16,-1)  # Reshape to [batch_size, 16*4*4]\n",
    "        x = np.transpose(x, (1,0))\n",
    "        x = x.reshape(1,-1)\n",
    "        \n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "model_pt_basic = BasicLeNetPT()\n",
    "\n",
    "# Create a basic LeNet model in TensorFlow with two convolutional layers\n",
    "model_tf_basic = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='sigmoid'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[-0.09746441 -0.07356118  0.12461983 ... -0.20353669  0.20595847\n",
      "  -0.17135966]\n",
      " [ 0.24493529  0.15121421 -0.2389823  ...  0.23655343 -0.41860393\n",
      "   0.23539582]\n",
      " [-0.0257456  -0.12429156 -0.1322509  ... -0.44357076  0.09737598\n",
      "  -0.14918238]\n",
      " ...\n",
      " [ 0.22231688 -0.01645891  0.00374787 ...  0.04033783  0.18552913\n",
      "  -0.15830086]\n",
      " [ 0.00637587 -0.32641515  0.23852865 ...  0.1092146  -0.2395123\n",
      "   0.6130949 ]\n",
      " [-0.01752851  0.07713001  0.03625944 ...  0.03375389  0.10262422\n",
      "  -0.1099361 ]]\n",
      "w_T: torch.Size([120, 256])\n"
     ]
    }
   ],
   "source": [
    "# Transfer weights for the first Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_tf_basic.layers[0].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_tf_basic.layers[2].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "model_tf_basic.layers[5].set_weights([weights, biases])\n",
    "\n",
    "\n",
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt_basic.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt_basic.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "print ('w:',weights)\n",
    "model_pt_basic.fc1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1,0))))\n",
    "print ('w_T:',model_pt_basic.fc1.weight.shape)\n",
    "model_pt_basic.fc1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'controlled_input_tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Select the image for TensorFlow\u001b[39;00m\n\u001b[1;32m      2\u001b[0m controlled_input \u001b[38;5;241m=\u001b[39m test_images[\u001b[38;5;241m36\u001b[39m][np\u001b[38;5;241m.\u001b[39mnewaxis, ]  \u001b[38;5;66;03m# No reshape needed as it's already in (28, 28, 1) format\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m controlled_input_pt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mcontrolled_input_tf\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'controlled_input_tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the image for TensorFlow\n",
    "controlled_input = test_images[36][np.newaxis, ]  # No reshape needed as it's already in (28, 28, 1) format\n",
    "controlled_input_pt = torch.tensor(controlled_input_tf).float().permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "TensorFlow Basic Model Output: [[8.18893015e-01 6.09264314e-01 1.66922715e-03 4.11255181e-01\n",
      "  2.49907449e-02 2.99167298e-02 7.96839595e-01 5.64328372e-01\n",
      "  3.26452255e-01 6.82837749e-03 8.49843144e-01 6.74841583e-01\n",
      "  8.32838356e-01 1.35930413e-02 9.28429067e-01 2.79215068e-01\n",
      "  1.82010308e-01 8.45037960e-03 9.92652118e-01 9.68585014e-01\n",
      "  2.62810066e-02 1.11930847e-01 7.52481520e-01 9.07907069e-01\n",
      "  2.90007144e-03 8.81928265e-01 8.32566202e-01 9.12400186e-01\n",
      "  8.92612875e-01 1.09533019e-01 9.80841100e-01 7.19543278e-01\n",
      "  9.26168680e-01 9.86669302e-01 5.43678820e-01 9.56499994e-01\n",
      "  1.10772308e-02 4.64457721e-01 9.96092975e-01 4.27115505e-04\n",
      "  3.59919071e-01 9.72848415e-01 8.75910699e-01 1.85742781e-01\n",
      "  7.08810687e-02 7.54384637e-01 7.68655062e-01 2.86270827e-01\n",
      "  2.97551183e-03 7.74625782e-03 8.78870487e-01 8.34008455e-01\n",
      "  9.68998671e-03 9.33030024e-02 9.78342414e-01 9.95083451e-01\n",
      "  3.98346394e-01 3.37340939e-03 1.96328619e-04 5.10417342e-01\n",
      "  9.61192429e-01 9.92735744e-01 3.33790034e-01 8.46149623e-01\n",
      "  8.38303566e-01 1.38847098e-01 9.29634929e-01 9.89429057e-01\n",
      "  7.74056196e-01 8.01210757e-03 3.65361452e-01 7.33494684e-02\n",
      "  5.59661627e-01 2.18880102e-01 9.40548897e-01 9.49010432e-01\n",
      "  9.67209280e-01 1.67210713e-01 7.77952850e-01 1.46899624e-02\n",
      "  9.45390761e-01 8.73562276e-01 1.19081489e-03 3.10716149e-03\n",
      "  1.81131750e-01 9.77498293e-01 3.27539504e-01 1.08271111e-02\n",
      "  4.02369916e-01 4.13982481e-01 6.91337466e-01 1.12241425e-01\n",
      "  8.02324414e-01 1.56026319e-01 9.14678812e-01 3.05642709e-02\n",
      "  1.96535766e-01 1.82458743e-01 3.57173860e-01 3.33318138e-04\n",
      "  9.97613192e-01 2.02667490e-02 9.62973654e-01 2.32640117e-01\n",
      "  9.53050792e-01 2.17204541e-01 9.77334440e-01 3.73849005e-01\n",
      "  2.97618820e-03 8.48382950e-01 5.96779108e-01 9.65401232e-01\n",
      "  1.06444792e-03 7.08011985e-01 9.95790422e-01 8.68220404e-02\n",
      "  9.68772292e-01 9.25553918e-01 7.11481692e-03 9.90346849e-01]]\n",
      "PyTorch Basic Model Output: [[8.18893015e-01 6.09264374e-01 1.66922715e-03 4.11255181e-01\n",
      "  2.49907747e-02 2.99167503e-02 7.96839535e-01 5.64328611e-01\n",
      "  3.26452017e-01 6.82837097e-03 8.49843264e-01 6.74841762e-01\n",
      "  8.32838297e-01 1.35930646e-02 9.28429067e-01 2.79215187e-01\n",
      "  1.82010233e-01 8.45040381e-03 9.92652118e-01 9.68585014e-01\n",
      "  2.62809936e-02 1.11930944e-01 7.52481520e-01 9.07907128e-01\n",
      "  2.90007005e-03 8.81928384e-01 8.32566082e-01 9.12400246e-01\n",
      "  8.92612755e-01 1.09532997e-01 9.80840981e-01 7.19543278e-01\n",
      "  9.26168680e-01 9.86669421e-01 5.43678820e-01 9.56499994e-01\n",
      "  1.10772308e-02 4.64457810e-01 9.96092975e-01 4.27114428e-04\n",
      "  3.59919131e-01 9.72848296e-01 8.75910699e-01 1.85742900e-01\n",
      "  7.08810240e-02 7.54384875e-01 7.68655062e-01 2.86270767e-01\n",
      "  2.97550624e-03 7.74624804e-03 8.78870487e-01 8.34008455e-01\n",
      "  9.68998205e-03 9.33030769e-02 9.78342414e-01 9.95083451e-01\n",
      "  3.98346633e-01 3.37340636e-03 1.96328241e-04 5.10417104e-01\n",
      "  9.61192429e-01 9.92735744e-01 3.33790034e-01 8.46149683e-01\n",
      "  8.38303387e-01 1.38846979e-01 9.29634929e-01 9.89429057e-01\n",
      "  7.74056196e-01 8.01209267e-03 3.65361214e-01 7.33495057e-02\n",
      "  5.59661508e-01 2.18879983e-01 9.40549016e-01 9.49010432e-01\n",
      "  9.67209280e-01 1.67210609e-01 7.77952909e-01 1.46899894e-02\n",
      "  9.45390642e-01 8.73562396e-01 1.19081419e-03 3.10716173e-03\n",
      "  1.81131780e-01 9.77498412e-01 3.27539444e-01 1.08270813e-02\n",
      "  4.02369767e-01 4.13982093e-01 6.91337407e-01 1.12241521e-01\n",
      "  8.02324414e-01 1.56026378e-01 9.14678693e-01 3.05643138e-02\n",
      "  1.96535811e-01 1.82458639e-01 3.57173800e-01 3.33319127e-04\n",
      "  9.97613192e-01 2.02667583e-02 9.62973654e-01 2.32640162e-01\n",
      "  9.53050792e-01 2.17204630e-01 9.77334440e-01 3.73848975e-01\n",
      "  2.97619100e-03 8.48383069e-01 5.96779108e-01 9.65401232e-01\n",
      "  1.06445001e-03 7.08011746e-01 9.95790422e-01 8.68220031e-02\n",
      "  9.68772173e-01 9.25553918e-01 7.11485092e-03 9.90346849e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Test TensorFlow Basic Model\n",
    "output_tf_basic = model_tf_basic.predict(controlled_input)\n",
    "\n",
    "# Test PyTorch Basic Model\n",
    "model_pt_basic.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt_basic = model_pt_basic(controlled_input_pt)\n",
    "\n",
    "\n",
    "# Compare outputs\n",
    "print(\"TensorFlow Basic Model Output:\", output_tf_basic)\n",
    "print(\"PyTorch Basic Model Output:\", output_pt_basic.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define a basic LeNet model in PyTorch with two convolutional layers\n",
    "class BasicLeNetPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicLeNetPT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(120, 256) # 256 * 120\n",
    "        self.fc2 = nn.Linear(120,84)         # 120 inputs, 84 outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), (2, 2)).permute(3,2,0,1) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # Flattening the tensor to the correct size\n",
    "        x = x.reshape(x.size(0),-1).reshape(1,-1)  # Reshape to [batch_size, 16*4*4]\n",
    "        \n",
    "        # Print the shape of x before and after each layer\n",
    "        print(\"Before fc1:\", x.shape)\n",
    "        \n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        \n",
    "        print(\"After fc1:\", x.shape)\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        print(\"After fc2:\", x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "model_pt_basic = BasicLeNetPT()\n",
    "\n",
    "# Create a basic LeNet model in TensorFlow with two convolutional layers\n",
    "model_tf_basic = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='sigmoid'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(84, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_tf_basic.layers[0].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_tf_basic.layers[2].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "model_tf_basic.layers[5].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from the original model_tf\n",
    "weights, biases = model_tf.layers[6].get_weights()\n",
    "model_tf_basic.layers[6].set_weights([weights, biases])\n",
    "\n",
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt_basic.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt_basic.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt_basic.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "model_pt_basic.fc1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1,0))))\n",
    "model_pt_basic.fc1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[6].get_weights()\n",
    "model_pt_basic.fc2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1,0))))\n",
    "model_pt_basic.fc2.bias = nn.Parameter(torch.from_numpy(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a controlled input (e.g., an array of ones)\n",
    "controlled_input = np.ones((1, 28, 28, 1), dtype=np.float32)  # For TensorFlow\n",
    "controlled_input_pt = torch.from_numpy(controlled_input).permute(0, 3, 1, 2)  # For PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "Before fc1: torch.Size([1, 256])\n",
      "After fc1: torch.Size([1, 120])\n",
      "After fc2: torch.Size([1, 84])\n",
      "TensorFlow Basic Model Output: [[0.7160134  0.8385422  0.0253077  0.42892176 0.6184138  0.9969837\n",
      "  0.09171487 0.01182156 0.04299246 0.4810178  0.9516474  0.09384901\n",
      "  0.8192958  0.55231595 0.10896716 0.00647116 0.04556889 0.8126056\n",
      "  0.82992846 0.5289272  0.894237   0.08265778 0.9708183  0.24809329\n",
      "  0.79544413 0.00390048 0.02803985 0.7674697  0.04256167 0.06272971\n",
      "  0.3221807  0.43452185 0.6216037  0.04312156 0.97908485 0.72737664\n",
      "  0.9310374  0.14843705 0.9657128  0.7040428  0.14954226 0.7755475\n",
      "  0.2979573  0.5029429  0.85015994 0.19273664 0.04996477 0.02114206\n",
      "  0.9176138  0.9626188  0.39863586 0.9899365  0.97770965 0.0713995\n",
      "  0.02932361 0.17433517 0.99833655 0.8545451  0.11654612 0.21318336\n",
      "  0.83583117 0.02372023 0.0214206  0.978412   0.852728   0.12194854\n",
      "  0.23547943 0.55145293 0.06977712 0.49735156 0.98175037 0.28126732\n",
      "  0.9684286  0.8804305  0.87427825 0.25589195 0.05280343 0.29675412\n",
      "  0.08128658 0.0786276  0.9940673  0.6950344  0.8771883  0.98410296]]\n",
      "PyTorch Basic Model Output: [[0.7160134  0.83854216 0.02530768 0.4289217  0.6184138  0.9969837\n",
      "  0.09171487 0.01182156 0.04299246 0.48101768 0.9516474  0.09384903\n",
      "  0.8192958  0.552316   0.10896713 0.00647116 0.04556889 0.8126055\n",
      "  0.82992846 0.52892715 0.894237   0.08265776 0.9708183  0.24809335\n",
      "  0.795444   0.00390048 0.02803986 0.7674695  0.04256171 0.06272968\n",
      "  0.32218087 0.43452194 0.6216038  0.04312156 0.97908485 0.72737664\n",
      "  0.93103755 0.14843704 0.9657128  0.7040428  0.14954224 0.77554744\n",
      "  0.29795715 0.502943   0.8501598  0.19273663 0.04996475 0.02114206\n",
      "  0.9176138  0.9626187  0.39863595 0.9899365  0.97770965 0.0713995\n",
      "  0.02932359 0.17433527 0.99833655 0.85454524 0.11654617 0.21318336\n",
      "  0.8358312  0.02372022 0.02142061 0.978412   0.852728   0.12194851\n",
      "  0.23547933 0.55145293 0.06977714 0.4973515  0.98175037 0.28126743\n",
      "  0.9684285  0.8804305  0.87427825 0.25589207 0.05280342 0.2967542\n",
      "  0.08128664 0.07862758 0.9940673  0.69503444 0.8771883  0.98410296]]\n"
     ]
    }
   ],
   "source": [
    "# Test TensorFlow Basic Model\n",
    "output_tf_basic = model_tf_basic.predict(controlled_input)\n",
    "\n",
    "# Test PyTorch Basic Model\n",
    "model_pt_basic.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt_basic = model_pt_basic(controlled_input_pt)\n",
    "\n",
    "\n",
    "# Compare outputs\n",
    "print(\"TensorFlow Basic Model Output:\", output_tf_basic)\n",
    "print(\"PyTorch Basic Model Output:\", output_pt_basic.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
