{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Convolutional encoder\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # 1 input channel, 6 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel\n",
    "\n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120) # 256 * 120\n",
    "        self.fc2 = nn.Linear(120, 84)         # 120 inputs, 84 outputs\n",
    "        self.fc3 = nn.Linear(84, 10)          # 84 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.sigmoid(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # Flattening\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)  # No activation function here, will use CrossEntropyLoss later\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_(nn.Module):\n",
    "    def __init__(self, features=(6, 16, 120, 84)):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        features = list(features)\n",
    "        if len(features) == 3:\n",
    "            features.append(None)\n",
    "\n",
    "        f1, f2, f3, f4 = features\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, f1, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(f1, f2, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(f2 * 4 * 4, f3)\n",
    "        if f4 is not None:\n",
    "            self.fc2 = nn.Linear(f3, f4)\n",
    "            self.fc3 = nn.Linear(f4, 10)\n",
    "        else:\n",
    "            self.fc2 = nn.Linear(f3, 10)\n",
    "            self.fc3 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Note that tanh activation does a better job at keeping activations in a predictable\n",
    "        # range. This means that fewer bits are needed for quantization!\n",
    "        x = torch.tanh(self.conv1(x))\n",
    "        x = torch.nn.functional.avg_pool2d(x, 2)\n",
    "        x = torch.tanh(self.conv2(x))\n",
    "        x = torch.nn.functional.avg_pool2d(x, 2)\n",
    "        x = x.flatten(1)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        if self.fc3 is not None:\n",
    "            x = self.fc3(torch.tanh(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def load_dataset(batch_size=256):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, transform=ToTensor(), download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=False, transform=ToTensor())\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def train(model, train_dataset, learning_rate=0.001, num_epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        # Wrap the train_dataset with tqdm for a progress bar\n",
    "        for images, labels in tqdm(train_dataset, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print average loss for the epoch\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {total_loss / len(train_dataset):.4f}')\n",
    "\n",
    "\n",
    "def evaluate(model, test_dataset):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for images, labels in test_dataset:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.8762, -5.5624,  1.3357, -1.6389, -3.0630,  1.1249,  0.0394, -1.9192,\n",
      "         -2.3672, -2.1795]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "img = test_dataset[10][0]\n",
    "img = img.unsqueeze(0)  # Add a batch dimension\n",
    "images = img.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "\n",
    "print (outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mnist_images(dataset, indices = []):\n",
    "\n",
    "    if not indices:\n",
    "        fig, axes = plt.subplots(1, len(dataset), figsize=(12, 4))\n",
    "        \n",
    "        for i in range(len(axes)):\n",
    "            image, label = dataset[i]\n",
    "            ax = axes[i]\n",
    "            \n",
    "            image = image.squeeze()  # Remove channel dimension\n",
    "\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(f'Label: {label}')\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(indices), figsize=(12, 4))\n",
    "    if len(indices) == 1:  # If only one index is provided, wrap axes in a list\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, idx in zip(axes, indices):\n",
    "        image, label = dataset[idx]\n",
    "        image = image.squeeze()  # Remove channel dimension\n",
    "\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(f'Label: {label}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_loader, test_loader, train_dataset, test_dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 235/235 [00:01<00:00, 139.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 2.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 235/235 [00:01<00:00, 146.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 235/235 [00:01<00:00, 149.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.3671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 235/235 [00:01<00:00, 149.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.2793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 235/235 [00:01<00:00, 149.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 235/235 [00:01<00:00, 149.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.1937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 235/235 [00:01<00:00, 150.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 235/235 [00:01<00:00, 150.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Average Loss: 0.1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 235/235 [00:01<00:00, 149.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Average Loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 235/235 [00:01<00:00, 150.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Average Loss: 0.1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model (in a separate cell)\n",
    "model = LeNet().to(device)\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.51%\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mnist_images(test_dataset, [0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl, os, json\n",
    "\n",
    "run_args = ezkl.PyRunArgs()\n",
    "run_args.input_visibility = \"public\"\n",
    "run_args.param_visibility = \"fixed\"\n",
    "run_args.output_visibility = \"public\"\n",
    "# run_args.num_inner_cols = 2\n",
    "run_args.variables = [(\"batch_size\", 0)]\n",
    "\n",
    "# Capture set of data points\n",
    "num_data_points = 8\n",
    "\n",
    "# Fetch data points from the train_dataset\n",
    "data_points = []\n",
    "for i, (data_point, _) in enumerate(test_loader):\n",
    "    if i >= num_data_points:\n",
    "        break\n",
    "    data_points.append(data_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(data_points).dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_witness_LN(folder, model, data_point):\n",
    "    model_path = os.path.join(folder, 'network.onnx')\n",
    "    compiled_model_path = os.path.join(folder, 'network.compiled')\n",
    "    settings_path = os.path.join(folder, 'settings.json') \n",
    "    witness_path = os.path.join(folder, 'witness.json')\n",
    "    data_path = os.path.join(folder, 'input.json')\n",
    "\n",
    "    # cal_path = os.path.join(folder, \"cal_data.json\")\n",
    "    # srs_path = os.path.join(folder, 'kzg.srs')\n",
    "\n",
    "    model.eval()\n",
    "    # Verify the device (CPU or CUDA) and transfer the data point to the same device as the model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    data_point = data_point.to(device).unsqueeze(0)  # Add a batch dimension\n",
    "    # _, pred = torch.max(model(data_point),1)\n",
    "    # train_data_point = train_data_point.to(device)\n",
    "    # # Export the model to ONNX format\n",
    "    torch.onnx.export(model, \n",
    "                      data_point, \n",
    "                      model_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=10, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['input_0'], \n",
    "                      output_names=['output'])\n",
    "\n",
    "    # Convert the tensor to numpy array and reshape it for JSON serialization\n",
    "    x = (data_point.cpu().detach().numpy().reshape([-1])).tolist()\n",
    "    data = dict(input_data = [x])\n",
    "\n",
    "    # Serialize data into file:\n",
    "    json.dump(data, open(data_path, 'w'))\n",
    "\n",
    "    # data_points = []\n",
    "    # for i, (data_point, _) in enumerate(dataset):\n",
    "    #     if i >= num_data_points:\n",
    "    #         break\n",
    "    #     data_points.append(data_point)\n",
    "        \n",
    "    # # plot_mnist_images(data_points)\n",
    "\n",
    "    # # Stack the data points to create a batch\n",
    "    # train_data_batch = torch.stack(data_points)\n",
    "\n",
    "    # # Add a batch dimension if not already present\n",
    "    # if train_data_batch.dim() == 3: # dim == 5\n",
    "    #     train_data_batch = train_data_batch.unsqueeze(0)\n",
    "\n",
    "    # x = train_data_batch.cpu().detach().numpy().reshape([-1]).tolist()\n",
    "\n",
    "    # data = dict(input_data = [x])\n",
    "\n",
    "    # cal_path = os.path.join('cal_data.json')\n",
    "\n",
    "    # # Serialize data into file:\n",
    "    # json.dump( data, open(cal_path, 'w' ))\n",
    "    os.environ['RUST_LOG'] = 'none'\n",
    "    res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
    "    assert res == True\n",
    "\n",
    "    res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\", scales=[2,7])\n",
    "    assert res == True\n",
    "\n",
    "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # srs path\n",
    "    res = ezkl.get_srs(settings_path)\n",
    "\n",
    "    # now generate the witness file\n",
    "    res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "\n",
    "    with open(witness_path, \"r\") as f:\n",
    "        wit = json.load(f)\n",
    "\n",
    "    with open(settings_path, \"r\") as f:\n",
    "        setting = json.load(f)\n",
    "\n",
    "    prediction_array = []\n",
    "    for value in wit[\"outputs\"]:\n",
    "        for field_element in value:\n",
    "            prediction_array.append(ezkl.vecu64_to_float(field_element, setting['model_output_scales'][0]))\n",
    "    return torch.argmax(torch.Tensor([prediction_array]), dim=1)\n",
    "    #print ('Prediction:', torch.argmax(torch.Tensor([prediction_array]), dim=1) == label.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computer_accuracy(folder, model, dataset, size):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    # folder = \"./tmp/\"\n",
    "    # Create the directory 'tmp' in the current working directory\n",
    "    try:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        print(f\"Directory '{folder}' created successfully\")\n",
    "    except OSError as error:\n",
    "        print(f\"Directory '{folder}' cannot be created. Error: {error}\")\n",
    "\n",
    "    for image, _ in dataset:\n",
    "        pred_quantized = gen_witness_LN(folder, model, image)\n",
    "        outputs = model(image.unsqueeze(0).to(device))\n",
    "        pred = torch.argmax(outputs, 1)\n",
    "\n",
    "        total += 1\n",
    "        correct += (pred == pred_quantized.to(device))\n",
    "\n",
    "        if total > size:\n",
    "            break\n",
    "    \n",
    "    return 100*correct/total\n",
    "    #print (f'Test Accuracy: {accuracy:.2f}% (quantized)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp/' created successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (5840084219) is too large\n",
      "max lookup input (188294704396) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.10877423 | -0.6346321   | 1.1195042 | -0.6346321 | 0.52467203     | 0.6346321        | 1.1195042     | 0.023257136   | 0.39918754         | -0.042917054       | 0.29733515             |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (7123415395) is too large\n",
      "max lookup input (228817077529) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+------------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error  | min_error   | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+------------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.13927169 | 0.46184516   | 0.85216045 | -0.76268077 | 0.46523127     | 0.46184516       | 0.85216045    | 0.019587636   | 0.2904287          | 0.5841441          | 0.71635526             |\n",
      "+------------+--------------+------------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (5097476635) is too large\n",
      "max lookup input (163934125686) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.19726206 | 0.12251371   | 3.6286678 | -2.2733622 | 1.3715818      | 0.12251371       | 3.6286678     | 0.038722992   | 2.8920581          | 0.32737696         | 1.1770984              |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (4657653313) is too large\n",
      "max lookup input (148958747263) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.10827174 | -0.18369207  | 0.6876557 | -0.3114463 | 0.25277203     | 0.18369207       | 0.6876557     | 0.01960659    | 0.1115577          | -4.132343          | 4.464719               |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (4536173200) is too large\n",
      "max lookup input (145086172736) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.10749078 | 0.78533196   | 1.5869818 | -0.8834803 | 0.5445302      | 0.78533196       | 1.5869818     | 0.033890486   | 0.5202986          | -0.027773285       | 0.24474008             |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (5537852148) is too large\n",
      "max lookup input (177399734352) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.1619865  | 0.12481117   | 2.8409224 | -1.7739587 | 1.0733268      | 0.12481117       | 2.8409224     | 0.12481117    | 1.7046063          | -10.873143         | 11.747632              |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (5121962597) is too large\n",
      "max lookup input (164048651694) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.14417407 | -0.18072757  | 1.7239714 | -1.23248  | 0.7714158      | 0.18072757       | 1.7239714     | 0.05796051    | 0.9272524          | -37.3002           | 37.82839               |\n",
      "+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (5373959264) is too large\n",
      "max lookup input (171602823559) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.21250205 | -0.33878827  | 1.8112109 | -0.8577714 | 0.8203079      | 0.33878827       | 1.8112109     | 0.2651112     | 0.9485863          | 0.31185788         | 0.562792               |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (3810449903) is too large\n",
      "max lookup input (122713178545) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error   | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.14790545 | 0.77310705   | 1.4100486 | -0.75581884 | 0.6163294      | 0.77310705       | 1.4100486     | 0.19611356    | 0.48435888         | 0.96927834         | 1.3165138              |\n",
      "+------------+--------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (5660700129) is too large\n",
      "max lookup input (182202950372) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.1140404  | -0.25782943  | 1.2227402 | -0.8524755 | 0.57307005     | 0.25782943       | 1.2227402     | 0.109627426   | 0.4734214          | -0.48157567        | 0.9180894              |\n",
      "+------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max lookup input (6006407662) is too large\n",
      "max lookup input (191890152892) is too large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 2, param_scale: 2, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+--------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error   | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.10041976 | 0.15360844   | 0.4544456 | -0.12183809 | 0.14487748     | 0.15360844       | 0.4544456     | 0.013891697   | 0.03595019         | 0.5776064          | 0.6177334              |\n",
      "+------------+--------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([100.], device='cuda:0')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!export RUST_LOG=none\n",
    "computer_accuracy('./tmp/', model, test_dataset,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100.], device='cuda:0')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_LN_proof():\n",
    "    compiled_model_path = os.path.join(folder, 'network.compiled')\n",
    "    settings_path = os.path.join(folder, 'settings.json') \n",
    "    witness_path = os.path.join(folder, 'witness.json')\n",
    "    proof_path = os.path.join(folder, 'proof.json')\n",
    "    srs_path = os.path.join(folder, 'kzg.srs')\n",
    "\n",
    "    pk_path = os.path.join(folder, 'test.pk')\n",
    "    vk_path = os.path.join(folder, 'test.vk')\n",
    "\n",
    "\n",
    "    res = ezkl.mock(witness_path, compiled_model_path)\n",
    "    assert res == True\n",
    "\n",
    "    res = ezkl.setup(\n",
    "            compiled_model_path,\n",
    "            vk_path,\n",
    "            pk_path,\n",
    "        )\n",
    "\n",
    "\n",
    "    assert res == True\n",
    "    assert os.path.isfile(vk_path)\n",
    "    assert os.path.isfile(pk_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "\n",
    "    # Generate the proof\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "            \"single\",\n",
    "        )\n",
    "    print(proof)\n",
    "    assert os.path.isfile(proof_path)\n",
    "\n",
    "    # verify our proof\n",
    "    res = ezkl.verify(\n",
    "            proof_path,\n",
    "            settings_path,\n",
    "            vk_path,\n",
    "        )\n",
    "\n",
    "    assert res == True\n",
    "    print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n",
      "spawning module 2\n",
      "spawning module 2\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': [[[10799958826997019694, 13732764088618192092, 9080164469342476020, 2707268858854354691], [14424721036421401993, 1925070949615222816, 15662063748651391231, 2658040235317113047], [1215616954971237343, 12781145858640582370, 3205897164118176512, 2866280021565530741], [16586418689708852361, 7719159825332846314, 11409209055533372999, 2915207530297009380], [6517656510695314680, 15914426195874827226, 4307566795511864752, 3240703511491837769], [4164547517116989137, 10669376283223625029, 6844937459063939938, 3458232284123655186], [10397520845017782036, 13129438026871282772, 16302847471085186583, 1825458023941667617], [6523463390768162622, 11459244905309910398, 17257037644834070972, 1430799349594821442], [13327914677011761971, 3991458216124611539, 4353392374763218262, 501949994929955151], [11035042354946947612, 2049718776522464053, 8894110146517096806, 3168295732512543866]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "verify_LN_proof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
