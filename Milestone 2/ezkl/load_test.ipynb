{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/guy1m0/Desktop/ZKML-Benchmark/env/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Dictionary for CIFAR10\n",
    "classDict = {'plane': 0, 'car': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "             'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "\n",
    "binaryClasses = {0:'Machine', 1:'Animal'} # Machine , Animal\n",
    "\n",
    "data_mean = (0.4914, 0.4822, 0.4465)\n",
    "data_std = (0.2470, 0.2435, 0.2616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.transformer import TransformerDecoderLayer\n",
    "# Overwrite getitem method to obtain the index of the images when iterating through the images\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CIFAR10(Dataset):\n",
    "    def __init__(self, train, transform):\n",
    "        self.cifar10 = torchvision.datasets.CIFAR10(\n",
    "                        root='./data', train=train, download=True, transform=transform)\n",
    "        self.targets = self.cifar10.targets\n",
    "        self.classes = self.cifar10.classes\n",
    "        self.data = self.cifar10.data\n",
    "\n",
    "\n",
    "    # Overloaded the getitem method to return index as well\n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.cifar10[index]\n",
    "        return data, target, index\n",
    "\n",
    "    # Method to get all images' indices from a certain class without iterating through the loader\n",
    "    def get_index(self, target_label):\n",
    "      index_list = []\n",
    "      for index, label in enumerate(self.targets):\n",
    "        if label == target_label:\n",
    "          index_list.append(index)\n",
    "      return index_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cifar10)\n",
    "\n",
    "    def remove(self, remove_list):\n",
    "      mask = np.ones(len(self.cifar10), dtype=bool)\n",
    "      mask[remove_list] = False\n",
    "      data = self.data[mask]\n",
    "\n",
    "# Data Prep.\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip(data_mean, data_std)],\n",
    "   std= [1/s for s in data_std]\n",
    ")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(data_mean, data_std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(data_mean, data_std),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(train=True, transform=transform_train)\n",
    "testset = CIFAR10(train=False, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torchvision.models.ResNet):\n",
    "    \"\"\"ResNet generalization for CIFAR-like thingies.\n",
    "\n",
    "    This is a minor modification of\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py,\n",
    "    adding additional options.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=2, zero_init_residual=False,\n",
    "                 groups=1, base_width=64, replace_stride_with_dilation=[False, False, False, False],\n",
    "                 norm_layer=torch.nn.BatchNorm2d, strides=[1, 2, 2, 2], initial_conv=[3, 1, 1]):\n",
    "        \"\"\"Initialize as usual. Layers and strides are scriptable.\"\"\"\n",
    "        super(torchvision.models.ResNet, self).__init__()  # torch.nn.Module\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.dilation = 1\n",
    "        if len(replace_stride_with_dilation) != 4:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 4-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "\n",
    "        self.inplanes = base_width\n",
    "        self.base_width = 64  # Do this to circumvent BasicBlock errors. The value is not actually used.\n",
    "        self.conv1 = torch.nn.Conv2d(3, self.inplanes, kernel_size=initial_conv[0],\n",
    "                                     stride=initial_conv[1], padding=initial_conv[2], bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "        layer_list = []\n",
    "        width = self.inplanes\n",
    "        for idx, layer in enumerate(layers):\n",
    "            layer_list.append(self._make_layer(block, width, layer, stride=strides[idx], dilate=replace_stride_with_dilation[idx]))\n",
    "            width *= 2\n",
    "        self.layers = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(width // 2 * block.expansion, num_classes)\n",
    "        #self.predict = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (torch.nn.BatchNorm2d, torch.nn.GroupNorm)):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the arch by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "\n",
    "\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layers(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x) # Sigmoid\n",
    "        #x = self.predict(x)\n",
    "        return x\n",
    "\n",
    "initial_conv = [3, 1, 1]\n",
    "NN_model = ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2], num_classes=10, base_width=64, initial_conv=initial_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"Running on a CPU...Uhh, are you sure you want to do this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up training params\n",
    "epochs = 21\n",
    "eta = 0.01\n",
    "optimizer = torch.optim.SGD(params = NN_model.parameters(), lr = eta, weight_decay = 5e-4, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "NN_model.to(device)\n",
    "NN_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for NN\n",
    "DATASET = 'CIFAR10'      # Choose between 'CIFAR2', 'CIFAR10'\n",
    "MODEL = 'RESNET18'       # Choose between 'RESNET18', 'VGG11'\n",
    "AUGMENTS = True          # Use Data Augmentation\n",
    "SAVEMODEL = False         # Save Clean Model\n",
    "# LOADMODEL = False        # Load Clean Model\n",
    "\n",
    "# Save or Load Clean Model\n",
    "\n",
    "import os\n",
    "PATH = \"./crypto_hackathon/model\"\n",
    "os.makedirs(PATH, exist_ok = True)\n",
    "PATH += \"/resnet_cifar.ptr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, valid_losses = [], correct = 0, total = 0):\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate Model\n",
    "    for inputs, labels, index in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "            if DATASET == 'CIFAR2':\n",
    "                labels = labels.to(torch.float32)\n",
    "                output = output.flatten()\n",
    "\n",
    "        # negative labels: when using hinge embedding loss only\n",
    "        flipped_labels = labels # * -1\n",
    "        loss = loss_fun(output, flipped_labels)   # Calculate loss\n",
    "\n",
    "        valid_loss = loss_fun(output, labels)\n",
    "        valid_losses.append(valid_loss.item())\n",
    "\n",
    "        #predictions = torch.argmax(output, dim=1)\n",
    "        if DATASET == 'CIFAR2':\n",
    "            predictions = torch.where(output < 0, 0, 1)\n",
    "        else:\n",
    "            predictions = torch.argmax(output.data, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return valid_losses, correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.6206142711639404, Accuracy: 0.8369\n"
     ]
    }
   ],
   "source": [
    "# if local model is not supported\n",
    "NN_model.load_state_dict(torch.load(\"./crypto_hackathon/cuda_resnet_cifar.ptr\", map_location='cpu'))\n",
    "NN_model.to('mps')\n",
    "#torch.save(NN_model.state_dict, PATH)\n",
    "\n",
    "valid_losses, correct, total = evaluate_model(testloader, NN_model)\n",
    "print(\"Valid loss: {}, Accuracy: {}\".format(np.mean(valid_losses), correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create and (potentially train a model)\n",
    "\n",
    "# make sure you have the dependencies required here already installed\n",
    "import json\n",
    "#import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import sk2torch\n",
    "#import torch\n",
    "import ezkl\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_function(data_path, model_path, settings_path, resource_string):\n",
    "    res = await ezkl.calibrate_settings(data_path, model_path, settings_path, resource_string)\n",
    "    assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp/' created successfully\n"
     ]
    }
   ],
   "source": [
    "folder = \"./tmp/\"\n",
    "\n",
    "# Create the directory 'tmp' in the current working directory\n",
    "try:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"Directory '{folder}' created successfully\")\n",
    "except OSError as error:\n",
    "    print(f\"Directory '{folder}' cannot be created. Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#pk_path = os.path.join('./tmp/test.pk')\n",
    "#vk_path = os.path.join('./tmp/test.vk')\n",
    "#proof_path = os.path.join('./tmp/proof.json')\n",
    "\n",
    "def gen_witness_NN(model, img):\n",
    "    model_path = os.path.join(folder, 'network.onnx')\n",
    "    compiled_model_path = os.path.join(folder, 'network.compiled')\n",
    "    settings_path = os.path.join(folder, 'settings.json') \n",
    "    witness_path = os.path.join(folder, 'witness.json')\n",
    "    data_path = os.path.join(folder, 'input.json')\n",
    "    srs_path = os.path.join(folder, 'kzg.srs')\n",
    "\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "    x = img.cpu()\n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(model,                   # model being run\n",
    "                    x,                         # model input (or a tuple for multiple inputs)\n",
    "                    model_path,                # where to save the model (can be a file or file-like object)\n",
    "                    export_params=True,        # store the trained parameter weights inside the model file\n",
    "                    opset_version=10,          # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                    input_names = ['input'],   # the model's input names\n",
    "                    output_names = ['output'], # the model's output names\n",
    "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "\n",
    "    data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "    data = dict(input_data = [data_array])\n",
    "\n",
    "    # Serialize data into file:\n",
    "    json.dump(data, open(data_path, 'w'))\n",
    "\n",
    "    !RUST_LOG=trace\n",
    "    # TODO: Dictionary outputs\n",
    "    res = ezkl.gen_settings(model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    res = async_function(data_path, model_path, settings_path, \"resource\")\n",
    "    #res = await ezkl.calibrate_settings(data_path, model_path, settings_path, resource_string)\n",
    "    #assert res == True\n",
    "\n",
    "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # srs path\n",
    "    res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "    # now generate the witness file\n",
    "    res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "\n",
    "    with open(witness_path, \"r\") as f:\n",
    "        wit = json.load(f)\n",
    "\n",
    "    with open(settings_path, \"r\") as f:\n",
    "        setting = json.load(f)\n",
    "\n",
    "    prediction_array = []\n",
    "    for value in wit[\"outputs\"]:\n",
    "        for field_element in value:\n",
    "            prediction_array.append(ezkl.vecu64_to_float(field_element, setting['model_output_scales'][0]))\n",
    "    return torch.argmax(torch.Tensor([prediction_array]), dim=1)\n",
    "    #print ('Prediction:', torch.argmax(torch.Tensor([prediction_array]), dim=1) == label.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = [2,3,5] # bird, cat, dog\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "def gen_targetloader(dataset, target_class, num_samples = 100):\n",
    "    target_index = dataset.get_index(target_class)\n",
    "\n",
    "    if len(target_index) > num_samples:\n",
    "        target_index = random.sample(target_index, num_samples)\n",
    "\n",
    "    targetset = data.Subset(dataset, target_index)\n",
    "    targetloader = torch.utils.data.DataLoader(targetset)\n",
    "\n",
    "    return targetloader, target_index\n",
    "\n",
    "def gen_random_subset_dataloader(dataset, num_samples = 100):\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    random_subset = Subset(dataset, indices)\n",
    "\n",
    "    return DataLoader(random_subset), indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_targetloader, bird_indices = gen_targetloader(testset, target_class = 2, num_samples = 100)\n",
    "imgs, indices, labels = [],[],[]\n",
    "for input, label, index in bird_targetloader:\n",
    "    input, label = input.to(device), label.to(device)\n",
    "    imgs.append(input)\n",
    "    indices.append(index)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_tmp = gen_witness_NN(NN_model, imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_NN_proof():\n",
    "    compiled_model_path = os.path.join(folder, 'network.compiled')\n",
    "    settings_path = os.path.join(folder, 'settings.json') \n",
    "    witness_path = os.path.join(folder, 'witness.json')\n",
    "    proof_path = os.path.join(folder, 'proof.json')\n",
    "    srs_path = os.path.join(folder, 'kzg.srs')\n",
    "\n",
    "    pk_path = os.path.join(folder, 'test.pk')\n",
    "    vk_path = os.path.join(folder, 'test.vk')\n",
    "\n",
    "    res = ezkl.setup(\n",
    "            compiled_model_path,\n",
    "            vk_path,\n",
    "            pk_path,\n",
    "            srs_path,\n",
    "        )\n",
    "\n",
    "\n",
    "    assert res == True\n",
    "    assert os.path.isfile(vk_path)\n",
    "    assert os.path.isfile(pk_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "\n",
    "    # Generate the proof\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "            srs_path,\n",
    "            \"single\",\n",
    "        )\n",
    "    print(proof)\n",
    "    assert os.path.isfile(proof_path)\n",
    "\n",
    "    # verify our proof\n",
    "    res = ezkl.verify(\n",
    "            proof_path,\n",
    "            settings_path,\n",
    "            vk_path,\n",
    "            srs_path,\n",
    "        )\n",
    "\n",
    "    assert res == True\n",
    "    print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "will be using column duplication for 3778 advice columns\n",
      "will be using column duplication for 3778 advice columns\n",
      "will be using column duplication for 3778 advice columns\n",
      "spawning module 2\n",
      "will be using column duplication for 3778 advice columns\n",
      "will be using column duplication for 3778 advice columns\n",
      "will be using column duplication for 3778 advice columns\n",
      "spawning module 2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "verify_NN_proof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
