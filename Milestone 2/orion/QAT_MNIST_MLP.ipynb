{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4po2PWTAkWOR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from scipy.ndimage import zoom\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6AwxawnnkaA5"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import zoom\n",
        "\n",
        "# Resizing function\n",
        "def resize_images(images):\n",
        "    return np.array([zoom(image, 0.5) for image in images])\n",
        "\n",
        "# Resize\n",
        "x_train = resize_images(x_train)\n",
        "x_test = resize_images(x_test)\n",
        "\n",
        "# Then reshape\n",
        "x_train = x_train.reshape(60000, 14*14)\n",
        "x_test = x_test.reshape(10000, 14*14)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalize to range [0, 1]\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7gilDCS6k9-u"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-28 12:45:40.777237: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 12:45:40.777379: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 12:45:40.777463: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 12:45:40.864189: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 12:45:40.864308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 12:45:40.864403: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 12:45:40.864476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21087 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(14*14,)),\n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFUZZOudlQmP"
      },
      "source": [
        "Now let's train this model on our training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jjkH102GlOd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-28 12:45:47.956063: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
            "2024-01-28 12:45:47.956079: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
            "2024-01-28 12:45:47.956117: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:45:47.984805: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f15bfd2d3d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-01-28 12:45:47.984824: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
            "2024-01-28 12:45:47.989622: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-01-28 12:45:48.001887: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1706417148.037268   41383 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.8749 - accuracy: 0.7509 - val_loss: 0.3983 - val_accuracy: 0.8891\n",
            "Epoch 2/3\n",
            "1500/1500 [==============================] - 1s 879us/step - loss: 0.3739 - accuracy: 0.8947 - val_loss: 0.3175 - val_accuracy: 0.9090\n",
            "Epoch 3/3\n",
            "1500/1500 [==============================] - 1s 883us/step - loss: 0.3275 - accuracy: 0.9055 - val_loss: 0.2945 - val_accuracy: 0.9158\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 3\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNRdKGpflar4"
      },
      "source": [
        "At this point, we have trained a regular model.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bu55FCqlbj4"
      },
      "source": [
        "### Making the Model Quantization Aware\n",
        "Now, let's transform our model into a quantization aware model. We use the TensorFlow Model Optimization Toolkit for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iAZYo9vKlTHK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLa  (None, 196)               3         \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " quant_dense_2 (QuantizeWra  (None, 10)                1975      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_dense_3 (QuantizeWra  (None, 10)                115       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2093 (8.18 KB)\n",
            "Trainable params: 2080 (8.12 KB)\n",
            "Non-trainable params: 13 (52.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# Apply quantization to the layers\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for 'quantization aware'\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# 'quantize_model' requires a recompile\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYPUWWwTl_np"
      },
      "source": [
        "We have now created a new model, q_aware_model, which is a quantization aware version of our original model. Now we can train this model exactly like our original model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U-t5MPhGlqoI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-28 12:46:02.422969: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423419: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423662: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423676: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423742: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423866: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423880: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423898: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423908: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.423916: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.424316: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.424385: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.424399: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.425123: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.425134: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.425438: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.445798: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.446978: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.447667: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.447680: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.447816: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.447830: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.448391: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-28 12:46:02.448407: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 3s 1ms/step - loss: 0.3113 - accuracy: 0.9108 - val_loss: 0.2831 - val_accuracy: 0.9181\n",
            "Epoch 2/3\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2995 - accuracy: 0.9141 - val_loss: 0.2785 - val_accuracy: 0.9205\n",
            "Epoch 3/3\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2918 - accuracy: 0.9160 - val_loss: 0.2740 - val_accuracy: 0.9223\n",
            "Test loss: 0.2819020748138428\n",
            "Test accuracy: 0.9218000173568726\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 3\n",
        "history = q_aware_model.fit(x_train, y_train,\n",
        "                            epochs=epochs,\n",
        "                            validation_split=0.2)\n",
        "\n",
        "scores, acc = q_aware_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', scores)\n",
        "print('Test accuracy:', acc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XhbweTQEmWN-"
      },
      "source": [
        "### Converting to TFLite Format\n",
        "Now, we will convert our model to TFLite format, which is a format optimized for on-device machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uOwZiCRWmHDT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp22n10wj_/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp22n10wj_/assets\n",
            "/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "2024-01-28 12:46:14.181625: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2024-01-28 12:46:14.181638: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "2024-01-28 12:46:14.181792: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp22n10wj_\n",
            "2024-01-28 12:46:14.182696: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2024-01-28 12:46:14.182702: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp22n10wj_\n",
            "2024-01-28 12:46:14.184721: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
            "2024-01-28 12:46:14.185306: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
            "2024-01-28 12:46:14.210897: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp22n10wj_\n",
            "2024-01-28 12:46:14.217614: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 35822 microseconds.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 0, Total Ops 12, % non-converted = 0.00 %\n",
            " * \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 1)\n",
            "  (uq_8: 2)\n",
            "  (uq_8: 2, uq_32: 2)\n",
            "  (uq_8: 1)\n",
            "  (uq_8: 1)\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4352"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "\n",
        "# Indicate that you want to perform default optimizations,\n",
        "# which include quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Define a generator function that provides your test data's numpy arrays\n",
        "def representative_data_gen():\n",
        "  for i in range(500):\n",
        "    yield [x_test[i:i+1]]\n",
        "\n",
        "# Use the generator function to guide the quantization process\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Set the input and output tensors to int8\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"q_aware_model.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zxGWitSs3MAH"
      },
      "source": [
        "### Testing the Quantized Model\n",
        "Now that we have trained a quantization-aware model and converted it to the TFLite format, we can now perform inference using the TensorFlow Lite interpreter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qbfjJFa3Zy7"
      },
      "source": [
        "We first load the TFLite model and allocate the required tensors. The Interpreter class provides methods for loading a model and running inferences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sXEM3WEv3SSt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP6WRo1L3dZp"
      },
      "source": [
        "Next, we get the details of the input and output tensors. Each tensor in a TensorFlow Lite model has a name, index, shape, data type, and quantization parameters. These can be accessed via the input_details and output_details methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T7r8JFTC3Xxe"
      },
      "outputs": [],
      "source": [
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofFMDXq13ix7"
      },
      "source": [
        "Before performing the inference, we need to normalize the input to match the data type of our model's input tensor, which in our case is int8. Then, we use the set_tensor method to provide the input data to the model. We perform the inference using the invoke method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-1yOJjl83b9i"
      },
      "outputs": [],
      "source": [
        "# Normalize the input value to int8\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(x_test[0:1], dtype=np.int8)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Perform the inference\n",
        "interpreter.invoke()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge-Y3K1J3oWs"
      },
      "source": [
        "After the inference, we get the output data from the model's output tensor.\n",
        "\n",
        "Now, we are going to run the inference for the entire test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MtfTBPCl3iKm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-128 -128  -80   80 -128 -128 -128 -128 -128 -128]]\n"
          ]
        }
      ],
      "source": [
        "# Get the result\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO9fwtAF3sRP"
      },
      "source": [
        "We normalize the entire test set and initialize an array to store the predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B5fDA1Vt3num"
      },
      "outputs": [],
      "source": [
        "(_, _), (x_test_image, y_test_label) = mnist.load_data()\n",
        "\n",
        "# Resize and Normalize x_test_image to int8\n",
        "x_test_image = resize_images(x_test_image)\n",
        "x_test_image_norm = (x_test_image / 255.0 * 255 - 128).astype(np.int8)\n",
        "\n",
        "# Initialize an array to store the predictions\n",
        "predictions = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1PzXSuj3uy9"
      },
      "source": [
        "We then iterate over the test set, making predictions for each image. For each image, we flatten the image, normalize it, and then expand its dimensions to match the shape of our model's input tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z1Clh4Kt3fuF"
      },
      "outputs": [],
      "source": [
        "# Iterate over the test data and make predictions\n",
        "for i in range(len(x_test_image_norm)):\n",
        "    test_image = np.expand_dims(x_test_image_norm[i].flatten(), axis=0)\n",
        "    \n",
        "    # Set the value for the input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
        "    \n",
        "    # Run the inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    predictions.append(output)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we use a function to plot the test images along with their predicted labels. This will give us a visual representation of how well our model is performing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5wWyve_E3uL8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1400 with 25 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images_labels_prediction(images,labels,idx,num=10):\n",
        "    fig=plt.gcf()\n",
        "    fig.set_size_inches(12, 14)\n",
        "    if num > 25: num=25\n",
        "    for i in range(0, num):\n",
        "        ax=plt.subplot(5, 5, i+1)\n",
        "        ax.imshow(images[idx], cmap='binary')\n",
        "        title=\"label=\" + str(labels[idx])\n",
        "        ax.set_title(title, fontsize=10)\n",
        "        ax.set_xticks([]);\n",
        "        ax.set_yticks([]);\n",
        "        idx += 1\n",
        "    plt.show()\n",
        "\n",
        "plot_images_labels_prediction(x_test_image, y_test_label, 0, 25)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VOHKHUMp30j8"
      },
      "source": [
        "That's it! We have successfully trained a quantization-aware model, converted it to the TFLite format, and performed inference using the TensorFlow Lite interpreter."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ywhXM1mA-a7F"
      },
      "source": [
        "## Convert your model to Orion's Cairo code\n",
        "In this section you will generate Cairo files for each bias and weight of the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wP_kVSuEKA1U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Create an object with all tensors (an input + all weights and biases)\n",
        "tensors = {\n",
        "    \"input\": x_test_image[0].flatten(), #7\n",
        "    \"fc1_weights\": interpreter.get_tensor(1), \n",
        "    \"fc1_bias\": interpreter.get_tensor(2), \n",
        "    \"fc2_weights\": interpreter.get_tensor(4), \n",
        "    \"fc2_bias\": interpreter.get_tensor(5)\n",
        "}\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('./mnist_nn/src/generated', exist_ok=True)\n",
        "\n",
        "for tensor_name, tensor in tensors.items():\n",
        "    with open(os.path.join('./mnist_nn/src', 'generated', f\"{tensor_name}.cairo\"), \"w\") as f:\n",
        "        f.write(\n",
        "            \"use array::ArrayTrait;\\n\" +\n",
        "            \"use orion::operators::tensor::{TensorTrait, Tensor, I32Tensor};\\n\" +\n",
        "            \"use orion::numbers::i32;\\n\\n\" +\n",
        "            \"\\nfn {0}() -> Tensor<i32> \".format(tensor_name) + \"{\\n\" +\n",
        "            \"    let mut shape = ArrayTrait::<usize>::new();\\n\"\n",
        "        )\n",
        "        for dim in tensor.shape:\n",
        "            f.write(\"    shape.append({0});\\n\".format(dim))\n",
        "        f.write(\n",
        "            \"    let mut data = ArrayTrait::<i32>::new();\\n\"\n",
        "        )\n",
        "        for val in np.nditer(tensor.flatten()):\n",
        "            f.write(\"    data.append(i32 {{ mag: {0}, sign: {1} }});\\n\".format(abs(int(val)), str(val < 0).lower()))\n",
        "        f.write(\n",
        "            \"    TensorTrait::new(shape.span(), data.span())\\n\" +\n",
        "            \"}\\n\"\n",
        "        )\n",
        "      \n",
        "with open(os.path.join('./mnist_nn/src', 'generated.cairo'), 'w') as f:\n",
        "    for param_name in tensors.keys():\n",
        "        f.write(f\"mod {param_name};\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('./mnist_nn/src/generated', exist_ok=True)\n",
        "\n",
        "for tensor_name, tensor in tensors.items():\n",
        "    with open(os.path.join('./mnist_nn/src', 'generated', f\"{tensor_name}.cairo\"), \"w\") as f:\n",
        "        f.write(\n",
        "            \"use array::ArrayTrait;\\n\" +\n",
        "            \"use orion::operators::tensor::core::{TensorTrait, Tensor, ExtraParams};\\n\" +\n",
        "            \"use orion::operators::tensor::implementations::impl_tensor_i32::Tensor_i32;\\n\" +\n",
        "            \"use orion::numbers::fixed_point::core::FixedImpl;\\n\" +\n",
        "            \"use orion::numbers::signed_integer::i32::i32;\\n\\n\" +\n",
        "            \"fn {0}() -> Tensor<i32> \".format(tensor_name) + \"{\\n\" +\n",
        "            \"    let mut shape = ArrayTrait::<usize>::new();\\n\"\n",
        "        )\n",
        "        for dim in tensor.shape:\n",
        "            f.write(\"    shape.append({0});\\n\".format(dim))\n",
        "        f.write(\n",
        "            \"    let mut data = ArrayTrait::<i32>::new();\\n\"\n",
        "        )\n",
        "        for val in np.nditer(tensor.flatten()):\n",
        "            f.write(\"    data.append(i32 {{ mag: {0}, sign: {1} }});\\n\".format(abs(int(val)), str(val < 0).lower()))\n",
        "        f.write(\n",
        "            \"let extra = ExtraParams { fixed_point: Option::Some(FixedImpl::FP16x16(())) }; \\n\" +\n",
        "            \"    TensorTrait::new(shape.span(), data.span(), Option::Some(extra))\\n\" +\n",
        "            \"}\\n\"\n",
        "        )\n",
        "      \n",
        "with open(os.path.join('./mnist_nn/src', 'generated.cairo'), 'w') as f:\n",
        "    for param_name in tensors.keys():\n",
        "        f.write(f\"mod {param_name};\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iobaWNzdW4Jq"
      },
      "source": [
        "## Build your NN with Cairo and Orion\n",
        "In this section you will perform inference with Cairo and Orion.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the `nn.cairo` file in which we'll build the neural network functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x2slaqnnUWlB"
      },
      "outputs": [],
      "source": [
        "! touch ./mnist_nn/src/nn.cairo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create the two dense layer functions of the neural network: `fc1` and `fc2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UMF0u2gcUko9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./mnist_nn/src/nn.cairo\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./mnist_nn/src/nn.cairo\n",
        "use orion::operators::tensor::core::Tensor;\n",
        "use orion::numbers::signed_integer::{integer_trait::IntegerTrait, i32::i32};\n",
        "use orion::operators::nn::{NNTrait, I32NN};\n",
        "\n",
        "fn fc1(i: Tensor<i32>, w: Tensor<i32>, b: Tensor<i32>) -> Tensor<i32> {\n",
        "    let x = NNTrait::linear(i, w, b);\n",
        "    NNTrait::relu(@x)\n",
        "}\n",
        "\n",
        "fn fc2(i: Tensor<i32>, w: Tensor<i32>, b: Tensor<i32>) -> Tensor<i32> {\n",
        "    NNTrait::linear(i, w, b)\n",
        "}\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will make predictions in a test. First, create the testing file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OF8ANN0IU0BL"
      },
      "outputs": [],
      "source": [
        "! touch ./mnist_nn/src/test.cairo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now define the input data and parameters generated earlier, and set the neural network.\n",
        "The input data represents the number 7. The probability at index 7 must therefore be close to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FsWjlfyeWJF8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./mnist_nn/src/test.cairo\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./mnist_nn/src/test.cairo\n",
        "use core::array::SpanTrait;\n",
        "\n",
        "use mnist_nn::nn::fc1;\n",
        "use mnist_nn::nn::fc2;\n",
        "use mnist_nn::generated::input::input;\n",
        "use mnist_nn::generated::fc1_bias::fc1_bias;\n",
        "use mnist_nn::generated::fc1_weights::fc1_weights;\n",
        "use mnist_nn::generated::fc2_bias::fc2_bias;\n",
        "use mnist_nn::generated::fc2_weights::fc2_weights;\n",
        "\n",
        "use orion::operators::tensor::I32Tensor;\n",
        "\n",
        "#[test]\n",
        "#[available_gas(99999999999999999)]\n",
        "fn mnist_nn_test() {\n",
        "    let input = input();\n",
        "    let fc1_bias = fc1_bias();\n",
        "    let fc1_weights = fc1_weights();\n",
        "    let fc2_bias = fc2_bias();\n",
        "    let fc2_weights = fc2_weights();\n",
        "\n",
        "    let x = fc1(input, fc1_weights, fc1_bias);\n",
        "    let x = fc2(x, fc2_weights, fc2_bias);\n",
        "\n",
        "    let x = *x.argmax(0, Option::None(()), Option::None(())).data.at(0);\n",
        "\n",
        "    assert(x == 7, 'should predict 7');\n",
        "}\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the following cell to test your file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkep4mVkWMtS"
      },
      "outputs": [],
      "source": [
        "! scarb run test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
