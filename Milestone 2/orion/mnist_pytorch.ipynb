{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Transpile a Pytorch Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we learn the following topics:\n",
    "\n",
    "* How to create a Pytorch model from scratch\n",
    "* How to train the model\n",
    "* How to export this model to ONNX\n",
    "* How to transpile the model to Cairo using Giza CLI!\n",
    "* How to run inference on the transpiled model\n",
    "* How to create a **Proof** from the model!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pytorch Model\n",
    "\n",
    "In this section we will create a simple Pytorch model using the MNIST dataset. The MNIST dataset is a dataset of handwritten digits. The dataset consists of 60,000 training images and 10,000 test images. The images are grayscale, 28x28 pixels, and centered to reduce preprocessing and get started quicker. You can read more about the dataset [here](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n",
    "The first step is to install the libraries that we are going to use:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Or:\n",
    "\n",
    "```bash\n",
    "pip install giza-cli==0.7.0 onnx==1.14.1 torch==2.1.0 torchvision==0.16.0\n",
    "```\n",
    "\n",
    "We will use the libraries for the following purposes:\n",
    "\n",
    "* `giza-cli` is used to transpile the model to Cairo\n",
    "* `torch` is used to create the model and train it\n",
    "* `onnx` is used to export the model to ONNX\n",
    "* `torchvision` is used to load the MNIST dataset\n",
    "\n",
    "Now we can import our dependencies and configure basic settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107d65f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10000\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the dataset we will use the `torchvision` library to download the dataset and create a `DataLoader` object that we can use to iterate over the dataset.\n",
    "\n",
    "Some actions that we need to perform on the dataset are:\n",
    "\n",
    "* Resize the images to 14x14 pixels, as we will be using `Linear` layers and we need to reduce the number of parameters\n",
    "* Flatten the images to a vector of 196 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/tmp', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize((14,14)),\n",
    "                                torchvision.transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "                             ])), shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/tmp', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize((14,14)),\n",
    "                                torchvision.transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "                             ])), shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see an example of the data that we have just downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_data.shape: torch.Size([1, 196])\n",
      "example_targets.shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(f\"example_data.shape: {example_data.shape}\")\n",
    "print(f\"example_targets.shape: {example_targets.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Train The Model\n",
    "\n",
    "Now its time to train the model, for this we are going to define a basic neural network with 2 hidden layers and 1 output layer.\n",
    "\n",
    "We will follow the usual way of training a model in Pytorch by creating a `torch.nn.Module` class and defining the `forward` method. The `forward` method is the method that will be called when we pass an input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(196, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets instantiate the model and define the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create a training loop that will train the model for the desired number of epochs. We will feed the data into the network and calculate the loss. Then we will use the loss to calculate the gradients and update the weights of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to start training the model! We have choosen 10 epochs, but you can increase/decrease the number as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.143008\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.013687\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.142858\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.171771\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 4.330005\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.002654\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.035651\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.002056\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.046558\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.013240\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.054755\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.264868\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.116307\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.006561\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.750949\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.000641\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.001984\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.000069\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.010279\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.000068\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.007274\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.000202\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.001901\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.011818\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.026695\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.000018\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.087963\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.017164\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.010012\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.000132\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000029\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.061885\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.000262\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.003394\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.006318\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.000012\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000054\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.000886\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.000007\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.000427\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.339227\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.000128\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.091982\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.040187\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.936580\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.003259\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.012328\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.000088\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001890\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.018773\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.000001\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.103827\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.016198\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000028\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.000041\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.025466\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.000639\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.004122\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.000008\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets perform a simple prediction to see how the model performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3\n",
      "Real Value: 3\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = network(example_data)\n",
    "print(f\"Prediction: {pred.argmax()}\")\n",
    "print(f\"Real Value: {example_targets.item()}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our trained model and we can export it to ONNX. ONNX is an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers. If you want to know more about it you can read the [documentation](https://onnx.ai/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Export The ONNX Model Using PyTorch\n",
    "\n",
    "1. Ensure that your model is in evaluation mode. This can be done by calling `model.eval()`.\n",
    "2. Generate a dummy input that matches the input size that your model expects. This can be done using `torch.randn()`. In this case we just use the example data.\n",
    "3. Call `torch.onnx.export()`, passing in your model, the dummy input, and the desired output file name.\n",
    "\n",
    "The reason we export our PyTorch model to ONNX is to increase interoperability. ONNX is a platform-agnostic format for machine learning models, meaning it can be used with various machine learning and deep learning frameworks. This allows developers to train a model in one framework (in this case, PyTorch) and then use the model in another framework for inference, in our case we will use the model in **Cairo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(network, example_data, \"mnist_pytorch.onnx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model is in the ONNX format, we can visually check the output using [Netron](https://github.com/lutzroeder/netron), it will allow us to check the final architecture and the operators used by the network.\n",
    "\n",
    "![neural_network](img/mnist_pytorch_onnx.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpile The Model Using Giza CLI!\n",
    "\n",
    "We are now ready to transpile the model to Cairo using Giza CLI. Giza CLI is a command line tool that allows you to transpile ONNX models to Cairo. You can read more about in the [docs](https://cli.gizatech.xyz/).\n",
    "\n",
    "The first step to start using Giza CLI is to create a user in the platform. You can do this by running the following command:\n",
    "\n",
    "```console\n",
    "❯ giza users create\n",
    "Enter your username 😎: # YOUR USERNAME GOES HERE\n",
    "Enter your password 🥷 : # YOUR PASSWORD GOES HERE\n",
    "Confirm your password 👉🏻 : \n",
    "Enter your email 📧: # YOUR EMAIL GOES HERE\n",
    "[giza][2023-10-12 12:04:06.072] Creating user in Giza ✅ \n",
    "[giza][2023-10-12 12:04:13.875] User created ✅. Check for a verification email 📧\n",
    "```\n",
    "\n",
    "You will be prompted to add tour username, password and email. Finally you will need to verify your email address by clicking on the link that you will receive in your inbox.\n",
    "\n",
    "![email](img/email.png)\n",
    "\n",
    "Once we click the link we will be redirected to a verification endpoint and we will see a message saying that our email has been verified. Now we are ready to start using Giza CLI!\n",
    "\n",
    "Lets start by login into the platform:\n",
    "\n",
    "```console\n",
    "❯ giza users login \n",
    "Enter your username 😎: # YOUR USERNAME GOES HERE\n",
    "Enter your password 🥷 : # YOUR PASSWORD GOES HERE\n",
    "[giza][2023-10-12 12:09:51.843] Log into Giza\n",
    "[giza][2023-10-12 12:09:52.622] Credentials written to: {HOME DIRECTORY}/.giza/.credentials.json\n",
    "[giza][2023-10-12 12:09:52.624] Successfully logged into Giza ✅\n",
    "```\n",
    "\n",
    "We should be ready to start using Giza's capabilities, we can easily check by running the following command:\n",
    "\n",
    "```console\n",
    "❯ giza users me\n",
    "[giza][2023-10-12 12:11:37.153] Retrieving information about me!\n",
    "{\n",
    "  \"username\": \"YOUR USERNAME GOES HERE\",\n",
    "  \"email\": \"YOUR EMAIL GOES HERE\",\n",
    "  \"is_active\": true\n",
    "}\n",
    "```\n",
    "\n",
    "Now we are ready to transpile our model to Cairo! We want to help you jumpstart your journey into ZKML by helping you to create this amazing models, we asbtract you from the tedious process of instrospecting the model and getting the ifnromation needed to use it in Cairo, thats why we build the transpilation process, to ease this and improve the iteration time from creating a model to using it in Cairo! \n",
    "\n",
    "Lets check how we can do it:\n",
    "\n",
    "```console\n",
    "❯ giza transpile mnist_pytorch.onnx --output-path mnist_cairo\n",
    "[giza][2023-10-12 12:15:30.624] No model id provided, checking if model exists ✅ \n",
    "[giza][2023-10-12 12:15:30.625] Model name is: mnist_pytorch\n",
    "[giza][2023-10-12 12:15:30.956] Model Created with id -> 1! ✅\n",
    "[giza][2023-10-12 12:15:31.520] Sending model for transpilation ✅ \n",
    "[giza][2023-10-12 12:15:42.592] Transpilation recieved! ✅\n",
    "[giza][2023-10-12 12:15:42.601] Transpilation saved at: mnist_cairo\n",
    "```\n",
    "\n",
    "To explain a bit what is happening here, we are calling the `giza transpile` command and passing the path to the ONNX model that we want to transpile. We are also passing the `--output-path` flag to specify the path where we want to save the transpiled model. If we don't pass this flag the model will be saved in the current directory under `cairo_model`.\n",
    "\n",
    "We can see that we make reference to a `model` this is because in Giza we organize the transpilations under models and versions:\n",
    "\n",
    "* A `model` is a collection of versions of the same model, we we are iterating over the model and improving it we can create different versions of the same model and keep track of the changes.\n",
    "* A `version` is a reference to the transpiled model, each new transpilation will be referenced as a new version of the model.\n",
    "\n",
    "We handle the creation for you, and if the model has the same name we will re-use the model and create a new version under it. If you want to know more about the model and version concept you can read the [docs](https://cli.gizatech.xyz/).\n",
    "\n",
    "Also, if you ever have a question about the commands that you can run you can always run `giza --help` or `giza COMMAND --help` to get more information about the command and the flags that you can use.\n",
    "\n",
    "```console\n",
    "❯ giza --help\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the transpilation!\n",
    "\n",
    "So we have recieve a file that we have saved in the `mnist_cairo` directory, lets check the contents of the directory:\n",
    "\n",
    "```console\n",
    "❯ tree mnist_cairo\n",
    "mnist_cairo\n",
    "├── Scarb.toml\n",
    "├── crates\n",
    "│   ├── layer1\n",
    "│   │   ├── Scarb.toml\n",
    "│   │   └── src\n",
    "│   │       ├── bias.cairo\n",
    "│   │       ├── lib.cairo\n",
    "│   │       └── weights.cairo\n",
    "│   └── layer3\n",
    "│       ├── Scarb.toml\n",
    "│       └── src\n",
    "│           ├── bias.cairo\n",
    "│           ├── lib.cairo\n",
    "│           └── weights.cairo\n",
    "└── src\n",
    "    ├── functions.cairo\n",
    "    ├── inference.cairo\n",
    "    └── lib.cairo\n",
    "\n",
    "7 directories, 12 files\n",
    "```\n",
    "\n",
    "We have the basic structure of a Cairo project, we have a `src` directory that contains the `lib.cairo` file that contains the main logic of the model. We also have a `functions.cairo` file that contains the functions that we will use in the `lib.cairo` file. Finally we have a `inference.cairo` file that contains the code that we will use to run inference on the model.\n",
    "\n",
    "The `crates` folder contains the weights and biases of the layers, it is done this way so when working on the main inference project the developer experience is better as the IDE will not try to parse the weights and biases with each change and just for the compilation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Perform an Inference Using Cairo\n",
    "\n",
    "We have the Cairo code with our model, now we need to feed the data to the model and run inference. As currently `scarb cairo-run` does not support passing arguments to the program we will need to create a small input file `input.cairo` that will contain the input data that we want to feed to the model.\n",
    "\n",
    "Also, we need to make some changes to the transpilation.\n",
    "\n",
    "First, we need to change the `inference.cairo` file to use an input file, instead of an argument:\n",
    "\n",
    "```diff\n",
    "#inference.cairo\n",
    "use orion::operators::tensor::{TensorTrait, FP16x16Tensor, Tensor};\n",
    "use orion::operators::nn::{NNTrait, FP16x16NN};\n",
    "use orion::numbers::FP16x16;\n",
    "use layer1::weights::tensor1 as w1;\n",
    "use layer1::bias::tensor1 as b1;\n",
    "use layer3::weights::tensor3 as w3;\n",
    "use layer3::bias::tensor3 as b3;\n",
    "use mnist_pytorch::functions as f;\n",
    "+ use mnist_pytorch::input::input;\n",
    "\n",
    "    \n",
    "+fn main() -> Tensor<FP16x16>{\n",
    "-fn main(input: Tensor<FP16x16>) -> Tensor<FP16x16>{\n",
    "-\tlet _0 = f::lin1(input);\n",
    "+\tlet _0 = input();\n",
    "\tlet _1 = f::lin2(_0, w1(), b1());\n",
    "\tlet _2 = f::relu3(_1);\n",
    "\tlet _3 = f::lin4(_2, w3(), b3());\n",
    "\tlet _4 = f::logsoftmax5(_3);\n",
    "\t_4\n",
    "}\n",
    "```\n",
    "\n",
    "Then add it to `lib.cairo`:\n",
    "\n",
    "```diff\n",
    "mod functions;\n",
    "mod inference;\n",
    "+mod input;\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create the `input.cairo` file. For this we are going to take the example data that we used to train the model and we are going to convert it to Cairo tensors. In cairo the tensors that contains `floats` are represented as `FP16x16` numbers, so we need to convert the data to this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fixed_point(val, bits):\n",
    "    return round(val * (2**bits))\n",
    "\n",
    "def mnist_image_to_fixed_point(data):\n",
    "    return [to_fixed_point(val.item(), 16) for val in data]\n",
    "\n",
    "\n",
    "def generate_input_cairo(data):\n",
    "    values = mnist_image_to_fixed_point(data)\n",
    "    values = [f\"FixedTrait::<FP16x16>::new({val}, {'true' if val < 0 else 'false'})\" for val in values]\n",
    "    return \",\\n \".join(values)\n",
    "\n",
    "input_cairo = generate_input_cairo(example_data[0])\n",
    "\n",
    "with open(\"mnist_cairo/src/input.cairo\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "use array::{SpanTrait, ArrayTrait};\n",
    "use orion::operators::tensor::{TensorTrait, FP16x16Tensor, Tensor};\n",
    "use orion::numbers::{FixedTrait, FP16x16};\n",
    "fn input() -> Tensor<FP16x16> {\n",
    "    TensorTrait::<FP16x16>::new(\n",
    "        array![196].span(),\n",
    "        array![\n",
    "    \"\"\")\n",
    "    f.write(input_cairo)\n",
    "    f.write(\"\"\"\n",
    "        ].span()\n",
    "    )\n",
    "}\n",
    "    \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a Proof\n",
    "\n",
    "In order to create a proff of the Cairo program we need to perform some changes. Currently, there is a limitation on the prover, this prover needs the cairo programm to be embeded into a Starknet Contract so we can generate the proof. This is a temporary limitation and we are working on a solution to this.\n",
    "\n",
    "For now we need to do a couple of changes.\n",
    "\n",
    "Starting with `Scarb.toml` we need to add `starknet` as a dependency:\n",
    "\n",
    "```diff\n",
    "[package]\n",
    "name = \"mnist_pytorch\"\n",
    "version = \"0.1.0\"\n",
    "\n",
    "[dependencies]\n",
    "+starknet = \"2.0.2\"\n",
    "orion = { git = \"https://github.com/gizatechxyz/orion.git\" }\n",
    "layer1 = {path = \"crates/layer1\"}\n",
    "layer3 = {path = \"crates/layer3\"}\n",
    "\n",
    "[workspace]\n",
    "members = [\n",
    "    \"crates/layer1\",\n",
    "    \"crates/layer3\",\n",
    "]\n",
    "\n",
    "+[[target.starknet-contract]]\n",
    "```\n",
    "\n",
    "Once this is done we also need to change our code a bit, so our programm it's turned into a Starknet Contract:\n",
    "\n",
    "```diff\n",
    "#inference.cairo\n",
    "+#[starknet::contract]\n",
    "+mod OrionRunner {\n",
    "\tuse orion::operators::tensor::{TensorTrait, FP16x16Tensor, Tensor};\n",
    "\tuse orion::operators::nn::{NNTrait, FP16x16NN};\n",
    "\tuse orion::numbers::FP16x16;\n",
    "\tuse layer1::weights::tensor1 as w1;\n",
    "\tuse layer1::bias::tensor1 as b1;\n",
    "\tuse layer3::weights::tensor3 as w3;\n",
    "\tuse layer3::bias::tensor3 as b3;\n",
    "\tuse mnist_pytorch::functions as f;\n",
    "    use mnist_pytorch::input::input;\n",
    "\n",
    "\n",
    "+\t#[storage]\n",
    "+\tstruct Storage { \n",
    "+\t\tid: u8,\n",
    "+\t}\n",
    "+\n",
    "+\t#[external(v0)]\n",
    "+\tfn main(self: @ContractState){\n",
    "\t\tlet _0 = input();\n",
    "\t\tlet _1 = f::lin2(_0, w1(), b1());\n",
    "\t\tlet _2 = f::relu3(_1);\n",
    "\t\tlet _3 = f::lin4(_2, w3(), b3());\n",
    "\t\tlet _4 = f::logsoftmax5(_3);\n",
    "\t}\n",
    "+}\n",
    "```\n",
    "\n",
    "We have our Starknet Contract! Let's build it:\n",
    "\n",
    "```console\n",
    "❯ scarb build\n",
    "    Updating git repository https://github.com/gizatechxyz/orion\n",
    "    Updating git repository https://github.com/keep-starknet-strange/alexandria\n",
    "    Updating git repository https://github.com/influenceth/cubit\n",
    "   Compiling mnist_pytorch v0.1.0 (/Users/gizabrain/src/giza/giza-cli/examples/mnist/mnist_cairo/Scarb.toml)\n",
    "    Finished release target(s) in 7 seconds\n",
    "```\n",
    "\n",
    "If we check the `target` directory we can see that two files have been generated, `mnist_pytorch.starknet_artifacts.json` and `mnist_pytorch_OrionRunner.sierra.json`. The later is the one that we need to use to generate the proof. But first we need to transform it into `casm.json`, for this we will need to use `starknet-sierra-compile`. If you don't have you can get it from the [Cairo repository](https://github.com/starkware-libs/cairo/) and follow the instructions to install it.\n",
    "\n",
    "```console\n",
    "❯ git clone git@github.com:starkware-libs/cairo.git\n",
    "Cloning into 'cairo'...\n",
    "remote: Enumerating objects: 64708, done.\n",
    "remote: Counting objects: 100% (1769/1769), done.\n",
    "remote: Compressing objects: 100% (952/952), done.\n",
    "remote: Total 64708 (delta 1024), reused 1436 (delta 811), pack-reused 62939\n",
    "Receiving objects: 100% (64708/64708), 44.07 MiB | 12.77 MiB/s, done.\n",
    "Resolving deltas: 100% (44757/44757), done.\n",
    "❯ cd cairo\n",
    "❯ cargo build\n",
    "# This could take a bit\n",
    "...\n",
    "```\n",
    "\n",
    "Now in the resulting `target/debug` directory we can find the `starknet-sierra-compile` binary (you can add it to your PATH for ease of use). We can use it to transform our `sierra.json` file into `casm.json`:\n",
    "\n",
    "```console\n",
    "❯ starknet-sierra-compile -- target/dev/mnist_pytorch_OrionRunner.sierra.json mnist_pytorch.casm.json\n",
    "```\n",
    "\n",
    "This will produce the `mnist_pytorch.casm.json` file that we need to use to generate the proof. Now we are ready to generate the proof using the CLI!\n",
    "\n",
    "```console\n",
    "❯ giza prove --size M mnist_pytorch.casm.json\n",
    "[giza][2023-10-26 13:29:22.337] Proving job created with name 'proof-job-20231026-73fb1007' and id -> 1 ✅\n",
    "# This log live updates with the job elapsed time\n",
    "[giza][2023-10-26 13:32:44.431] Job status is 'PROCESSING', elapsed 103.0s\n",
    "# Once finished it will update to indicate that the job finished\n",
    "[giza][2023-10-26 13:37:06.634] Proving job is successful ✅\n",
    "[giza][2023-10-26 13:37:06.748] Proof metrics:\n",
    "{\n",
    "  \"cairovm_execution_time\": 4.973674,\n",
    "  \"proving_time\": 316.3519\n",
    "}\n",
    "[giza][2023-10-26 13:37:07.471] Proof saved at: zk.proof\n",
    "```\n",
    "\n",
    "Now we have our proof four our model! We can use it to verify that the model is correct and that the output that we get is the expected one.\n",
    "\n",
    "`verify` command coming soon!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
