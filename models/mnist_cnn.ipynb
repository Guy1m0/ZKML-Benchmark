{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model for MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 01:35:47.705367: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 01:35:47.737674: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 01:35:47.737699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 01:35:47.738354: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 01:35:47.743043: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 01:35:48.410681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 01:35:50.214591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.215485: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.215575: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.216484: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.216574: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.216652: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.300052: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.300196: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.300287: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-06 01:35:50.300362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19913 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images_tf = train_images / 255.0\n",
    "test_images_tf = test_images / 255.0\n",
    "train_images_tf = train_images_tf.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images_tf = test_images_tf.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "train_images_tf_14 = tf.image.resize(train_images_tf, [14, 14]).numpy()\n",
    "test_images_tf_14 = tf.image.resize(test_images_tf, [14, 14]).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch format [batch_size, channels, height, width]\n",
    "train_images_pt = torch.tensor(train_images_tf).permute(0, 3, 1, 2).float()\n",
    "test_images_pt = torch.tensor(test_images_tf).permute(0, 3, 1, 2).float()\n",
    "\n",
    "\n",
    "train_images_pt_14 =  torch.tensor(test_images_tf_14).permute(0, 3, 1, 2).float()\n",
    "test_images_pt_14 =  torch.tensor(test_images_tf_14).permute(0, 3, 1, 2).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5_11_80_10 CNN Model for 14x14 input and 3x3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 5)         50        \n",
      "                                                                 \n",
      " average_pooling2d_8 (Avera  (None, 6, 6, 5)           0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 11)          506       \n",
      "                                                                 \n",
      " average_pooling2d_9 (Avera  (None, 2, 2, 11)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 44)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 80)                3600      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                810       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4966 (19.40 KB)\n",
      "Trainable params: 4966 (19.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = [14, 5, 11, 80, 10, 3]\n",
    "\n",
    "# Define the LeNet model in TensorFlow\n",
    "model_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(5, 3, activation='relu', input_shape=(layers[0], layers[0], 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(11, 3, activation='relu'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(80, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10)  # Assuming 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_tf.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6917 - accuracy: 0.7884 - val_loss: 0.3224 - val_accuracy: 0.9048\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3197 - accuracy: 0.9026 - val_loss: 0.2002 - val_accuracy: 0.9420\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2235 - accuracy: 0.9329 - val_loss: 0.1552 - val_accuracy: 0.9603\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1760 - accuracy: 0.9468 - val_loss: 0.1343 - val_accuracy: 0.9618\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1513 - accuracy: 0.9539 - val_loss: 0.1148 - val_accuracy: 0.9658\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1346 - accuracy: 0.9600 - val_loss: 0.1125 - val_accuracy: 0.9660\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1222 - accuracy: 0.9626 - val_loss: 0.1009 - val_accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1149 - accuracy: 0.9641 - val_loss: 0.1000 - val_accuracy: 0.9708\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1067 - accuracy: 0.9671 - val_loss: 0.0862 - val_accuracy: 0.9720\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1019 - accuracy: 0.9693 - val_loss: 0.0977 - val_accuracy: 0.9740\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model_tf.fit(train_images_tf_14, train_labels, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0971 - accuracy: 0.9707 - 218ms/epoch - 697us/step\n",
      "\n",
      "Test accuracy: 0.9707000255584717\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_tf.evaluate(test_images_tf_14, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert it to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "layers = [14, 5, 11, 80, 10, 3]\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional encoder\n",
    "        self.conv1 = nn.Conv2d(1, layers[1], layers[-1]) \n",
    "        self.conv2 = nn.Conv2d(layers[1], layers[2], layers[-1]) \n",
    "\n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(11 * 2 * 2, layers[3]) # 256 * 120\n",
    "        self.fc2 = nn.Linear(layers[3], layers[4])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.relu(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.relu(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # TODO: figure out the resize, currently work on batch_size = 1\n",
    "        batch_size = x.size(0)\n",
    "        x = x.reshape(x.size(0),layers[2],-1)  # 16 output channels\n",
    "        x = np.transpose(x, (0,2,1)).reshape(batch_size,-1)\n",
    "        #x = x.reshape(batch_size,-1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No activation function here, will use CrossEntropyLoss later\n",
    "        return x\n",
    "\n",
    "model_pt = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "model_pt.fc1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second dense layer (fc2) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[6].get_weights()\n",
    "model_pt.fc2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc2.bias = nn.Parameter(torch.from_numpy(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "TensorFlow Basic Model Output: [[-4.868403   4.1331396 -4.9311266 -1.1776102 -0.9888911 -2.0313888\n",
      "  -4.0539174 -3.8575764  0.7993514 -0.0939117]]\n",
      "PyTorch Basic Model Output: tensor([[-4.8684,  4.1331, -4.9311, -1.1776, -0.9889, -2.0314, -4.0539, -3.8576,\n",
      "          0.7994, -0.0939]])\n"
     ]
    }
   ],
   "source": [
    "# Select the image for TensorFlow and PyTorch\n",
    "controlled_input_tf = test_images_tf_14[189:190]  # Reshape to (1, 784) for DNN\n",
    "controlled_input_pt = test_images_pt_14[189:190]\n",
    "\n",
    "# Test TensorFlow Model\n",
    "output_tf = model_tf.predict(controlled_input_tf) \n",
    "print(\"TensorFlow Basic Model Output:\", output_tf)\n",
    "\n",
    "# Test PyTorch Model\n",
    "model_pt.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt = model_pt(controlled_input_pt)\n",
    "print(\"PyTorch Basic Model Output:\", output_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 97.07%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming test_labels are already loaded\n",
    "test_dataset = TensorDataset(test_images_pt_14, torch.tensor(test_labels))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = evaluate_model(model_pt, test_loader)\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_tf(model, test_images, batch_size=256):\n",
    "    predictions = []\n",
    "    for i in range(0, len(test_images), batch_size):\n",
    "        batch = test_images[i:i+batch_size]\n",
    "        pred = model.predict(batch)\n",
    "        predictions.extend(np.argmax(pred, axis=1))\n",
    "    return predictions\n",
    "\n",
    "def get_predictions_pt(model, test_images, batch_size=256):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_images), batch_size):\n",
    "            batch = test_images[i:i+batch_size]\n",
    "            pred = model(batch)\n",
    "            predictions.extend(torch.argmax(pred, axis=1).tolist())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 618us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 516us/step\n",
      "8/8 [==============================] - 0s 585us/step\n",
      "8/8 [==============================] - 0s 484us/step\n",
      "8/8 [==============================] - 0s 500us/step\n",
      "8/8 [==============================] - 0s 527us/step\n",
      "8/8 [==============================] - 0s 524us/step\n",
      "8/8 [==============================] - 0s 584us/step\n",
      "8/8 [==============================] - 0s 606us/step\n",
      "8/8 [==============================] - 0s 800us/step\n",
      "8/8 [==============================] - 0s 779us/step\n",
      "8/8 [==============================] - 0s 732us/step\n",
      "8/8 [==============================] - 0s 814us/step\n",
      "8/8 [==============================] - 0s 555us/step\n",
      "8/8 [==============================] - 0s 722us/step\n",
      "8/8 [==============================] - 0s 671us/step\n",
      "8/8 [==============================] - 0s 530us/step\n",
      "8/8 [==============================] - 0s 668us/step\n",
      "8/8 [==============================] - 0s 682us/step\n",
      "8/8 [==============================] - 0s 745us/step\n",
      "8/8 [==============================] - 0s 677us/step\n",
      "8/8 [==============================] - 0s 698us/step\n",
      "8/8 [==============================] - 0s 641us/step\n",
      "8/8 [==============================] - 0s 810us/step\n",
      "8/8 [==============================] - 0s 739us/step\n",
      "8/8 [==============================] - 0s 900us/step\n",
      "8/8 [==============================] - 0s 805us/step\n",
      "8/8 [==============================] - 0s 792us/step\n",
      "8/8 [==============================] - 0s 742us/step\n",
      "8/8 [==============================] - 0s 604us/step\n",
      "8/8 [==============================] - 0s 529us/step\n",
      "8/8 [==============================] - 0s 625us/step\n",
      "8/8 [==============================] - 0s 676us/step\n",
      "8/8 [==============================] - 0s 668us/step\n",
      "8/8 [==============================] - 0s 480us/step\n",
      "8/8 [==============================] - 0s 517us/step\n",
      "8/8 [==============================] - 0s 554us/step\n",
      "8/8 [==============================] - 0s 494us/step\n",
      "8/8 [==============================] - 0s 549us/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Number of mismatches: 0 out of 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions_tf = get_predictions_tf(model_tf, test_images_tf_14)\n",
    "predictions_pt = get_predictions_pt(model_pt, test_images_pt_14)\n",
    "\n",
    "# Compare predictions\n",
    "mismatches = sum(p1 != p2 for p1, p2 in zip(predictions_tf, predictions_pt))\n",
    "print(f\"Number of mismatches: {mismatches} out of {len(test_images)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 5, 11, 80, 10, 3]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp577cc43o/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp577cc43o/assets\n",
      "2024-02-06 02:54:22.909645: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-06 02:54:22.909665: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-06 02:54:22.909809: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp577cc43o\n",
      "2024-02-06 02:54:22.910631: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-06 02:54:22.910641: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp577cc43o\n",
      "2024-02-06 02:54:22.912794: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-06 02:54:22.951124: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp577cc43o\n",
      "2024-02-06 02:54:22.960978: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 51170 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 19, % non-converted = 47.37 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 8, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Tensorflow\n",
    "arch_folder = \"./input-conv2d-conv2d-dense-dense/\"\n",
    "os.makedirs(arch_folder, exist_ok=True)\n",
    "\n",
    "model_name = \"_\".join([str(x) for x in layers])\n",
    "model_tf.save(arch_folder + model_name + '.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_tf)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(arch_folder + model_name + '.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire model\n",
    "torch.save(model_pt, arch_folder + model_name + \".pt\")\n",
    "# Save only the state_dict\n",
    "torch.save(model_pt.state_dict(), arch_folder + model_name + \".pth\")\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(model_pt, controlled_input_pt, arch_folder + model_name + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 784_6_16_10 Conv2d-Conv2D-Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:20:13.152800: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.153747: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.153840: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.154914: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.155011: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.155093: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.236484: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.236604: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.236694: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-05 16:20:13.236770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18524 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:20:14.150712: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-02-05 16:20:14.190407: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-05 16:20:14.286295: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f1af0a13d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-05 16:20:14.286314: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-02-05 16:20:14.291426: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-05 16:20:14.324180: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707121214.359937 2876481 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.3205 - accuracy: 0.9070 - val_loss: 0.1176 - val_accuracy: 0.9668\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1153 - accuracy: 0.9645 - val_loss: 0.0852 - val_accuracy: 0.9767\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0844 - accuracy: 0.9742 - val_loss: 0.0595 - val_accuracy: 0.9833\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0684 - accuracy: 0.9791 - val_loss: 0.0558 - val_accuracy: 0.9840\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.0479 - val_accuracy: 0.9868\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0518 - accuracy: 0.9842 - val_loss: 0.0549 - val_accuracy: 0.9848\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.0473 - val_accuracy: 0.9863\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 2s 977us/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.0439 - val_accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 0.0382 - val_accuracy: 0.9887\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.0390 - val_accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "# Define the LeNet model in TensorFlow\n",
    "model_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)  # Assuming 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_tf.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_tf.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 12, 12, 6)         0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 16)          2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 4, 4, 16)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5142 (20.09 KB)\n",
      "Trainable params: 5142 (20.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0387 - accuracy: 0.9877 - 194ms/epoch - 621us/step\n",
      "\n",
      "Test accuracy: 0.9876999855041504\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_tf.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional encoder\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # 1 input channel, 6 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel\n",
    "\n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 10) # 256 * 120\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.relu(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.relu(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # TODO: figure out the resize, currently work on batch_size = 1\n",
    "        batch_size = x.size(0)\n",
    "        x = x.reshape(x.size(0),16,-1)  # 16 output channels\n",
    "        x = np.transpose(x, (0,2,1)).reshape(batch_size,-1)\n",
    "        #x = x.reshape(batch_size,-1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)  # No activation function here, will use CrossEntropyLoss later\n",
    "        return x\n",
    "    \n",
    "\n",
    "model_pt = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "model_pt.fc1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc1.bias = nn.Parameter(torch.from_numpy(biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the image for TensorFlow\n",
    "controlled_input_tf = test_images[36][np.newaxis, ]  # No reshape needed as it's already in (28, 28, 1) format\n",
    "controlled_input_pt = torch.tensor(controlled_input_tf).float().permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "TF Basic Model Output: [[ -7.848706   -3.3647184   3.2896788  -2.3894203 -20.845005   -9.981148\n",
      "  -20.85786    11.181317  -11.737088  -10.418606 ]]\n",
      "PT Basic Model Output: [[ -7.8487053  -3.3647187   3.2896793  -2.3894205 -20.845015   -9.981146\n",
      "  -20.857857   11.18132   -11.737091  -10.418609 ]]\n"
     ]
    }
   ],
   "source": [
    "# Test PyTorch Basic Model\n",
    "model_pt.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt = model_pt(controlled_input_pt)\n",
    "\n",
    "output_tf = model_tf.predict(controlled_input_tf) \n",
    "print(\"TF Basic Model Output:\", output_tf)\n",
    "print(\"PT Basic Model Output:\", output_pt.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 98.77%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming the TensorFlow MNIST data has already been loaded\n",
    "# Convert test_images to PyTorch tensor and permute\n",
    "test_images_pt = torch.tensor(test_images).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Assuming test_labels are already loaded\n",
    "test_dataset = TensorDataset(test_images_pt, torch.tensor(test_labels))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = evaluate_model(model_pt, test_loader)\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_tf(model, test_images, batch_size=256):\n",
    "    predictions = []\n",
    "    for i in range(0, len(test_images), batch_size):\n",
    "        batch = test_images[i:i+batch_size]\n",
    "        pred = model.predict(batch)\n",
    "        predictions.extend(np.argmax(pred, axis=1))\n",
    "    return predictions\n",
    "\n",
    "def get_predictions_pt(model, test_images, batch_size=256):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_images), batch_size):\n",
    "            batch = test_images[i:i+batch_size]\n",
    "            pred = model(batch)\n",
    "            predictions.extend(torch.argmax(pred, axis=1).tolist())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 824us/step\n",
      "8/8 [==============================] - 0s 745us/step\n",
      "8/8 [==============================] - 0s 711us/step\n",
      "8/8 [==============================] - 0s 790us/step\n",
      "8/8 [==============================] - 0s 695us/step\n",
      "8/8 [==============================] - 0s 705us/step\n",
      "8/8 [==============================] - 0s 764us/step\n",
      "8/8 [==============================] - 0s 794us/step\n",
      "8/8 [==============================] - 0s 711us/step\n",
      "8/8 [==============================] - 0s 780us/step\n",
      "8/8 [==============================] - 0s 790us/step\n",
      "8/8 [==============================] - 0s 678us/step\n",
      "8/8 [==============================] - 0s 759us/step\n",
      "8/8 [==============================] - 0s 766us/step\n",
      "8/8 [==============================] - 0s 732us/step\n",
      "8/8 [==============================] - 0s 765us/step\n",
      "8/8 [==============================] - 0s 804us/step\n",
      "8/8 [==============================] - 0s 791us/step\n",
      "8/8 [==============================] - 0s 711us/step\n",
      "8/8 [==============================] - 0s 788us/step\n",
      "8/8 [==============================] - 0s 766us/step\n",
      "8/8 [==============================] - 0s 772us/step\n",
      "8/8 [==============================] - 0s 798us/step\n",
      "8/8 [==============================] - 0s 805us/step\n",
      "8/8 [==============================] - 0s 772us/step\n",
      "8/8 [==============================] - 0s 745us/step\n",
      "8/8 [==============================] - 0s 562us/step\n",
      "8/8 [==============================] - 0s 682us/step\n",
      "8/8 [==============================] - 0s 693us/step\n",
      "8/8 [==============================] - 0s 710us/step\n",
      "8/8 [==============================] - 0s 699us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "8/8 [==============================] - 0s 765us/step\n",
      "8/8 [==============================] - 0s 638us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "8/8 [==============================] - 0s 783us/step\n",
      "8/8 [==============================] - 0s 715us/step\n",
      "8/8 [==============================] - 0s 759us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Number of mismatches: 0 out of 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions_tf = get_predictions_tf(model_tf, test_images)\n",
    "predictions_pt = get_predictions_pt(model_pt, test_images_pt)\n",
    "\n",
    "# Compare predictions\n",
    "mismatches = sum(p1 != p2 for p1, p2 in zip(predictions_tf, predictions_pt))\n",
    "print(f\"Number of mismatches: {mismatches} out of {len(test_images)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Models for 784_6_16_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdq8sxxdi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdq8sxxdi/assets\n",
      "2024-02-05 16:22:44.382112: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-05 16:22:44.382125: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-05 16:22:44.382279: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpdq8sxxdi\n",
      "2024-02-05 16:22:44.382902: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-05 16:22:44.382907: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpdq8sxxdi\n",
      "2024-02-05 16:22:44.384357: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-02-05 16:22:44.384799: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-05 16:22:44.406560: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpdq8sxxdi\n",
      "2024-02-05 16:22:44.412235: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 29956 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 7, Total Ops 16, % non-converted = 43.75 %\n",
      " * 7 ARITH ops\n",
      "\n",
      "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Tensorflow\n",
    "arch_folder = \"./input-conv2d-conv2d-dense/\"\n",
    "os.makedirs(arch_folder, exist_ok=True)\n",
    "\n",
    "model_name = \"784_6_16_10\"\n",
    "model_tf.save(arch_folder + model_name + '.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_tf)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(arch_folder + model_name + '.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "\n",
    "# Save entire model\n",
    "torch.save(model_pt, arch_folder + model_name + \".pt\")\n",
    "# Save only the state_dict\n",
    "torch.save(model_pt.state_dict(), arch_folder + model_name + \".pth\")\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(model_pt, controlled_input_pt, arch_folder + model_name + \".onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 784_6_16_120_84_10 Conv2d-Conv2D-Dense-Dense-Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 2s 3ms/step - loss: 0.5725 - accuracy: 0.8337 - val_loss: 0.1971 - val_accuracy: 0.9423\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9451 - val_loss: 0.1256 - val_accuracy: 0.9608\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9645 - val_loss: 0.0845 - val_accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9727 - val_loss: 0.0739 - val_accuracy: 0.9783\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9767 - val_loss: 0.0683 - val_accuracy: 0.9818\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9797 - val_loss: 0.0577 - val_accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9821 - val_loss: 0.0596 - val_accuracy: 0.9842\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9848 - val_loss: 0.0551 - val_accuracy: 0.9842\n",
      "Epoch 9/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9850 - val_loss: 0.0533 - val_accuracy: 0.9843\n",
      "Epoch 10/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.0466 - val_accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "# Define the LeNet model in TensorFlow\n",
    "model_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='relu'),\n",
    "    tf.keras.layers.Dense(84, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)  # Assuming 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_tf.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_tf.fit(train_images, train_labels, epochs=10, batch_size=256, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0377 - accuracy: 0.9872 - 247ms/epoch - 790us/step\n",
      "\n",
      "Test accuracy: 0.9872000217437744\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_tf.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Avera  (None, 12, 12, 6)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 16)          2416      \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 4, 4, 16)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 120)               30840     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44426 (173.54 KB)\n",
      "Trainable params: 44426 (173.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional encoder\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # 1 input channel, 6 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel\n",
    "\n",
    "        # Fully connected layers / Dense block\n",
    "        self.fc1 = nn.Linear(16 *4 * 4,120) # 256 * 120\n",
    "        self.fc2 = nn.Linear(120, 84)         # 120 inputs, 84 outputs\n",
    "        self.fc3 = nn.Linear(84, 10)          # 84 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block\n",
    "        x = F.avg_pool2d(F.relu(self.conv1(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "        x = F.avg_pool2d(F.relu(self.conv2(x)), (2, 2)) # Convolution -> Sigmoid -> Avg Pool\n",
    "\n",
    "        # TODO: figure out the resize, currently work on batch_size = 1\n",
    "        batch_size = x.size(0)\n",
    "        x = x.reshape(x.size(0),16,-1)  # 16 output channels\n",
    "        x = np.transpose(x, (0,2,1)).reshape(batch_size,-1)\n",
    "        #x = x.reshape(batch_size,-1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # No activation function here, will use CrossEntropyLoss later\n",
    "        return x\n",
    "    \n",
    "\n",
    "model_pt = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt.conv1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second Conv2D layer from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[2].get_weights()\n",
    "model_pt.conv2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (3, 2, 0, 1))))\n",
    "model_pt.conv2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[5].get_weights()\n",
    "model_pt.fc1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second dense layer (fc2) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[6].get_weights()\n",
    "model_pt.fc2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc2.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the third dense layer (fc3) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[7].get_weights()\n",
    "model_pt.fc3.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc3.bias = nn.Parameter(torch.from_numpy(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the image for TensorFlow\n",
    "controlled_input_tf = test_images[36][np.newaxis, ]  # No reshape needed as it's already in (28, 28, 1) format\n",
    "controlled_input_pt = torch.tensor(controlled_input_tf).float().permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Basic Model Output: [[ -5.0148506   -1.157651     3.4304547   -0.13103871 -10.998174\n",
      "   -7.736541   -10.994179    10.4635515   -2.6589053   -6.6241155 ]]\n",
      "PT Basic Model Output: [[ -5.0148487   -1.1576512    3.430455    -0.13104191 -10.998172\n",
      "   -7.7365384  -10.994177    10.463552    -2.6589077   -6.624114  ]]\n"
     ]
    }
   ],
   "source": [
    "# Test PyTorch Basic Model\n",
    "model_pt.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt = model_pt(controlled_input_pt)\n",
    "\n",
    "output_tf = model_tf.predict(controlled_input_tf) \n",
    "print(\"TF Basic Model Output:\", output_tf)\n",
    "print(\"PT Basic Model Output:\", output_pt.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 98.72%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming the TensorFlow MNIST data has already been loaded\n",
    "# Convert test_images to PyTorch tensor and permute\n",
    "test_images_pt = torch.tensor(test_images).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Assuming test_labels are already loaded\n",
    "test_dataset = TensorDataset(test_images_pt, torch.tensor(test_labels))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = evaluate_model(model_pt, test_loader)\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 862us/step\n",
      "8/8 [==============================] - 0s 752us/step\n",
      "8/8 [==============================] - 0s 749us/step\n",
      "8/8 [==============================] - 0s 747us/step\n",
      "8/8 [==============================] - 0s 772us/step\n",
      "8/8 [==============================] - 0s 831us/step\n",
      "8/8 [==============================] - 0s 941us/step\n",
      "8/8 [==============================] - 0s 918us/step\n",
      "8/8 [==============================] - 0s 893us/step\n",
      "8/8 [==============================] - 0s 815us/step\n",
      "8/8 [==============================] - 0s 814us/step\n",
      "8/8 [==============================] - 0s 826us/step\n",
      "8/8 [==============================] - 0s 913us/step\n",
      "8/8 [==============================] - 0s 894us/step\n",
      "8/8 [==============================] - 0s 757us/step\n",
      "8/8 [==============================] - 0s 819us/step\n",
      "8/8 [==============================] - 0s 739us/step\n",
      "8/8 [==============================] - 0s 843us/step\n",
      "8/8 [==============================] - 0s 895us/step\n",
      "8/8 [==============================] - 0s 803us/step\n",
      "8/8 [==============================] - 0s 784us/step\n",
      "8/8 [==============================] - 0s 752us/step\n",
      "8/8 [==============================] - 0s 809us/step\n",
      "8/8 [==============================] - 0s 754us/step\n",
      "8/8 [==============================] - 0s 734us/step\n",
      "8/8 [==============================] - 0s 848us/step\n",
      "8/8 [==============================] - 0s 773us/step\n",
      "8/8 [==============================] - 0s 717us/step\n",
      "8/8 [==============================] - 0s 751us/step\n",
      "8/8 [==============================] - 0s 738us/step\n",
      "8/8 [==============================] - 0s 759us/step\n",
      "8/8 [==============================] - 0s 617us/step\n",
      "8/8 [==============================] - 0s 550us/step\n",
      "8/8 [==============================] - 0s 735us/step\n",
      "8/8 [==============================] - 0s 723us/step\n",
      "8/8 [==============================] - 0s 742us/step\n",
      "8/8 [==============================] - 0s 800us/step\n",
      "8/8 [==============================] - 0s 725us/step\n",
      "8/8 [==============================] - 0s 709us/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Number of mismatches: 0 out of 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions_tf = get_predictions_tf(model_tf, test_images)\n",
    "predictions_pt = get_predictions_pt(model_pt, test_images_pt)\n",
    "\n",
    "# Compare predictions\n",
    "mismatches = sum(p1 != p2 for p1, p2 in zip(predictions_tf, predictions_pt))\n",
    "print(f\"Number of mismatches: {mismatches} out of {len(test_images)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model for 784_6_16_120_84_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptka8q2hl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptka8q2hl/assets\n",
      "2024-02-05 16:24:02.657200: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-05 16:24:02.657221: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-05 16:24:02.657370: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmptka8q2hl\n",
      "2024-02-05 16:24:02.658461: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-05 16:24:02.658471: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmptka8q2hl\n",
      "2024-02-05 16:24:02.661524: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-05 16:24:02.707050: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmptka8q2hl\n",
      "2024-02-05 16:24:02.718252: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 60883 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 11, Total Ops 22, % non-converted = 50.00 %\n",
      " * 11 ARITH ops\n",
      "\n",
      "- arith.constant:   11 occurrences  (f32: 10, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Tensorflow\n",
    "arch_folder = \"./input-conv2d-conv2d-dense-dense-dense/\"\n",
    "os.makedirs(arch_folder, exist_ok=True)\n",
    "\n",
    "model_name = \"784_6_16_120_84_10\"\n",
    "model_tf.save(arch_folder + model_name + '.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_tf)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(arch_folder + model_name + '.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "\n",
    "# Save entire model\n",
    "torch.save(model_pt, arch_folder + model_name + \".pt\")\n",
    "# Save only the state_dict\n",
    "torch.save(model_pt.state_dict(), arch_folder + model_name + \".pth\")\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(model_pt, controlled_input_pt, arch_folder + model_name + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
