{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN model for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load TensorFlow MNIST data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m mnist \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load TensorFlow MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize and flatten the images\n",
    "train_images_tf = train_images.reshape((-1, 28*28)) / 255.0\n",
    "test_images_tf = test_images.reshape((-1, 28*28)) / 255.0\n",
    "\n",
    "# Convert to PyTorch format [batch_size, total pixels]\n",
    "# Since images are already normalized and flattened for TensorFlow, we can use the same arrays\n",
    "train_images_pt = torch.tensor(train_images_tf).float()\n",
    "test_images_pt = torch.tensor(test_images_tf).float()\n",
    "train_labels_pt = torch.tensor(train_labels)\n",
    "test_labels_pt = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "num_classes = 10\n",
    "\n",
    "model_tf = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28*28,)),  # Adjusted for 28x28 images\n",
    "#    keras.layers.Dense(128, activation='relu'),     # Increased number of neurons\n",
    "    keras.layers.Dense(56, activation='relu'),      # Additional hidden layer\n",
    "    keras.layers.Dense(num_classes, activation='softmax')  # Output layer for 10 classes\n",
    "])\n",
    "\n",
    "model_tf.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 16:04:21.886799: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.2KiB (rounded to 2304)requested by op Fill\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-01-28 16:04:21.886822: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-01-28 16:04:21.886827: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 59, Chunks in use: 59. 14.8KiB allocated for chunks. 14.8KiB in use in bin. 3.2KiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886830: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886832: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886835: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 8, Chunks in use: 8. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 17.5KiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886837: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 3, Chunks in use: 3. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 6.6KiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886839: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886841: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886843: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 52.8KiB allocated for chunks. 52.8KiB in use in bin. 52.7KiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886846: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 4, Chunks in use: 4. 386.5KiB allocated for chunks. 386.5KiB in use in bin. 210.9KiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886848: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 11, Chunks in use: 11. 1.84MiB allocated for chunks. 1.84MiB in use in bin. 1.84MiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886850: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 282.5KiB allocated for chunks. 282.5KiB in use in bin. 171.5KiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886852: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886854: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886856: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886858: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886860: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886862: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886864: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886866: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886870: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 5, Chunks in use: 5. 809.59MiB allocated for chunks. 809.59MiB in use in bin. 807.50MiB client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886872: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-28 16:04:21.886874: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 2.2KiB was 2.0KiB, Chunk State: \n",
      "2024-01-28 16:04:21.886876: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 851640320\n",
      "2024-01-28 16:04:21.886879: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000000 of size 256 next 1\n",
      "2024-01-28 16:04:21.886881: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000100 of size 1280 next 2\n",
      "2024-01-28 16:04:21.886883: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000600 of size 256 next 3\n",
      "2024-01-28 16:04:21.886884: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000700 of size 256 next 4\n",
      "2024-01-28 16:04:21.886886: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000800 of size 256 next 6\n",
      "2024-01-28 16:04:21.886887: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000900 of size 256 next 7\n",
      "2024-01-28 16:04:21.886889: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000a00 of size 256 next 5\n",
      "2024-01-28 16:04:21.886890: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000b00 of size 256 next 8\n",
      "2024-01-28 16:04:21.886892: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000c00 of size 256 next 12\n",
      "2024-01-28 16:04:21.886894: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000d00 of size 256 next 13\n",
      "2024-01-28 16:04:21.886895: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000e00 of size 256 next 11\n",
      "2024-01-28 16:04:21.886897: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c000f00 of size 256 next 14\n",
      "2024-01-28 16:04:21.886898: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c001000 of size 256 next 17\n",
      "2024-01-28 16:04:21.886900: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c001100 of size 256 next 20\n",
      "2024-01-28 16:04:21.886901: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c001200 of size 256 next 21\n",
      "2024-01-28 16:04:21.886903: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c001300 of size 256 next 22\n",
      "2024-01-28 16:04:21.886904: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c001400 of size 256 next 24\n",
      "2024-01-28 16:04:21.886906: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c001500 of size 256 next 25\n",
      "2024-01-28 16:04:21.886908: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c001600 of size 2816 next 15\n",
      "2024-01-28 16:04:21.886910: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c002100 of size 2304 next 16\n",
      "2024-01-28 16:04:21.886911: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c002a00 of size 54016 next 19\n",
      "2024-01-28 16:04:21.886913: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c00fd00 of size 289280 next 9\n",
      "2024-01-28 16:04:21.886915: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c056700 of size 175616 next 10\n",
      "2024-01-28 16:04:21.886917: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb4c081500 of size 169344000 next 18\n",
      "2024-01-28 16:04:21.886919: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb56201100 of size 175616 next 23\n",
      "2024-01-28 16:04:21.886921: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622bf00 of size 2304 next 26\n",
      "2024-01-28 16:04:21.886922: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622c800 of size 256 next 27\n",
      "2024-01-28 16:04:21.886924: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622c900 of size 256 next 28\n",
      "2024-01-28 16:04:21.886925: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622ca00 of size 256 next 29\n",
      "2024-01-28 16:04:21.886927: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622cb00 of size 256 next 30\n",
      "2024-01-28 16:04:21.886929: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622cc00 of size 256 next 31\n",
      "2024-01-28 16:04:21.886930: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622cd00 of size 256 next 32\n",
      "2024-01-28 16:04:21.886932: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622ce00 of size 256 next 33\n",
      "2024-01-28 16:04:21.886933: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622cf00 of size 256 next 38\n",
      "2024-01-28 16:04:21.886935: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622d000 of size 256 next 37\n",
      "2024-01-28 16:04:21.886936: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622d100 of size 256 next 39\n",
      "2024-01-28 16:04:21.886938: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622d200 of size 256 next 34\n",
      "2024-01-28 16:04:21.886939: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622d300 of size 256 next 46\n",
      "2024-01-28 16:04:21.886941: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622d400 of size 256 next 47\n",
      "2024-01-28 16:04:21.886942: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622d500 of size 4096 next 43\n",
      "2024-01-28 16:04:21.886944: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622e500 of size 2304 next 44\n",
      "2024-01-28 16:04:21.886946: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5622ee00 of size 92672 next 35\n",
      "2024-01-28 16:04:21.886947: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb56245800 of size 256 next 36\n",
      "2024-01-28 16:04:21.886949: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb56245900 of size 175616 next 45\n",
      "2024-01-28 16:04:21.886950: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb56270700 of size 175616 next 42\n",
      "2024-01-28 16:04:21.886952: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb5629b500 of size 175616 next 40\n",
      "2024-01-28 16:04:21.886954: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb562c6300 of size 169344000 next 41\n",
      "2024-01-28 16:04:21.886955: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60445f00 of size 2304 next 48\n",
      "2024-01-28 16:04:21.886957: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446800 of size 256 next 49\n",
      "2024-01-28 16:04:21.886958: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446900 of size 256 next 50\n",
      "2024-01-28 16:04:21.886960: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446a00 of size 256 next 51\n",
      "2024-01-28 16:04:21.886961: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446b00 of size 256 next 52\n",
      "2024-01-28 16:04:21.886963: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446c00 of size 256 next 53\n",
      "2024-01-28 16:04:21.886964: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446d00 of size 256 next 54\n",
      "2024-01-28 16:04:21.886966: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446e00 of size 256 next 55\n",
      "2024-01-28 16:04:21.886968: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60446f00 of size 107776 next 58\n",
      "2024-01-28 16:04:21.886970: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60461400 of size 256 next 63\n",
      "2024-01-28 16:04:21.886971: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb60461500 of size 169344000 next 56\n",
      "2024-01-28 16:04:21.886973: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e1100 of size 256 next 61\n",
      "2024-01-28 16:04:21.886974: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e1200 of size 256 next 57\n",
      "2024-01-28 16:04:21.886976: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e1300 of size 256 next 59\n",
      "2024-01-28 16:04:21.886978: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e1400 of size 256 next 70\n",
      "2024-01-28 16:04:21.886979: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e1500 of size 256 next 71\n",
      "2024-01-28 16:04:21.886981: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e1600 of size 4096 next 62\n",
      "2024-01-28 16:04:21.886982: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e2600 of size 2304 next 68\n",
      "2024-01-28 16:04:21.886984: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5e2f00 of size 102144 next 65\n",
      "2024-01-28 16:04:21.886986: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5fbe00 of size 256 next 66\n",
      "2024-01-28 16:04:21.886987: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a5fbf00 of size 175616 next 69\n",
      "2024-01-28 16:04:21.886989: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a626d00 of size 175616 next 67\n",
      "2024-01-28 16:04:21.886990: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a651b00 of size 175616 next 60\n",
      "2024-01-28 16:04:21.886992: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb6a67c900 of size 169344000 next 64\n",
      "2024-01-28 16:04:21.886993: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fc500 of size 2304 next 72\n",
      "2024-01-28 16:04:21.886995: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fce00 of size 256 next 73\n",
      "2024-01-28 16:04:21.886996: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fcf00 of size 256 next 74\n",
      "2024-01-28 16:04:21.886998: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd000 of size 256 next 75\n",
      "2024-01-28 16:04:21.887000: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd100 of size 256 next 76\n",
      "2024-01-28 16:04:21.887001: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd200 of size 256 next 77\n",
      "2024-01-28 16:04:21.887003: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd300 of size 256 next 78\n",
      "2024-01-28 16:04:21.887004: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd400 of size 256 next 79\n",
      "2024-01-28 16:04:21.887006: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd500 of size 256 next 81\n",
      "2024-01-28 16:04:21.887007: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd600 of size 256 next 80\n",
      "2024-01-28 16:04:21.887009: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd700 of size 256 next 87\n",
      "2024-01-28 16:04:21.887010: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd800 of size 256 next 82\n",
      "2024-01-28 16:04:21.887012: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fd900 of size 256 next 91\n",
      "2024-01-28 16:04:21.887014: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fda00 of size 256 next 92\n",
      "2024-01-28 16:04:21.887015: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747fdb00 of size 4096 next 89\n",
      "2024-01-28 16:04:21.887017: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747feb00 of size 2304 next 90\n",
      "2024-01-28 16:04:21.887019: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb747ff400 of size 93184 next 83\n",
      "2024-01-28 16:04:21.887020: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb74816000 of size 256 next 84\n",
      "2024-01-28 16:04:21.887022: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb74816100 of size 175616 next 86\n",
      "2024-01-28 16:04:21.887024: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb74840f00 of size 175616 next 85\n",
      "2024-01-28 16:04:21.887025: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb7486bd00 of size 175616 next 88\n",
      "2024-01-28 16:04:21.887027: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcb74896b00 of size 171545856 next 18446744073709551615\n",
      "2024-01-28 16:04:21.887030: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-01-28 16:04:21.887033: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 59 Chunks of size 256 totalling 14.8KiB\n",
      "2024-01-28 16:04:21.887035: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-01-28 16:04:21.887037: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 2304 totalling 15.8KiB\n",
      "2024-01-28 16:04:21.887039: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2816 totalling 2.8KiB\n",
      "2024-01-28 16:04:21.887041: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 4096 totalling 12.0KiB\n",
      "2024-01-28 16:04:21.887042: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 54016 totalling 52.8KiB\n",
      "2024-01-28 16:04:21.887044: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 92672 totalling 90.5KiB\n",
      "2024-01-28 16:04:21.887046: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 93184 totalling 91.0KiB\n",
      "2024-01-28 16:04:21.887048: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 102144 totalling 99.8KiB\n",
      "2024-01-28 16:04:21.887050: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 107776 totalling 105.2KiB\n",
      "2024-01-28 16:04:21.887052: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 11 Chunks of size 175616 totalling 1.84MiB\n",
      "2024-01-28 16:04:21.887054: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 289280 totalling 282.5KiB\n",
      "2024-01-28 16:04:21.887056: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 169344000 totalling 646.00MiB\n",
      "2024-01-28 16:04:21.887057: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 171545856 totalling 163.60MiB\n",
      "2024-01-28 16:04:21.887059: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 812.19MiB\n",
      "2024-01-28 16:04:21.887061: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 851640320 memory_limit_: 851640320 available bytes: 0 curr_region_allocation_bytes_: 1703280640\n",
      "2024-01-28 16:04:21.887066: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       851640320\n",
      "InUse:                       851640320\n",
      "MaxInUse:                    851640320\n",
      "NumAllocs:                         270\n",
      "MaxAllocSize:                171545856\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-01-28 16:04:21.887070: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] ****************************************************************************************************\n",
      "2024-01-28 16:04:21.887081: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at constant_op.cc:176 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[56,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 150, in build\n        self.add_variable_from_reference(\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1125, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 508, in add_variable_from_reference\n        initial_value = tf.zeros(\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/dtensor/python/api.py\", line 64, in call_with_layout\n        return fn(*args, **kwargs)\n\n    ResourceExhaustedError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[56,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill] name: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model_tf\u001b[38;5;241m.\u001b[39mevaluate(test_images_tf, test_labels, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:52\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 150, in build\n        self.add_variable_from_reference(\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1125, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 508, in add_variable_from_reference\n        initial_value = tf.zeros(\n    File \"/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/dtensor/python/api.py\", line 64, in call_with_layout\n        return fn(*args, **kwargs)\n\n    ResourceExhaustedError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[56,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill] name: \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_tf.fit(train_images_tf, train_labels, epochs=3, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model_tf.evaluate(test_images_tf, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Pytorch DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        # Fully connected layers / Dense block\n",
    "        # First dense layer\n",
    "        self.fc1 = nn.Linear(28*28, 56)  # Flatten 28*28 and feed into 56 neurons\n",
    "        \n",
    "        # Second dense layer (output layer)\n",
    "        self.fc2 = nn.Linear(56, num_classes)  # 56 inputs, 10 outputs (number of classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the tensor\n",
    "        #x = x.view(-1, 28*28)\n",
    "        \n",
    "        # Fully connected layers with ReLU activation for the first layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # Output layer with no activation\n",
    "        # Softmax will be applied externally during training and evaluation\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "    \n",
    "model_pt = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer weights for the first dense layer (fc1) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[0].get_weights()\n",
    "model_pt.fc1.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc1.bias = nn.Parameter(torch.from_numpy(biases))\n",
    "\n",
    "# Transfer weights for the second dense layer (fc2) from model_tf to model_pt\n",
    "weights, biases = model_tf.layers[1].get_weights()\n",
    "model_pt.fc2.weight = nn.Parameter(torch.from_numpy(np.transpose(weights, (1, 0))))\n",
    "model_pt.fc2.bias = nn.Parameter(torch.from_numpy(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "TensorFlow Basic Model Output: [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "PyTorch Basic Model Output: [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Select the image for TensorFlow and PyTorch\n",
    "controlled_input_tf = test_images[38].reshape(1, 28*28)  # Reshape to (1, 784) for DNN\n",
    "controlled_input_pt = torch.from_numpy(controlled_input_tf).float()\n",
    "\n",
    "# Test TensorFlow Model\n",
    "output_tf = model_tf.predict(controlled_input_tf) \n",
    "print(\"TensorFlow Basic Model Output:\", output_tf)\n",
    "\n",
    "# Test PyTorch Model\n",
    "model_pt.eval()  # Set PyTorch model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output_pt = model_pt(controlled_input_pt)\n",
    "print(\"PyTorch Basic Model Output:\", torch.exp(output_pt).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the PyTorch model on the test images: 96.61000000%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create TensorDataset for test data\n",
    "test_dataset = TensorDataset(test_images_pt, test_labels_pt)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def evaluate_pytorch_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the PyTorch model\n",
    "accuracy = evaluate_pytorch_model(model_pt, test_loader)\n",
    "print(f'Accuracy of the PyTorch model on the test images: {accuracy:.8f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_tf(model, test_images, batch_size=32):\n",
    "    predictions = []\n",
    "    for i in range(0, len(test_images), batch_size):\n",
    "        batch = test_images[i:i+batch_size]\n",
    "        pred = model.predict(batch)\n",
    "        predictions.extend(np.argmax(pred, axis=1))\n",
    "    return predictions\n",
    "\n",
    "def get_predictions_pt(model, test_images, batch_size=32):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_images), batch_size):\n",
    "            batch = test_images[i:i+batch_size]\n",
    "            pred = model(batch)\n",
    "            predictions.extend(torch.argmax(pred, axis=1).tolist())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Number of mismatches: 0 out of 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions_tf = get_predictions_tf(model_tf, test_images_tf)\n",
    "predictions_pt = get_predictions_pt(model_pt, test_images_pt)\n",
    "\n",
    "# Compare predictions\n",
    "mismatches = sum(p1 != p2 for p1, p2 in zip(predictions_tf, predictions_pt))\n",
    "print(f\"Number of mismatches: {mismatches} out of {len(test_images_tf)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and Normalize x_test_image from float64 to int8\n",
    "x_test_image_norm = (test_images / 255.0 * 255 - 128).astype(np.int8)\n",
    "x_train_image_norm = (train_images / 255.0 * 255 - 128).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwhl7byf9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwhl7byf9/assets\n",
      "/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-28 12:40:59.650471: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-28 12:40:59.650491: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-28 12:40:59.650629: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpwhl7byf9\n",
      "2024-01-28 12:40:59.651605: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-28 12:40:59.651614: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpwhl7byf9\n",
      "2024-01-28 12:40:59.654288: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-28 12:40:59.693065: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpwhl7byf9\n",
      "2024-01-28 12:40:59.703200: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 52572 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 0, Total Ops 12, % non-converted = 0.00 %\n",
      " * \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 2, uq_32: 2)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46896"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "\n",
    "# Indicate that you want to perform default optimizations,\n",
    "# which include quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Define a generator function that provides your test data's numpy arrays\n",
    "def representative_data_gen():\n",
    "  for i in range(500):\n",
    "    yield [np.array(train_images[i:i+1], dtype=np.float32)]\n",
    "\n",
    "# Use the generator function to guide the quantization process\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to int8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"q_aware_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# The input needs to be quantized, so we retrieve the quantization parameters\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "output_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "# Normalize and quantize the test images\n",
    "test_images_quant = (test_images / input_scale + input_zero_point).astype(np.int8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 3 but expected 2 for input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_images_quant[i], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Set the value for the input tensor\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run the inference\u001b[39;00m\n\u001b[1;32m     10\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:720\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    705\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 3 but expected 2 for input 0."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized TFLite model\n",
    "correct_predictions = 0\n",
    "for i in range(len(test_images)):\n",
    "    test_image = np.expand_dims(test_images_quant[i], axis=0)\n",
    "    \n",
    "    # Set the value for the input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    \n",
    "    # Run the inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Retrieve the output and dequantize\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    output = np.argmax(output, axis=1)\n",
    "    predicted_class = output[0]\n",
    "    if predicted_class == test_labels[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / len(test_images) * 100\n",
    "print(f'Quantized model accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Orion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `orion` package.\n"
     ]
    }
   ],
   "source": [
    "!scarb new orion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Create an object with all tensors (an input + all weights and biases)\n",
    "tensors = {\n",
    "    \"fc1_weights\": interpreter.get_tensor(1), \n",
    "    \"fc1_bias\": interpreter.get_tensor(2), \n",
    "    \"fc2_weights\": interpreter.get_tensor(4), \n",
    "    \"fc2_bias\": interpreter.get_tensor(5)\n",
    "}\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('./orion_dnn/src/generated', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fixed_point(val, bits):\n",
    "    return round(val * (2**bits))\n",
    "\n",
    "def mnist_image_to_fixed_point(data):\n",
    "    return [to_fixed_point(val.item(), 16) for val in data]\n",
    "\n",
    "\n",
    "def generate_input_cairo(data):\n",
    "    values = mnist_image_to_fixed_point(data)\n",
    "    values = [f\"FixedTrait::<FP16x16>::new({val}, {'true' if val < 0 else 'false'})\" for val in values]\n",
    "    return \",\\n \".join(values)\n",
    "\n",
    "input_cairo = generate_input_cairo(controlled_input_tf[0])\n",
    "\n",
    "with open(\"orion_dnn/src/generated/input.cairo\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "use array::{SpanTrait, ArrayTrait};\n",
    "use orion::operators::tensor::{TensorTrait, FP16x16Tensor, Tensor};\n",
    "use orion::numbers::{FixedTrait, FP16x16};\n",
    "fn input() -> Tensor<FP16x16> {\n",
    "    TensorTrait::<FP16x16>::new(\n",
    "        array![196].span(),\n",
    "        array![\n",
    "    \"\"\")\n",
    "    f.write(input_cairo)\n",
    "    f.write(\"\"\"\n",
    "        ].span()\n",
    "    )\n",
    "}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tensor_name, tensor in tensors.items():\n",
    "    with open(os.path.join('./orion_dnn/src', 'generated', f\"{tensor_name}.cairo\"), \"w\") as f:\n",
    "        f.write(\n",
    "            \"use array::{ArrayTrait, SpanTrait};\\n\" +\n",
    "            \"use orion::operators::tensor::{core::{Tensor, TensorTrait}};\\n\" +\n",
    "            \"use orion::operators::tensor::FP16x16Tensor;\\n\" +\n",
    "            \"use orion::numbers::fixed_point::implementations::fp16x16::core::{FP16x16, FixedTrait};\\n\" +\n",
    "            \"\\n\" + f\"fn {tensor_name}() -> Tensor<FP16x16>\" + \"{\\n\\n\" + \n",
    "            \"let mut shape = ArrayTrait::new();\\n\"\n",
    "        )\n",
    "        for dim in tensor.shape:\n",
    "            f.write(f\"shape.append({dim});\\n\")\n",
    "        f.write(\"let mut data = ArrayTrait::new();\\n\")\n",
    "\n",
    "        for val in np.nditer(tensor.flatten()):\n",
    "            f.write(\"    data.append(i32 {{ mag: {0}, sign: {1} }});\\n\".format(abs(int(val)), str(val < 0).lower()))\n",
    "        f.write(\n",
    "            \"    TensorTrait::new(shape.span(), data.span())\\n\" +\n",
    "            \"}\\n\"\n",
    "        )\n",
    "\n",
    "with open(os.path.join('./orion_dnn/src', 'generated.cairo'), 'w') as f:\n",
    "    for param_name in tensors.keys():\n",
    "        f.write(f\"mod {param_name};\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLa  (None, 784)               3         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 56)                43965     \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 10)                575       \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44543 (174.00 KB)\n",
      "Trainable params: 44530 (173.95 KB)\n",
      "Non-trainable params: 13 (52.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Apply quantization to the layers\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "q_aware_model = quantize_model(model_tf)\n",
    "\n",
    "# 'quantize_model' requires a recompile\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 12:38:59.657971: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.658006: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.659413: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.659424: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.659437: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.659808: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.659965: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.659974: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.857932: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.857941: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.859053: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.859349: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.859755: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.859765: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.859787: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-28 12:38:59.859798: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0963 - accuracy: 0.9720 - val_loss: 0.1078 - val_accuracy: 0.9672\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0788 - accuracy: 0.9758 - val_loss: 0.0958 - val_accuracy: 0.9718\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0657 - accuracy: 0.9806 - val_loss: 0.0903 - val_accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 3\n",
    "history = q_aware_model.fit(train_images_tf, train_labels,\n",
    "                            epochs=epochs,\n",
    "                            validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4j4dhfnv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4j4dhfnv/assets\n",
      "/home/guy1m0/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-28 12:39:13.507507: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-28 12:39:13.507524: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-28 12:39:13.507747: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp4j4dhfnv\n",
      "2024-01-28 12:39:13.508200: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-28 12:39:13.508209: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp4j4dhfnv\n",
      "2024-01-28 12:39:13.509435: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-28 12:39:13.509897: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-28 12:39:13.536105: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp4j4dhfnv\n",
      "2024-01-28 12:39:13.542437: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 34691 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 4, Total Ops 10, % non-converted = 40.00 %\n",
      " * 4 ARITH ops\n",
      "\n",
      "- arith.constant:    4 occurrences  (f32: 4)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_input_1:0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m converter\u001b[38;5;241m.\u001b[39minference_output_type \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint8\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Convert the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Save the model to disk\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_aware_model.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite(tflite_model)\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1139\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1138\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1093\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m   1092\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m-> 1093\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1601\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;129m@_export_metrics\u001b[39m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;124;03m      Invalid quantization parameters.\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1601\u001b[0m   saved_model_convert_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_as_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1602\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1582\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1578\u001b[0m   graph_def, input_tensors, output_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1579\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_keras_to_saved_model(temp_dir)\n\u001b[1;32m   1580\u001b[0m   )\n\u001b[1;32m   1581\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_dir:\n\u001b[0;32m-> 1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFLiteKerasModelConverterV2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensors\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1586\u001b[0m   shutil\u001b[38;5;241m.\u001b[39mrmtree(temp_dir, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1378\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;66;03m# Converts model.\u001b[39;00m\n\u001b[1;32m   1371\u001b[0m result \u001b[38;5;241m=\u001b[39m _convert_graphdef(\n\u001b[1;32m   1372\u001b[0m     input_data\u001b[38;5;241m=\u001b[39mgraph_def,\n\u001b[1;32m   1373\u001b[0m     input_tensors\u001b[38;5;241m=\u001b[39minput_tensors,\n\u001b[1;32m   1374\u001b[0m     output_tensors\u001b[38;5;241m=\u001b[39moutput_tensors,\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverter_kwargs,\n\u001b[1;32m   1376\u001b[0m )\n\u001b[0;32m-> 1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_tflite_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quant_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_new_quantizer\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[0;32m--> 215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1037\u001b[0m, in \u001b[0;36mTFLiteConverterBase._optimize_tflite_model\u001b[0;34m(self, model, quant_mode, quant_io)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   q_allow_float \u001b[38;5;241m=\u001b[39m quant_mode\u001b[38;5;241m.\u001b[39mis_allow_float()\n\u001b[1;32m   1036\u001b[0m   q_variable_quantization \u001b[38;5;241m=\u001b[39m quant_mode\u001b[38;5;241m.\u001b[39menable_mlir_variable_quantization\n\u001b[0;32m-> 1037\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_in_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_out_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_activations_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_bias_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_allow_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_variable_quantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m m_in_type \u001b[38;5;241m=\u001b[39m in_type \u001b[38;5;28;01mif\u001b[39;00m in_type \u001b[38;5;28;01melse\u001b[39;00m _dtypes\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m   1048\u001b[0m m_out_type \u001b[38;5;241m=\u001b[39m out_type \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;28;01melse\u001b[39;00m _dtypes\u001b[38;5;241m.\u001b[39mfloat32\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:735\u001b[0m, in \u001b[0;36mTFLiteConverterBase._quantize\u001b[0;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float, enable_variable_quantization)\u001b[0m\n\u001b[1;32m    731\u001b[0m calibrate_quantize \u001b[38;5;241m=\u001b[39m _calibrator\u001b[38;5;241m.\u001b[39mCalibrator(\n\u001b[1;32m    732\u001b[0m     result, custom_op_registerers_by_name, custom_op_registerers_by_func\n\u001b[1;32m    733\u001b[0m )\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_calibrate_only \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_new_quantizer:\n\u001b[0;32m--> 735\u001b[0m   calibrated \u001b[38;5;241m=\u001b[39m \u001b[43mcalibrate_quantize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentative_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_gen\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_calibrate_only:\n\u001b[1;32m    740\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m calibrated\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[0;32m--> 215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:254\u001b[0m, in \u001b[0;36mCalibrator.calibrate\u001b[0;34m(self, dataset_gen)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;129m@convert_phase\u001b[39m(Component\u001b[38;5;241m.\u001b[39mOPTIMIZE_TFLITE_MODEL, SubComponent\u001b[38;5;241m.\u001b[39mCALIBRATE)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalibrate\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_gen):\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calibrates the model with specified generator.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    dataset_gen: A generator that generates calibration samples.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calibrator\u001b[38;5;241m.\u001b[39mCalibrate()\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:152\u001b[0m, in \u001b[0;36mCalibrator._feed_tensors\u001b[0;34m(self, dataset_gen, resize_input)\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calibrator\u001b[38;5;241m.\u001b[39mFeedTensor(input_array, signature_key)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calibrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeedTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_input_1:0 "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_tf)\n",
    "\n",
    "# Indicate that you want to perform default optimizations,\n",
    "# which include quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Define a generator function that provides your test data's numpy arrays\n",
    "def representative_data_gen():\n",
    "  for i in range(500):\n",
    "    yield [test_images_tf[i:i+1]]\n",
    "\n",
    "# Use the generator function to guide the quantization process\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to int8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"q_aware_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the image for TensorFlow and PyTorch\n",
    "controlled_input_tf = test_images[34].reshape(1, 28*28)  # Reshape to (1, 784) for DNN\n",
    "controlled_input_pt = torch.from_numpy(controlled_input_tf).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object with all tensors \n",
    "#(an input + all weights and biases)\n",
    "tensors = {\n",
    "    \"input\": controlled_input_pt,\n",
    "    \"fc1_weights\": interpreter.get_tensor(1), \n",
    "    \"fc1_bias\": interpreter.get_tensor(2), \n",
    "    \"fc2_weights\": interpreter.get_tensor(4), \n",
    "    \"fc2_bias\": interpreter.get_tensor(5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('./orion_dnn/src/generated', exist_ok=True)\n",
    "\n",
    "for tensor_name, tensor in tensors.items():\n",
    "    with open(os.path.join('./orion_dnn/src', 'generated', f\"{tensor_name}.cairo\"), \"w\") as f:\n",
    "        f.write(\n",
    "            \"use core::array::ArrayTrait;\\n\" +\n",
    "            \"use orion::operators::tensor::{TensorTrait, Tensor, I32Tensor};\\n\" +\n",
    "            \"use orion::numbers::i32;\\n\\n\" +\n",
    "            \"\\nfn {0}() -> Tensor<i32> \".format(tensor_name) + \"{\\n\" +\n",
    "            \"    let mut shape = ArrayTrait::<usize>::new();\\n\"\n",
    "        )\n",
    "        for dim in tensor.shape:\n",
    "            f.write(\"    shape.append({0});\\n\".format(dim))\n",
    "        f.write(\n",
    "            \"    let mut data = ArrayTrait::<i32>::new();\\n\"\n",
    "        )\n",
    "        for val in np.nditer(tensor.flatten()):\n",
    "            f.write(\"    data.append(i32 {{ mag: {0}, sign: {1} }});\\n\".format(abs(int(val)), str(val < 0).lower()))\n",
    "        f.write(\n",
    "            \"    TensorTrait::new(shape.span(), data.span())\\n\" +\n",
    "            \"}\\n\"\n",
    "        )\n",
    "      \n",
    "with open(os.path.join('./orion_dnn/src', 'generated.cairo'), 'w') as f:\n",
    "    for param_name in tensors.keys():\n",
    "        f.write(f\"mod {param_name};\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "! touch orion_dnn/src/nn.cairo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting orion_dnn/src/nn.cairo\n"
     ]
    }
   ],
   "source": [
    "%%writefile orion_dnn/src/nn.cairo\n",
    "use orion::operators::tensor::core::Tensor;\n",
    "use orion::numbers::signed_integer::{integer_trait::IntegerTrait, i32::i32};\n",
    "use orion::operators::nn::{NNTrait, I32NN};\n",
    "\n",
    "fn fc1(i: Tensor<i32>, w: Tensor<i32>, b: Tensor<i32>) -> Tensor<i32> {\n",
    "    let x = NNTrait::linear(i, w, b);\n",
    "    NNTrait::relu(@x)\n",
    "}\n",
    "\n",
    "fn fc2(i: Tensor<i32>, w: Tensor<i32>, b: Tensor<i32>) -> Tensor<i32> {\n",
    "    NNTrait::linear(i, w, b)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "! touch orion_dnn/src/test.cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting orion_dnn/src/test.cairo\n"
     ]
    }
   ],
   "source": [
    "%%writefile orion_dnn/src/test.cairo\n",
    "use core::array::SpanTrait;\n",
    "\n",
    "use mnist_nn::nn::fc1;\n",
    "use mnist_nn::nn::fc2;\n",
    "use mnist_nn::generated::input::input;\n",
    "use mnist_nn::generated::fc1_bias::fc1_bias;\n",
    "use mnist_nn::generated::fc1_weights::fc1_weights;\n",
    "use mnist_nn::generated::fc2_bias::fc2_bias;\n",
    "use mnist_nn::generated::fc2_weights::fc2_weights;\n",
    "\n",
    "use orion::operators::tensor::I32Tensor;\n",
    "\n",
    "#[test]\n",
    "#[available_gas(99999999999999999)]\n",
    "fn mnist_nn_test() {\n",
    "    let input = input();\n",
    "    let fc1_bias = fc1_bias();\n",
    "    let fc1_weights = fc1_weights();\n",
    "    let fc2_bias = fc2_bias();\n",
    "    let fc2_weights = fc2_weights();\n",
    "\n",
    "    let x = fc1(input, fc1_weights, fc1_bias);\n",
    "    let x = fc2(x, fc2_weights, fc2_bias);\n",
    "\n",
    "    let x = *x.argmax(0, Option::None(()), Option::None(())).data.at(0);\n",
    "\n",
    "    assert(x == 3, 'should predict 2');\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31merror\u001b[0m: failed to read manifest at: /home/guy1m0/Desktop/ZKML-Benchmark/Milestone 2/MNIST-DNN/Scarb.toml\n",
      "\n",
      "Caused by:\n",
      "    No such file or directory (os error 2)\n"
     ]
    }
   ],
   "source": [
    "! cd orion_dnn & scarb run test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Giza-cli to automatically generate cairo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fixed_point(val, bits):\n",
    "    return round(val * (2**bits))\n",
    "\n",
    "def mnist_image_to_fixed_point(data):\n",
    "    return [to_fixed_point(val.item(), 16) for val in data]\n",
    "\n",
    "\n",
    "def generate_input_cairo(data):\n",
    "    values = mnist_image_to_fixed_point(data)\n",
    "    values = [f\"FixedTrait::<FP16x16>::new({val}, {'true' if val < 0 else 'false'})\" for val in values]\n",
    "    return \",\\n \".join(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlled_input_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cairo = generate_input_cairo(controlled_input_pt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_cairo/src/input.cairo\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "use array::{SpanTrait, ArrayTrait};\n",
    "use orion::operators::tensor::{TensorTrait, FP16x16Tensor, Tensor};\n",
    "use orion::numbers::{FixedTrait, FP16x16};\n",
    "fn input() -> Tensor<FP16x16> {\n",
    "    TensorTrait::<FP16x16>::new(\n",
    "        array![196].span(),\n",
    "        array![\n",
    "    \"\"\")\n",
    "    f.write(input_cairo)\n",
    "    f.write(\"\"\"\n",
    "        ].span()\n",
    "    )\n",
    "}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
