{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dataset import Dataset\n",
    "import time\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "import ezkl, onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Dictionary for CIFAR10\n",
    "classDict = {'plane': 0, 'car': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "             'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "\n",
    "binaryClasses = {0:'Machine', 1:'Animal'} # Machine , Animal\n",
    "\n",
    "data_mean = (0.4914, 0.4822, 0.4465)\n",
    "data_std = (0.2470, 0.2435, 0.2616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.transformer import TransformerDecoderLayer\n",
    "# Overwrite getitem method to obtain the index of the images when iterating through the images\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CIFAR10(Dataset):\n",
    "    def __init__(self, train, transform, num_samples=0):\n",
    "        self.cifar10 = torchvision.datasets.CIFAR10(\n",
    "                        root='./data', train=train, download=True, transform=transform)\n",
    "        self.targets = self.cifar10.targets\n",
    "        self.classes = self.cifar10.classes\n",
    "        self.data = self.cifar10.data\n",
    "        if num_samples:\n",
    "            self.num_samples = num_samples\n",
    "        else:\n",
    "           self.num_samples = len(self.cifar10)\n",
    "\n",
    "    # Overloaded the getitem method to return index as well\n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.cifar10[index]\n",
    "        return data, target, index\n",
    "\n",
    "    # Method to get all images' indices from a certain class without iterating through the loader\n",
    "    def get_index(self, target_label):\n",
    "      index_list = []\n",
    "      for index, label in enumerate(self.targets):\n",
    "        if label == target_label:\n",
    "          index_list.append(index)\n",
    "      return index_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def remove(self, remove_list):\n",
    "      mask = np.ones(self.num_samples, dtype=bool)\n",
    "      mask[remove_list] = False\n",
    "      data = self.data[mask]\n",
    "\n",
    "# Data Prep.\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip(data_mean, data_std)],\n",
    "   std= [1/s for s in data_std]\n",
    ")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(data_mean, data_std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(data_mean, data_std),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:25<00:00, 6619129.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(train=True, transform=transform_train)\n",
    "testset = CIFAR10(train=False, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torchvision.models.ResNet):\n",
    "    \"\"\"ResNet generalization for CIFAR-like thingies.\n",
    "\n",
    "    This is a minor modification of\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py,\n",
    "    adding additional options.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=2, zero_init_residual=False,\n",
    "                 groups=1, base_width=64, replace_stride_with_dilation=[False, False, False, False],\n",
    "                 norm_layer=torch.nn.BatchNorm2d, strides=[1, 2, 2, 2], initial_conv=[3, 1, 1]):\n",
    "        \"\"\"Initialize as usual. Layers and strides are scriptable.\"\"\"\n",
    "        super(torchvision.models.ResNet, self).__init__()  # torch.nn.Module\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.dilation = 1\n",
    "        if len(replace_stride_with_dilation) != 4:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 4-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "\n",
    "        self.inplanes = base_width\n",
    "        self.base_width = 64  # Do this to circumvent BasicBlock errors. The value is not actually used.\n",
    "        self.conv1 = torch.nn.Conv2d(3, self.inplanes, kernel_size=initial_conv[0],\n",
    "                                     stride=initial_conv[1], padding=initial_conv[2], bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "        layer_list = []\n",
    "        width = self.inplanes\n",
    "        for idx, layer in enumerate(layers):\n",
    "            layer_list.append(self._make_layer(block, width, layer, stride=strides[idx], dilate=replace_stride_with_dilation[idx]))\n",
    "            width *= 2\n",
    "        self.layers = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(width // 2 * block.expansion, num_classes)\n",
    "        #self.predict = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (torch.nn.BatchNorm2d, torch.nn.GroupNorm)):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the arch by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "\n",
    "\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layers(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x) # Sigmoid\n",
    "        #x = self.predict(x)\n",
    "        return x\n",
    "\n",
    "initial_conv = [3, 1, 1]\n",
    "NN_model = ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2], num_classes=10, base_width=64, initial_conv=initial_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"Running on a CPU...Uhh, are you sure you want to do this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up training params\n",
    "epochs = 21\n",
    "eta = 0.01\n",
    "optimizer = torch.optim.SGD(params = NN_model.parameters(), lr = eta, weight_decay = 5e-4, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "NN_model.to(device)\n",
    "NN_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for NN\n",
    "DATASET = 'CIFAR10'      # Choose between 'CIFAR2', 'CIFAR10'\n",
    "MODEL = 'RESNET18'       # Choose between 'RESNET18', 'VGG11'\n",
    "AUGMENTS = True          # Use Data Augmentation\n",
    "SAVEMODEL = False         # Save Clean Model\n",
    "# LOADMODEL = False        # Load Clean Model\n",
    "\n",
    "# Save or Load Clean Model\n",
    "\n",
    "import os\n",
    "PATH = \"./crypto_hackathon/model\"\n",
    "os.makedirs(PATH, exist_ok = True)\n",
    "PATH += \"/resnet_cifar.ptr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, valid_losses = [], correct = 0, total = 0):\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate Model\n",
    "    for inputs, labels, index in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "            if DATASET == 'CIFAR2':\n",
    "                labels = labels.to(torch.float32)\n",
    "                output = output.flatten()\n",
    "\n",
    "        # negative labels: when using hinge embedding loss only\n",
    "        flipped_labels = labels # * -1\n",
    "        loss = loss_fun(output, flipped_labels)   # Calculate loss\n",
    "\n",
    "        valid_loss = loss_fun(output, labels)\n",
    "        valid_losses.append(valid_loss.item())\n",
    "\n",
    "        #predictions = torch.argmax(output, dim=1)\n",
    "        if DATASET == 'CIFAR2':\n",
    "            predictions = torch.where(output < 0, 0, 1)\n",
    "        else:\n",
    "            predictions = torch.argmax(output.data, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return valid_losses, correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.6206142967939376, Accuracy: 0.8369\n"
     ]
    }
   ],
   "source": [
    "# if local model is not supported\n",
    "NN_model.load_state_dict(torch.load(\"./crypto_hackathon/cuda_resnet_cifar.ptr\", map_location='cpu'))\n",
    "NN_model.to('mps')\n",
    "#torch.save(NN_model.state_dict, PATH)\n",
    "\n",
    "valid_losses, correct, total = evaluate_model(testloader, NN_model)\n",
    "print(\"Valid loss: {}, Accuracy: {}\".format(np.mean(valid_losses), correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_imgages(img1, img2, size, inv_normalize=None):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # If an inverse normalization function is provided, apply it\n",
    "    if inv_normalize:\n",
    "        img_to_show = inv_normalize(img1.cpu()).permute(1, 2, 0)\n",
    "    else:\n",
    "        img_to_show = img1.numpy()\n",
    "\n",
    "    # Show original image\n",
    "    axs[0].imshow(img_to_show)  # Transpose back to HxWxC format\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Show normalized grayscale image\n",
    "    axs[1].imshow(img2.reshape(size,size,1), cmap='gray')\n",
    "    axs[1].set_title('Grayscale Normalized Image')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def show_image(dataset, norms, ind=0, inv_normalize=None):\n",
    "    # Assuming 'ind' is a valid index for the dataset\n",
    "    # Retrieve data, target, and the index from the dataset\n",
    "    img, target, _ = dataset[ind]\n",
    "\n",
    "    # Convert PyTorch tensor to numpy array if necessary\n",
    "    img_np = img.numpy()\n",
    "\n",
    "    # Convert RGB to grayscale\n",
    "    img_grayscale = np.dot(img_np.transpose((1, 2, 0)), [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "    # Normalize grayscale image using the norm provided\n",
    "    img_normalized = img_grayscale / norms[ind]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # If an inverse normalization function is provided, apply it\n",
    "    if inv_normalize:\n",
    "        img_to_show = inv_normalize(img).permute(1, 2, 0)\n",
    "    else:\n",
    "        img_to_show = img_np\n",
    "\n",
    "    # Show original image\n",
    "    axs[0].imshow(img_to_show)  # Transpose back to HxWxC format\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Show normalized grayscale image\n",
    "    axs[1].imshow(img_normalized, cmap='gray')\n",
    "    axs[1].set_title('Grayscale Normalized Image')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = [2,3,5] # bird, cat, dog\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "def gen_targetloader(dataset, target_class, num_samples = 100):\n",
    "    target_index = dataset.get_index(target_class)\n",
    "\n",
    "    if len(target_index) > num_samples:\n",
    "        target_index = random.sample(target_index, num_samples)\n",
    "\n",
    "    targetset = data.Subset(dataset, target_index)\n",
    "    targetloader = torch.utils.data.DataLoader(targetset)\n",
    "\n",
    "    return targetloader, target_index\n",
    "\n",
    "def gen_random_subset_dataloader(dataset, batch = 1, num_samples = 100):\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    random_subset = Subset(dataset, indices)\n",
    "\n",
    "    return DataLoader(random_subset, batch_size=batch), indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Batch ZKML Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create and (potentially train a model)\n",
    "\n",
    "# make sure you have the dependencies required here already installed\n",
    "import json\n",
    "#import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import sk2torch\n",
    "#import torch\n",
    "import ezkl\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp/' created successfully\n"
     ]
    }
   ],
   "source": [
    "folder = \"./tmp/\"\n",
    "\n",
    "# Create the directory 'tmp' in the current working directory\n",
    "try:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"Directory '{folder}' created successfully\")\n",
    "except OSError as error:\n",
    "    print(f\"Directory '{folder}' cannot be created. Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_function(data_path, model_path, settings_path, resource_string):\n",
    "    res = await ezkl.calibrate_settings(data_path, model_path, settings_path, resource_string)\n",
    "    assert res == True\n",
    "\n",
    "def gen_witness_NN(model, img, pre_fix, batch_size):\n",
    "    model_path = os.path.join(folder, pre_fix + '_network.onnx')\n",
    "    compiled_model_path = os.path.join(folder, pre_fix + '_network.compiled')\n",
    "    settings_path = os.path.join(folder, pre_fix + '_settings.json') \n",
    "    witness_path = os.path.join(folder, pre_fix + '_witness.json')\n",
    "    data_path = os.path.join(folder, pre_fix + '_input.json')\n",
    "    srs_path = os.path.join(folder, pre_fix + '_kzg.srs')\n",
    "\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "    x = img.cpu()\n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(model,                   # model being run\n",
    "                    x,                         # model input (or a tuple for multiple inputs)\n",
    "                    model_path,                # where to save the model (can be a file or file-like object)\n",
    "                    export_params=True,        # store the trained parameter weights inside the model file\n",
    "                    opset_version=10,          # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                    input_names = ['input'],   # the model's input names\n",
    "                    output_names = ['output'], # the model's output names\n",
    "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "\n",
    "    data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "    data = dict(input_data = [data_array])\n",
    "\n",
    "    # Serialize data into file:\n",
    "    json.dump(data, open(data_path, 'w'))\n",
    "\n",
    "    !RUST_LOG=trace\n",
    "    # TODO: Dictionary outputs\n",
    "    run_args = ezkl.PyRunArgs()\n",
    "    run_args.variables = [(\"batch_size\", batch_size)]\n",
    "    res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
    "    assert res == True\n",
    "\n",
    "    res = async_function(data_path, model_path, settings_path, \"resource\")\n",
    "    #res = await ezkl.calibrate_settings(data_path, model_path, settings_path, resource_string)\n",
    "    #assert res == True\n",
    "\n",
    "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # srs path\n",
    "    res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "    # now generate the witness file\n",
    "    res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "\n",
    "    with open(witness_path, \"r\") as f:\n",
    "        wit = json.load(f)\n",
    "\n",
    "    with open(settings_path, \"r\") as f:\n",
    "        setting = json.load(f)\n",
    "\n",
    "    prediction_array = []\n",
    "    for value in wit[\"outputs\"]:\n",
    "        for field_element in value:\n",
    "            prediction_array.append(ezkl.vecu64_to_float(field_element, setting['model_output_scales'][0]))\n",
    "    return torch.argmax(torch.Tensor([prediction_array]), dim=1)\n",
    "    print ('Prediction:', torch.argmax(torch.Tensor([prediction_array]), dim=1) == label.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288\n"
     ]
    }
   ],
   "source": [
    "with open(\"./tmp/tensor([1, 0, 2, 6])_input.json\", \"r\") as f:\n",
    "    input = json.load(f)\n",
    "with open(\"./tmp/tensor([1, 0, 2, 6])_settings.json\", \"r\") as f:\n",
    "    setting = json.load(f)\n",
    "    \n",
    "print (len(input['input_data'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def model_benchmark(model1, testset, batch = 1, num_samples = 100):\n",
    "    # Get Model 1 predictions\n",
    "    # indices = random.sample(range(len(testset)), num_samples)\n",
    "    # target_loader, indices = gen_targetloader(testset, target_class, num_samples)\n",
    "    # test_loader, indices = gen_random_subset_dataloader(testset, batch, num_samples)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch, shuffle=True)\n",
    "\n",
    "    m1_predictions = []\n",
    "    m1_labels = []\n",
    "    \n",
    "    for img, label, index in tqdm(testloader, desc='NN_model Batch Proof Gen'):\n",
    "        pred = gen_witness_NN(model1, img, \"new\", batch)\n",
    "        # pred == label.cpu()\n",
    "        m1_predictions.append(pred)\n",
    "        m1_labels.append(label)       \n",
    "\n",
    "\n",
    "    return m1_predictions, m1_labels\n",
    "\n",
    "    # # Get Model 2 predictions\n",
    "    # x_test, y_test, _ = process_dataset(testset)\n",
    "    # m2_predictions = []\n",
    "    # m2_labels = []\n",
    "\n",
    "    # for index in tqdm(indices, desc = 'SVC_model Batch Proof Gen'):\n",
    "    #     pred = gen_witness_SVC(model2, x_test[index])\n",
    "    #     # pred == label\n",
    "    #     m2_predictions.append(pred)\n",
    "    #     m2_labels.append(y_test[index])\n",
    "\n",
    "    # return ([int(t.item()) for t in m1_predictions], [int(t.item()) for t in m1_labels]), (m2_predictions, m2_labels), indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN_model Batch Proof Gen: 100%|██████████| 3/3 [16:49<00:00, 336.54s/it]\n"
     ]
    }
   ],
   "source": [
    "testset = CIFAR10(train=False, transform=transform_test, num_samples=12)\n",
    "preds, labels = model_benchmark(NN_model, testset, 4, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([39]), tensor([28]), tensor([33])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 8, 9]), tensor([6, 6, 8, 0]), tensor([1, 6, 3, 3])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "with open(\"./tmp/tensor([6])_input.json\", \"r\") as f:\n",
    "    input = json.load(f)\n",
    "with open(\"./tmp/tensor([6])_settings.json\", \"r\") as f:\n",
    "    setting = json.load(f)\n",
    "    \n",
    "print (len(input['input_data'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
