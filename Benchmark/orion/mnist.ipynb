{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f06f8105370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10000\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/tmp', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize((14,14)),\n",
    "                                torchvision.transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "                             ])), shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/tmp', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize((14,14)),\n",
    "                                torchvision.transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "                             ])), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtest_loader\u001b[49m)\n\u001b[1;32m      2\u001b[0m batch_idx, (example_data, example_targets) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(examples)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_data.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(f\"example_data.shape: {example_data.shape}\")\n",
    "print(f\"example_targets.shape: {example_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(196, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.143008\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.013687\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.142858\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.171771\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 4.330003\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.002654\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3\n",
      "Real Value: 3\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = network(example_data)\n",
    "print(f\"Prediction: {pred.argmax()}\")\n",
    "print(f\"Real Value: {example_targets.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dummy input of shape [1, 196]\n",
    "dummy_input = torch.randn(1, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()\n",
    "torch.onnx.export(network, dummy_input, \"compl.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4\n",
      "Real Value: 4\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load the ONNX model\n",
    "ort_session = ort.InferenceSession(\"1l_5.onnx\")\n",
    "\n",
    "# Function to predict using the ONNX model\n",
    "def predict_with_onnx(model, data_loader):\n",
    "    for data, targets in data_loader:\n",
    "        # Convert the PyTorch tensor to a NumPy array\n",
    "        data_numpy = data.numpy().astype(np.float32)\n",
    "\n",
    "        # Run the model (input data needs to be in dictionary format)\n",
    "        ort_inputs = {model.get_inputs()[0].name: data_numpy}\n",
    "        ort_outs = model.run(None, ort_inputs)\n",
    "\n",
    "        # Get the prediction and actual label\n",
    "        predicted = np.argmax(ort_outs[0], axis=1)\n",
    "        print(f\"Prediction: {predicted[0]}\")\n",
    "        print(f\"Real Value: {targets.numpy()[0]}\")\n",
    "        break  # For demonstration, break after one batch\n",
    "\n",
    "# Use the function to predict with the ONNX model\n",
    "predict_with_onnx(ort_session, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mnist_cairo/src/input.cairo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(values)\n\u001b[1;32m     13\u001b[0m input_cairo \u001b[38;5;241m=\u001b[39m generate_input_cairo(example_data[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmnist_cairo/src/input.cairo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     16\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124muse array::\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mSpanTrait, ArrayTrait};\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124muse orion::operators::tensor::\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mTensorTrait, FP16x16Tensor, Tensor};\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m        array![\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(input_cairo)\n",
      "File \u001b[0;32m~/Desktop/ZKML-Benchmark/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist_cairo/src/input.cairo'"
     ]
    }
   ],
   "source": [
    "def to_fixed_point(val, bits):\n",
    "    return round(val * (2**bits))\n",
    "\n",
    "def mnist_image_to_fixed_point(data):\n",
    "    return [to_fixed_point(val.item(), 16) for val in data]\n",
    "\n",
    "\n",
    "def generate_input_cairo(data):\n",
    "    values = mnist_image_to_fixed_point(data)\n",
    "    values = [f\"FixedTrait::<FP16x16>::new({val}, {'true' if val < 0 else 'false'})\" for val in values]\n",
    "    return \",\\n \".join(values)\n",
    "\n",
    "input_cairo = generate_input_cairo(example_data[0])\n",
    "\n",
    "with open(\"mnist_cairo/src/input.cairo\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "use array::{SpanTrait, ArrayTrait};\n",
    "use orion::operators::tensor::{TensorTrait, FP16x16Tensor, Tensor};\n",
    "use orion::numbers::{FixedTrait, FP16x16};\n",
    "fn input() -> Tensor<FP16x16> {\n",
    "    TensorTrait::<FP16x16>::new(\n",
    "        array![196].span(),\n",
    "        array![\n",
    "    \"\"\")\n",
    "    f.write(input_cairo)\n",
    "    f.write(\"\"\"\n",
    "        ].span()\n",
    "    )\n",
    "}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
